<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <title>Sky Atlas</title>
  <style>
    body {
      font-family: Arial, Helvetica, sans-serif;
      line-height: 150%;
      font-size: 15px;
      background-color: #E8E8E8
    }

    h1 {
      padding: 2em 0 .5em
    }

    td {
      vertical-align: top;
      padding: 5px;
      min-width: 240px;
      border-top: 1px solid #E8E8E8
    }

    th {
      text-align: left;
      padding: 5px
    }

    dfn {
      font-style: normal
    }

    a {
      color: #70f
    }

    a:hover {
      color: #70f
    }

    a:visited {
      color: #470296
    }

    #scopes,
    #articles,
    #sections,
    #type-specifications,
    #annotations,
    #tenets,
    #scenarios,
    #scenario-variations,
    #needed-research,
    #active-data,
    #agent-scope {
      margin: 0 auto 1em;
      padding: 3em;
      width: 95%;
      min-width: 960px;
      max-width: 1600px;
      border-bottom: 5px solid #E8E8E8;
      background-color: #fff;
      box-sizing: border-box
    }

    #scopes td:nth-child(1),
    #articles td:nth-child(1) {
      min-width: 75px;
      max-width: 100px
    }

    #type-specifications {
      max-width: 100%;
      overflow-x: auto
    }

    #scopes td:nth-child(3),
    #articles td:nth-child(3),
    #sections td:nth-child(3),
    #type-specifications td:nth-child(3),
    #annotations td:nth-child(3),
    #tenets td:nth-child(3),
    #scenarios td:nth-child(3),
    #scenario-variations td:nth-child(3),
    #needed-research td:nth-child(3),
    #active-data td:nth-child(3) {
      min-width: 75px;
      text-transform: uppercase;
      font-size: 80%;
      color: #666;
      font-weight: 700
    }
    #agent-scope td:nth-child(3) {
      min-width: 75px;
      text-transform: uppercase;
      font-size: 80%;
      color: #666;
      font-weight: bold;
    }

    #type-specifications td:nth-child(6) {
      min-width: 160px;
      max-width: 160px
    }

    #scenario-variations td:nth-child(5),
    #scenarios td:nth-child(5) {
      min-width: 160px;
      max-width: 160px
    }
  </style>
  <base target="_blank" />
</head>

<body>

  <div id="scopes">
    <h1>Scopes</h1>
    <table>
      <tr>
        <th>Doc No</th>
        <th>Name</th>
        <th>Type</th>
        <th>Content</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>A.0</dfn>
          </td>
          <td>Atlas Preamble</td>
          <td>Scope</td>
          <td>This Preamble will be further populated in later iterations of the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1</dfn>
          </td>
          <td>The Governance Scope</td>
          <td>Scope</td>
          <td>The Governance Scope regulates the governance processes and balance of power of the Sky Ecosystem.
            The Governance Scope must ensure that the resilient equilibrium of Sky Governance remains protected
            against all potential direct and indirect threats.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2</dfn>
          </td>
          <td>The Support Scope</td>
          <td>Scope</td>
          <td>The Support Scope governs all routine aspects of ecosystem support, including governance process
            infrastructure and management, Star support and Ecosystem Actor support.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3</dfn>
          </td>
          <td>The Stability Scope</td>
          <td>Scope</td>
          <td>The Stability Scope governs the management of the USDS Stablecoin. The USDS Stablecoin must be a
            permissionless and useful currency available to anyone. Its stability and risk must be managed to
            generate as much value for Sky and public good as possible.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4</dfn>
          </td>
          <td>The Protocol Scope</td>
          <td>Scope</td>
          <td>The Protocol Scope regulates the maintenance and development of the core Sky Protocol and its
            critical, non-collateral components. The Protocol Scope defines all rules for protocol engineering.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5</dfn>
          </td>
          <td>The Accessibility Scope</td>
          <td>Scope</td>
          <td>The Accessibility Scope governs accessibility and distribution efforts, and regulates user-facing
            frontends.</td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="articles">
    <h1>Articles</h1>
    <table>
      <tr>
        <th>Doc No</th>
        <th>Name</th>
        <th>Type</th>
        <th>Content</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>A.0.1</dfn>
          </td>
          <td>Atlas Preamble</td>
          <td>Article</td>
          <td>This Article contains definitions and general provisions that should be inherited as essential
            context for the Atlas as a whole.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.1</dfn>
          </td>
          <td>Spirit of the Atlas</td>
          <td>Article</td>
          <td>The Spirit of the Atlas represents the foundational principles of Sky Governance. The Spirit of the
            Atlas is enshrined in the Immutable Documents, reflected in the Atlas as a whole and enacted by
            aligned participants of the Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2</dfn>
          </td>
          <td>Atlas Documents</td>
          <td>Article</td>
          <td>Atlas Documents are essential to the structure and governance of the Sky Ecosystem. They are
            organized into document trees, which include Immutable Documents and Adaptive Documents. Immutable
            Documents embody the Spirit of the Atlas; while Adaptive Documents operationalize the Spirit of the
            Atlas and facilitate its aligned evolution. This Article defines the properties, development, and
            procedures associated with Atlas Documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.3</dfn>
          </td>
          <td>Governance Accessibility</td>
          <td>Article</td>
          <td>This Article regulates the design and implementation of platforms for facilitating accessible and
            transparent governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4</dfn>
          </td>
          <td>Alignment Conservers</td>
          <td>Article</td>
          <td>Alignment Conservers (ACs) safeguard the Sky Governance process, ensuring its alignment with the
            Spirit of the Atlas. This Article defines requirements and processes related to Alignment
            Conservers.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5</dfn>
          </td>
          <td>Aligned Delegates</td>
          <td>Article</td>
          <td>A type of Alignment Conserver, Aligned Delegates (ADs) possess considerable influence over the Sky
            Protocol through their control of delegated voting power. Their primary focus is to prevent the
            abuse of this power, whether by themselves or others, and to safeguard the ecosystem against
            misaligned actions from other actors or parts of the governance process. This Article defines key
            infrastructure and requirements concerning Aligned Delegates.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6</dfn>
          </td>
          <td>Facilitators</td>
          <td>Article</td>
          <td>A type of Alignment Conserver, Facilitators are assigned responsibility over specific Scopes for Sky
            Core or Stars. This Article defines key infrastructure and requirements concerning Facilitators.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.7</dfn>
          </td>
          <td>Professional Ecosystem Actors</td>
          <td>Article</td>
          <td>Professional Ecosystem Actors are external actors that complete work for Sky Ecosystem. This Article
            defines rules and processes related to Professional Ecosystem Actors.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.8</dfn>
          </td>
          <td>Emergency Response System</td>
          <td>Article</td>
          <td>This Article defines a general emergency response protocol for managing emergencies or urgent situations 
            outside of the standard Weekly Governance Cycle and Monthly Governance Cycle.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9</dfn>
          </td>
          <td>Sky Core Governance Security</td>
          <td>Article</td>
          <td>This Article governs the correct and secure execution of Sky Governance processes for deploying and
            reviewing Executive Votes. This Article must protect against all forms of attacks, disruption and
            accidental failure by maximizing the transparency and resilience of the Sky Executive Process.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11</dfn>
          </td>
          <td>Weekly Governance Cycle</td>
          <td>Article</td>
          <td>This Article regulates the Weekly Governance Cycle which comprises two distinct subsets, the
            Operational Weekly Cycle and the Atlas Edit Weekly Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12</dfn>
          </td>
          <td>Monthly Governance Cycle</td>
          <td>Article</td>
          <td>This Article regulates the Monthly Governance Cycle, which provides a predictable monthly framework
            by which Sky Governance decisions are made.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13</dfn>
          </td>
          <td>Updating Active Data</td>
          <td>Article</td>
          <td>This Article regulates modifications to Active Data documents. Active Data documents can be directly
            modified by Facilitators or other recognized actors through processes that occur outside the
            standard Weekly Governance Cycle and Monthly Governance Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.15</dfn>
          </td>
          <td>Scope Bootstrapping</td>
          <td>Article</td>
          <td>This Article defines rules and procedures for swiftly resolving issues that may arise in the
            Governance Scope during the transition to the Endgame State. This Article must work to minimize
            transition costs and friction impeding this transition.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.2</dfn>
          </td>
          <td>Governance Process Support</td>
          <td>Article</td>
          <td>The Support Scope regulates the routine governance processes needed to operationalize the Atlas.
            This Article defines key infrastructure and processes supporting this objective.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.3</dfn>
          </td>
          <td>Atlas Core Development</td>
          <td>Article</td>
          <td>This Article defines key infrastructure and processes supporting the development of the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.5</dfn>
          </td>
          <td>Star Incubation</td>
          <td>Article</td>
          <td>This Article governs the incubation of Stars. It defines the necessary infrastructure and processes
            to ensure Stars are maximally supported to generate as much value as possible for the Sky Ecosystem.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.6</dfn>
          </td>
          <td>Ecosystem Actor Incubation</td>
          <td>Article</td>
          <td>This Article governs the incubation of new Ecosystem Actors to support the Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.7</dfn>
          </td>
          <td>Ecosystem Communication Channels</td>
          <td>Article</td>
          <td>This Article regulates the unified communication infrastructure for governance ecosystem
            communication. This infrastructure must include channels for inter-Star and Ecosystem Actor
            interaction.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.8</dfn>
          </td>
          <td>Ecosystem Agreements</td>
          <td>Article</td>
          <td>This Article governs Ecosystem Agreements, standardized agreements that facilitate the business
            activities of Ecosystem Actors.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9</dfn>
          </td>
          <td>Legal Resilience</td>
          <td>Article</td>
          <td>This Article governs the Resilience Fund and defines infrastructure and processes to support legal
            risk management and legal governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10</dfn>
          </td>
          <td>Resilience Research and Preparedness</td>
          <td>Article</td>
          <td>This Article defines infrastructure and processes to support resilience research and legal
            preparedness.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11</dfn>
          </td>
          <td>Ecosystem Security Infrastructure</td>
          <td>Article</td>
          <td>This Article defines ecosystem security infrastructure and processes to protect the Sky Protocol and
            its users.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.12</dfn>
          </td>
          <td>Purpose System</td>
          <td>Article</td>
          <td>This Article governs the Purpose System, which aims to fund open-source AI and software projects
            that benefit the Sky Ecosystem and public good.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.1</dfn>
          </td>
          <td>Scope Improvement</td>
          <td>Article</td>
          <td>This Article defines critical infrastructure for improving the Stability Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2</dfn>
          </td>
          <td>Core Stability Parameters</td>
          <td>Article</td>
          <td>This Article defines methodologies and processes for optimizing and aligning the Core Stability
            Parameters, which are designed to stabilize the USDS Stablecoin.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3</dfn>
          </td>
          <td>Real World Assets</td>
          <td>Article</td>
          <td>This Article governs the secure management of Real World Assets (RWA), which serve as collateral for
            the USDS Stablecoin. RWAs are enforced through legal recourse by Arranged Structures and present
            unique risks that this Article must address.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4</dfn>
          </td>
          <td>Collateral Portfolio</td>
          <td>Article</td>
          <td>This Article defines rules pertaining to Sky's Collateral Portfolio, which consists of several
            different assets to ensure liquidity.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.5</dfn>
          </td>
          <td>Surplus Buffer and Smart Burn Engine</td>
          <td>Article</td>
          <td>This Article defines key economic parameters relating to Sky Protocol Surplus, including the Surplus
            Buffer and Smart Burn Engine.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.7</dfn>
          </td>
          <td>SKY Backstop</td>
          <td>Article</td>
          <td>This Article governs the SKY Backstop. If the USDS Stablecoin becomes undercollateralized, the Sky
            Protocol will automatically generate and sell SKY to recapitalize the system.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9</dfn>
          </td>
          <td>Measures For Endgame Transition</td>
          <td>Article</td>
          <td>This Article defines temporary measures for implementing the Stability Scope during the transition
            to the Endgame State.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.1</dfn>
          </td>
          <td>Core Tokens</td>
          <td>Article</td>
          <td>The two core tokens, USDS and SKY, play the central role in the usability and tokenomics of the Sky
            Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.2</dfn>
          </td>
          <td>SkyLink</td>
          <td>Article</td>
          <td>SkyLink is a multichain system that enables native crosschain transfer of Sky Ecosystem-related
            tokens to other blockchains, including Ethereum L2s and major L1s.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.3</dfn>
          </td>
          <td>Savings Rate And Token Reward Mechanism</td>
          <td>Article</td>
          <td>This Article regulates the rewards benefitting Dai users and USDS users for holding each Stablecoin.
            DAI users can access the legacy DAI Savings Rate Mechanism. USDS users can access a built-in Savings
            Rate, as well as additional Token Reward Mechanisms including SKY and Star tokens.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4</dfn>
          </td>
          <td>Activation And Sealing Mechanisms</td>
          <td>Article</td>
          <td>This Article manages the Activation and Sealing Mechanisms that grant rewards on SKY and Star
            tokens. Activation and Sealing Mechanisms are designed to incentivize governance participation and
            long-term commitment to the Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.5</dfn>
          </td>
          <td>Emissions</td>
          <td>Article</td>
          <td>This Article governs the emissions of Star tokens. For the reward mechanisms that are multichain, 
            the rate of distribution is balanced across each SkyLink destination deployment to attempt to target 
            an equal Reward Rate per supplied USDS or Activated SKY.<br>Star Token Emissions:<br>The genesis 
            emissions of Star Tokens happens over a period of 10 years, with half of the emissions happening in 
            the first 2 years, and the emission rate halving every 2 years from then on. The Star Token genesis 
            emissions are split across 3 types of recipients: USDS holders, SKY holders that Activate (no exit 
            fee) and SKY holders that Seal (locks the SKY behind an exit fee). Each type of recipient share the 
            total Star Token emission rate among their own type.<br>Year 1 and 2:<br>Total: 2 billion Star 
            Tokens/year.<br>USDS Token Rewards: 1.4 billion Star Tokens/year.<br>SKY Activation Rewards: 300 million 
            Star Tokens/year.<br>SKY Seal Rewards: 300 million Star Tokens/year.<br>Year 3 and 4:<br>Total: 1 
            billion Star Tokens/year.<br>USDS Token Rewards: 700 million Star Tokens/year.<br>SKY Activation 
            Rewards: 150 million Star Tokens/year.<br>SKY Seal Rewards: 150 million Star Tokens/year.<br>Year 5 
            and 6:<br>Total: 500 million Star Tokens/year.<br>USDS Token Rewards: 350 million Star Tokens/year.<br>
            SKY Activation Rewards: 75 million Star Tokens/year.<br>SKY Seal Rewards: 75 million Star Tokens/year.<br>
            Year 7, 8, 9 and 10:<br>Total: 250 million Star Tokens/year.<br>USDS Token Rewards: 175 million Star 
            Tokens/year.<br>SKY Activation Rewards: 37.5 million Star Tokens/year.<br>SKY Seal Rewards: 37.5 million 
            Star Tokens/year.<br>Bootstrapping emissions:<br>Contributor token grants: 1 billion Star Tokens.<br>
            Contributor token grants are managed by Star governance controlled processes, subject to milestones and 
            performance deliverables.<br>Liquidity bootstrapping: 1 billion Star Tokens.<br>Liquidity bootstrapping 
            tokens are managed by Star governance controlled processes, subject to transparency and reporting of what 
            is happening with the assets. After a finite period of time the liquidity bootstrapping program must be 
            wound down and all remaining assets from the program must be returned to Star control.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.2</dfn>
          </td>
          <td>Brand Identity</td>
          <td>Article</td>
          <td>This Article governs the brand identity of Sky.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3</dfn>
          </td>
          <td>Integrator Program</td>
          <td>Article</td>
          <td>This Article defines an Integrator Program to incentivize third-party frontends and Stars to attract USDS users, Sky Savings Rate (SSR) users, and Star users.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.4</dfn>
          </td>
          <td>Accessibility Communication Channels</td>
          <td>Article</td>
          <td>This Article regulates accessibility assets, including communication channels and Sky's
            communication presence on external websites.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.5</dfn>
          </td>
          <td>Accessibility Campaigns</td>
          <td>Article</td>
          <td>This Article regulates accessibility campaigns.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8</dfn>
          </td>
          <td>Location Resilience</td>
          <td>Article</td>
          <td>This Article defines the location-filtering rules applicable to Ecosystem Actors that operate
            Frontends on behalf of Stars; and Ecosystem Actors that operate Frontends and receive Accessibility
            Rewards.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9</dfn>
          </td>
          <td>Launch Project</td>
          <td>Article</td>
          <td>The Launch Project is a temporary bootstrapping effort to support the deployment of Sky's early
            launch phases. This Article defines the infrastructure and processes related to the Launch Project,
            including its objectives and budget.</td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="sections">
    <h1>Sections & Primary Docs</h1>
    <table>
      <tr>
        <th>Doc No (or Temp Name)</th>
        <th>Name</th>
        <th>Type</th>
        <th>Content</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>A.0.1
              - A1 - Atlas Preamble - Definitions</dfn>
          </td>
          <td>Atlas Preamble - Definitions</td>
          <td>Section</td>
          <td>This Section contains essential definitions that are to be inherited as context for all Atlas
            documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Organizational Alignment</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Organizational Alignment</td>
          <td>Core</td>
          <td>Organizational alignment is a traditional business concept and can be described as the process of
            implementing strategies and philosophies to ensure that each member of an organization, from
            entry-level positions to executive managers, shares a common goal and vision for the success of an
            organization.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Ecosystem Intelligence</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Ecosystem Intelligence</td>
          <td>Core</td>
          <td>"Ecosystem Intelligence" characterizes a decentralized ecosystem as a single entity acting with a
            greater or lesser amount of intelligence. Ecosystem Intelligence is not merely determined by the sum
            of the intelligence of each of its constituent parts, but rather the alignment of these parts.
            Counterintuitively, very intelligent, but spiritually misaligned participants in a decentralized
            ecosystem will actually lower Ecosystem Intelligence.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Aligned Structure</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Aligned Structure</td>
          <td>Core</td>
          <td>An aligned structure is a network, ecosystem, entity, or organization that actively employs
            Alignment Engineering.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Universal Alignment</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Universal Alignment</td>
          <td>Core</td>
          <td>Universal Alignment refers to an actor's holistic understanding of their connection to their
            environment or context. This enables them to anticipate how their actions influence everything
            around them, including the second-order effects that impact them in return. This holistic
            understanding is rooted in the context of human morality, values, and the natural world. An actor
            who is universally aligned can grasp the intent behind universally aligned rules and identify
            discrepancies between the technical incentives of rules and their universal purpose. An action that
            is in opposition to Universal Alignment constitutes misalignment. Preventing misalignment is the
            fundamental objective of Alignment Engineering and Alignment Artifacts.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Universal Alignment Assumption</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Universal Alignment Assumption</td>
          <td>Core</td>
          <td>Universal Alignment is a spectrum, and actors are more or less Universally Aligned.In theory,
            Universal Alignment is absolute, but in practice it cannot be measured deterministically and thus
            practically will always be subject to debate and changes over time. Alignment Engineering aims to
            minimize the degree that actors experience their own, and others', Universal Alignment changing over
            time.The Universal Alignment Assumption holds that the outcomes of Alignment Engineering - namely,
            the Alignment Artifacts or rules themselves - always have the spirit, or underlying intent, to serve
            human values and promote the public good within a specific context.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Alignment Artifact Strength</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Alignment Artifact Strength</td>
          <td>Core</td>
          <td>The strength of an Alignment Artifact dictates the minimum level of Universal Alignment that an
            actor must possess in order to take actions that are universally aligned when interacting with the
            Artifact.Alignment Artifact Strength is enhanced by ensuring that Ecosystem Intelligence evolves
            such that each actor's self-interested incentives correspond as precisely as possible with
            requirements of Universal Alignment. This alignment minimizes the additional effort, or "inner
            incentive", that an actor must exert to overcome misalignment.The stronger an Alignment Artifact,
            the less inner incentive that an actor need possess to take actions that are universally aligned.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Inner Incentive</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Inner Incentive</td>
          <td>Core</td>
          <td>Inner incentive is the second-order incentive that a universally aligned actor uses to counteract
            the first-order (or self-interested) incentives that exist pre-Alignment Engineering or that arise
            from a misaligned structure.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Alignment Engineering</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Alignment Engineering</td>
          <td>Core</td>
          <td>Alignment Engineering is a philosophy of organizational design introduced through the Atlas. It aims
            to anchor internally sustainable Ecosystem Intelligence within Alignment Artifacts that embody
            recursive trends towards increased Alignment Artifact Strength over time.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Letter Of The Rule Vs Spirit Of The Rule</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Letter Of The Rule Vs Spirit Of The Rule</td>
          <td>Core</td>
          <td>The distinction between the "letter of the rule" and the "spirit of the rule" refers to whether an
            individual interprets and follows a rule strictly based on its precise wording, or instead also
            considers its underlying intent or larger purpose. The Universal Alignment Assumption holds that the
            underlying intent of rules always aims to serve human values and promote public benefit within a
            given context.A "letter of the rule" interpretation adheres strictly to the rule's language, often
            exploiting ambiguities or loopholes to achieve a specific outcome. This approach allows the rule's
            exact wording, even if flawed or misaligned with its goals, to dictate the result, particularly if
            it benefits the interpreter.A "spirit of the rule" interpretation seeks to comprehend the rule's
            true purpose and how it contributes to Universal Alignment, while remaining bound by the letter of
            the rule. When faced with inconsistencies or errors in the rule's language, this approach appeals to
            a pre-established method for disabling, disregarding or substituting the rule as needed to prevent
            outcomes that contradict its intended objective and the greater purpose it serves.Example:Imagine a
            large corporation discovers a loophole in the environmental regulation of its jurisdiction that
            allows them to generate profits by using a specific type of pollutant that isn't regulated as a
            greenhouse gas, but is as harmful as regulated greenhouse gasses.By exploiting the "letter of the
            rule," the corporation complies with the regulations on paper but continues to harm the environment
            and public health in practice.A universally aligned actor, such as an environmentally conscious
            competitor, would interpret the regulations based on their "spirit" or underlying purpose -
            protecting the environment and public health. Recognizing that exploiting the loophole contradicts
            the regulations' intent, the universally aligned actor would voluntarily choose not to emit the
            harmful pollutant, even though doing so might be profitable and technically legal. A universally
            aligned actor would also actively work with the government and other stakeholders to close the
            loophole and strengthen the regulations to ensure that they effectively serve their intended
            purpose, and to protect themselves from misaligned competitors.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Incentivized Alignment</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Incentivized Alignment</td>
          <td>Core</td>
          <td>Incentivized Alignment is the outcome of an actor's myopic and self-interested following of the
            letter of the rule with the first-order incentives of an Aligned Structure, but is not likely to be
            inherently Universally Aligned and lacks Inner Incentive.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Misalignment</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Misalignment</td>
          <td>Core</td>
          <td>Misalignment characterizes the state in which an actor does not possess Universal Alignment, or acts
            in a way that opposes or contradicts Universal Alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Slippery Slope Misalignment</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Slippery Slope Misalignment</td>
          <td>Core</td>
          <td>Slippery Slope Misalignment is the shortest path to misalignment where incremental misaligned acts
            are justified in various ways. These can include ignoring the potential significance and larger
            impact of acts due to their small scale; the trivial way that misalignment occurs; the good
            intentions of the actor; or the conviction that the ends justifies the means.Understanding Slippery
            Slope Misalignment means understanding that any misalignment at all is always very serious and, if
            not dealt with, results in increased risk of disequilibrium and alignment failure. In the context of
            a decentralized ecosystem such as Sky, this could mean a governance attack or financial collapse.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Scope</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Scope</td>
          <td>Core</td>
          <td>A Scope is a particular focus area of Sky or a Star. Sky Core has five Scopes:• Governance, focusing
            on Alignment Artifact interpretation and balance of powers• Support, focusing on ecosystem support,
            tools, and activities• Stability, focusing on financial stability and the core USDS Stablecoin
            product• Protocol, focusing on technical development, maintenance, and security• Accessibility,
            focusing on frontends and distribution.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Alignment Artifact</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Alignment Artifact</td>
          <td>Core</td>
          <td>Alignment Artifacts are outputs of Alignment Engineering, and can be used by universally aligned
            actors to coordinate to achieve a positive-sum outcome.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Scope Alignment Artifact (Scope Artifact)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Scope Alignment Artifact (Scope Artifact)</td>
          <td>Core</td>
          <td>A Scope Artifact is an Alignment Artifact designed to align the actions and incentives of
            participants within a specific Scope defined by the Atlas. It provides a framework for
            decision-making, resource allocation, and governance within the defined Scope.Each Scope has its own
            unique set of challenges and objectives that require a tailored approach to alignment.The strength
            of a Scope Alignment Artifact depends on how well it aligns with Universal Alignment principles, as
            well as how effectively it is communicated and understood by participants within the defined Scope.
            A strong Scope Artifact can help prevent misalignment and ensure that all participants are working
            towards a common goal for the benefit of the entire ecosystem.Scope Artifacts must not be changed
            beyond the Scope boundaries defined by the Atlas; this constitutes Slippery Slope Misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - The Atlas</dfn>
          </td>
          <td>Atlas Preamble - Definitions - The Atlas</td>
          <td>Core</td>
          <td>The Atlas is the foundational set of rules powering Sky Ecosystem. It consists of Immutable
            Documents and Adaptive Documents. The former enshrine the Spirit of the Atlas and become permanently
            immutable from the moment the Sky Ecosystem enters the Endgame State. The Adaptive Documents
            practically operationalize the Spirit of the Atlas and will be continuously improved through the Sky
            Governance process. The Immutable part of the Atlas ensures the aligned evolution of Sky: it
            mitigates the potential and actual damage caused by Slippery Slope Misalignment, which erodes the
            potency of Alignment Engineering over time.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Alignment Conserver (AC)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Alignment Conserver (AC)</td>
          <td>Core</td>
          <td>Alignment Conservers (ACs) are external entities that play a fundamental role in facilitating and
            protecting the Sky Governance process by ensuring it occurs according to the processes defined in
            the Atlas. ACs enable SKY holders to participate in Sky Governance in a manner where it is easy for
            SKY holders to make the decisions that best benefit their long-term interests as SKY holders, even
            if SKY holders overall have relatively little alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Aligned Delegate (AD)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Aligned Delegate (AD)</td>
          <td>Core</td>
          <td>Aligned Delegates (ADs) are anonymous Alignment Conservers that use Delegate Contracts to enable SKY
            holders to easily and safely delegate their SKY voting power.Because they directly control large
            amounts of incentivized SKY voting power, ADs are both highly influential and potentially risky
            actors within the governance framework. The Atlas empowers ADs and other Ecosystem Actors with the
            tools to derisk ADs' influence in the ecosystem.The primary responsibility of ADs is to use their
            delegated power to uphold the Spirit of the Atlas and maintain Universal Alignment of the Sky
            Ecosystem. ADs are subject to strict requirements enforced by the Governance Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Facilitator</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Facilitator</td>
          <td>Core</td>
          <td>Facilitators are anonymous Alignment Conservers with responsibility over specific Scopes.
            Facilitators can directly access governance processes and smart contracts to fulfill their
            responsibilities.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Star</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Star</td>
          <td>Core</td>
          <td>Formerly known as SubDAOs, Stars are smaller, specialized, decentralized ecosystems that exist
            within the broader Sky Ecosystem and are tied to the Sky Protocol. Their core design enables a
            derisked, second layer of the ecosystem to foster fast-moving, risk-adjusted innovation, growth and
            experimentation. Stars also enable delegation of responsibility and risk within specific, highly
            complex areas. In general, complexity, responsibility, decision-making authority and risk is
            off-loaded from Sky Core and pushed to the Stars, except if the Sky Atlas specifies otherwise.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Communication Channel</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Communication Channel</td>
          <td>Core</td>
          <td>Communication Channels are a critical consideration in the Atlas as they have a significant impact
            on incentivized alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Governance Scope (GOV)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Governance Scope (GOV)</td>
          <td>Core</td>
          <td>The Governance Scope Alignment Artifact codifies rules that regulate the critical balance-of-power
            processes defined in the Atlas, and adjudicate on appeals processes related to misalignment in the
            ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Support Scope (SUP)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Support Scope (SUP)</td>
          <td>Core</td>
          <td>The Support Scope Alignment Artifact codifies rules that regulate various tasks of ecosystem
            support, including governance process infrastructure and management and Star ecosystem support.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Protocol Scope (PRO)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Protocol Scope (PRO)</td>
          <td>Core</td>
          <td>The Protocol Scope Alignment Artifact codifies rules related to the core technical Sky protocol.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Stability Scope (STA)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Stability Scope (STA)</td>
          <td>Core</td>
          <td>The Stability Scope Alignment Artifact codifies the rules related to managing the core Stablecoin
            product, USDS, and supporting factors related to financial stability, such as surplus buffer and
            decentralized asset reserve.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Accessibility Scope (ACC)</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Accessibility Scope (ACC)</td>
          <td>Core</td>
          <td>The Accessibility Scope defines rules related to accessibility and distribution efforts and
            regulates user-facing frontends.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Star Scope Bounded Mutable Alignment Artifacts</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Star Scope Bounded Mutable Alignment Artifacts</td>
          <td>Core</td>
          <td>Star Scope Alignment Artifacts are internal Scope Alignment Artifacts for Stars. All Stars begin
            with a standard genesis Scope Artifact that they can modify. They can also create additional Scope
            Artifacts with new Scopes. Unlike Sky, Star Scope Artifacts have much fewer restrictions on how they
            can be modified and what strategic opportunities they can cover.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Governance Equilibrium</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Governance Equilibrium</td>
          <td>Core</td>
          <td>A Governance Equilibrium is a state in a Decentralized Governance dynamic where the governance
            process is able to remain decentralized over time with a very high degree of confidence. It requires
            redundant feedback loops that can counteract the natural incentives that push the governance process
            towards disequilibrium and centralization.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Endgame State</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Endgame State</td>
          <td>Core</td>
          <td>Endgame State is the final technical and alignment engineering state of Sky, in which all aspects of
            the ecosystem that can be made immutable, have been made immutable. The aim of the Endgame State is
            to create a highly resilient Governance Equilibrium.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Explicit Incentives</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Explicit Incentives</td>
          <td>Core</td>
          <td>Explicit Incentives are the first-order incentives that are coded into rules in Alignment Artifacts.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Implicit Incentives</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Implicit Incentives</td>
          <td>Core</td>
          <td>Implicit Incentives are the motivations or benefits that an actor can infer based on a 'letter of
            the rules' interpretation of an Alignment Artifact, and an assessment of the likelihood that these
            rules will be enforced.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Incentive Slack</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Incentive Slack</td>
          <td>Core</td>
          <td>Incentive Slack refers to the discrepancy between the explicit incentives (those clearly defined and
            communicated) and the implicit incentives (those inferred by actors) within an Aligned Structure.
            Incentive Slack can arise when coded rules are either not enforced or are too restrictive or
            impractical, leading to a pattern of bypassing these rules. When Incentive Slack is high, it creates
            the perception that rules are likely to be ignored, without regard for the spirit of the rules. This
            results in a significant risk of widespread misalignment. Incentive Slack cannot occur in an Aligned
            Structure in which actors are universally aligned and actively enforcing the rules.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Whole Weeks</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Whole Weeks</td>
          <td>Core</td>
          <td>The Atlas defines quarterly and yearly cycles that determine fixed points in time by counting whole
            weeks from the beginning of a quarter. The first whole week of a quarter is defined as the first
            week in which all days, beginning with Monday, fall within the quarter. Another definition would be
            "the week starting with the first Monday of the quarter."</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Sealing</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Sealing</td>
          <td>Core</td>
          <td>Sealing is a form of governance participation unlocked by SKY and MKR. When a user Seals their SKY
            or MKR tokens, they immediately begin to earn significant rewards. They must pay an Exit Fee to
            access their governance tokens again. This mechanism makes it more beneficial to Seal if the user
            anticipates remaining in the system long-term. Because there's a penalty for exiting, Sealing helps
            generate additional skin in the game and increases long-term alignment among ecosystem participants.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Activation</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Activation</td>
          <td>Core</td>
          <td>Activation is a less committed version of Sealing. When a user Activates their SKY tokens, they
            receive Activation Rewards, but don't have to Seal their tokens behind an Exit Fee. The Activated
            SKY can be freely Deactivated at any time.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Skylink</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Skylink</td>
          <td>Core</td>
          <td>Skylink is the Sky Ecosystem's multichain solution, connecting USDS, SKY and other Sky Ecosystem
            tokens from the Ethereum Mainnet to other chains and L2 protocols. Skylink will make all core Sky
            features available on the chains and L2s it is deployed to, including Native USDS; Native Sky
            Savings Rate; Native Token Rewards and Native 1:1 conversion between USDC and USDS. Skylink will be
            introduced after the launch of Sealing.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Target Document</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Target Document</td>
          <td>Core</td>
          <td>
            The term "Target Document" refers to the Immutable or Primary Document to which a Supporting
            Document is attached. Supporting Documents have various functions, including providing expanded
            definitions of vague or ambiguous terms in their Target Document; and providing hypothetical
            fact-patterns to illustrate the practical application of their Target Document. See <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Supporting Document
              Category</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - Definitions - Voting Power</dfn>
          </td>
          <td>Atlas Preamble - Definitions - Voting Power</td>
          <td>Core</td>
          <td>
            “Voting Power” denotes the ability of Aligned Delegates to vote on Sky governance decisions on behalf 
            of a SKY or MKR holder. SKY and MKR holders can delegate their Voting Power to an Aligned Delegate 
            through Delegate Contracts, allowing the Aligned Delegate to vote on their behalf while the SKY or 
            MKR holders retain control of their tokens.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - A2 - Atlas Preamble - General Provisions</dfn>
          </td>
          <td>Atlas Preamble - General Provisions</td>
          <td>Section</td>
          <td>This Section contains general provisions that are to be inherited as context for all Atlas
            documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</dfn>
          </td>
          <td>Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</td>
          <td>Core</td>
          <td>The next-generation Atlas is a self-contained governance infrastructure powering the Sky Ecosystem.
            It is designed to grow in tandem with the adaptive intelligence of the Ecosystem. Yet these first
            iterations of the next-generation Atlas may not sufficiently account for the critical, unforeseen
            contingencies that can arise, particularly as the Protocol is in a dynamic period of evolution. To
            ensure the Ecosystem grows in resilience and advances toward the Endgame State, it must be able to
            respond quickly to pressing changes in its environment. To facilitate this, the Scope Facilitators
            are granted broad discretionary power, given their close proximity to, and knowledge of, the Sky
            Ecosystem. Where the Atlas does not provide clear guidance on a current challenge, Scope
            Facilitators are empowered to infer the Spirit of the Atlas in such a way as to maximize Universal
            Alignment and secure the Ecosystem's growth, security and progression toward the Endgame State.
            Scope Facilitators also have the discretion to supersede existing Atlas provisions where they
            determine the latter to be unsuitable for current challenges. The discretionary power granted herein
            is temporary.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity -
              Authorization To Run Bootstrapping Governance Poll</dfn>
          </td>
          <td>Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity - Authorization To
            Run Bootstrapping Governance Poll</td>
          <td>Core</td>
          <td>
            The Governance Facilitators can run a Bootstrapping Governance Poll at any time to enable SKY
            holders to vote on needed changes to the Atlas. The Governance Facilitators can do this on their own
            initiative or at the request of another Scope Facilitator.Where feasible, the Scope Facilitators are
            encouraged to run a Governance Poll to formalize actions taken pursuant to <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity - Precedence
              Over Conflicting Provisions</dfn>
          </td>
          <td>Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity - Precedence Over
            Conflicting Provisions</td>
          <td>Core</td>
          <td>
            The broad interpretive and discretionary capacity granted Facilitators by <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity - Precedence
              Over Conflicting Provisions</dfn> takes precedence over any conflicting provisions in the Atlas.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.1
              - A1 - Spirit Of The Atlas - Universal Alignment And The Spirit Of The Atlas</dfn>
          </td>
          <td>Spirit Of The Atlas - Universal Alignment And The Spirit Of The Atlas</td>
          <td>Section</td>
          <td>The guiding principles of the Sky Ecosystem, known as the Spirit of the Atlas, form the foundation
            of the Sky Governance process. These principles are enshrined in the Immutable Documents of the
            Atlas, enabling coordination around a resilient governance equilibrium that optimizes for Universal
            Alignment between the ecosystem and its environment. The Immutable Documents take precedence over
            any other rules, decisions, or governance structures that may conflict with them. The Immutable
            Documents provide the definitive criteria for determining whether the Sky Ecosystem's rules and
            incentives are in harmony with Universal Alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.1
              - A2 - Spirit Of The Atlas - Interpretation Of The Spirit Of The Atlas</dfn>
          </td>
          <td>Spirit Of The Atlas - Interpretation Of The Spirit Of The Atlas</td>
          <td>Section</td>
          <td>Where the Immutable Documents do not contain explicit instructions about a particular topic, the
            Spirit of the Atlas should be extrapolated to maximize Universal Alignment and mitigate risks of
            slippery slope misalignment. Atlas Interpretations must be fully congruent with the Spirit of the
            Atlas and established precedent. Further, each Atlas Interpretation must set a clear precedent to
            avoid future ambiguities that could impede effective governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.1
              - Spirit Of The Atlas - Interpretation Of The Spirit Of The Atlas - General Principles</dfn>
          </td>
          <td>Spirit Of The Atlas - Interpretation Of The Spirit Of The Atlas - General Principles</td>
          <td>Core</td>
          <td>
            Scope Facilitators are authorized to conduct Atlas Interpretations to address and resolve
            ambiguities or contradictions within Atlas Documents. These interpretations may include providing
            expanded definitions for problematic terms, clarifying the practical application of specific rules
            or logic, and similar actions aimed at resolving uncertainties. Pursuant to <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</dfn>, the
            Facilitators have broad discretion in conducting Atlas Interpretations.All Atlas Interpretations
            must be documented to establish clear precedent that reflects the Spirit of the Atlas and guides
            future interpretations.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.1
              - A3 - Spirit Of The Atlas - List Of Interpretations</dfn>
          </td>
          <td>Spirit Of The Atlas - List Of Interpretations</td>
          <td>Section</td>
          <td>This Section contains a list of all settled Atlas interpretations with all necessary context.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.1
              - Spirit Of The Atlas - List Of Interpretations - Atlas Interpretations</dfn>
          </td>
          <td>Spirit Of The Atlas - List Of Interpretations - Atlas Interpretations</td>
          <td>Active Data Controller</td>
          <td>
            Atlas Interpretation precedent is defined as Active Data in <dfn>A.1.1
              - Spirit Of The Atlas - List Of Interpretations - Atlas Interpretations</dfn>. The Active Data is
            updated as follows:• The Responsible Party is the Governance Facilitators.• The Update Process must
            follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - A1 - Atlas Documents - Definition And Properties Of Atlas Documents</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents</td>
          <td>Section</td>
          <td>Atlas Documents are the basic building blocks for structuring data in the Atlas. They are organized
            as nested document trees, each with a unique Document Identifier. The first three layers contain the
            Immutable Documents, which together enshrine the Spirit of the Atlas and the core, permanent
            boundaries for how to operationalize it without risking slippery slope misalignment. In the layers
            below the Immutable Documents are the Adaptive Documents, which are continuously improved through
            the Sky Governance process. The Adaptive Documents interpret and practically operationalize the
            Spirit of the Atlas within the boundaries set by the Immutable Documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Document Identifiers</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Document Identifiers</td>
          <td>Core</td>
          <td>All Atlas Documents are distinguishable through their unique Document Identifier. The Document
            Identifier is the technical name of the Atlas Document, and it determines its position in the
            Document Tree of the Atlas. All Document Identifiers begin with a capital A, and the numbers and
            letters of the Document Identifiers are separated with dots, with each dot signifying that the Atlas
            Document is one layer deeper in the tree structure. The Document Identifiers help determine the
            position of each Atlas Document, and makes it easier to estimate the relationship between two
            different Atlas Documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Early Atlas Iteration
              Bootstrapping</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Early Atlas Iteration Bootstrapping
          </td>
          <td>Core</td>
          <td>In the first iterations of the Atlas, formal Atlas Document Identifiers will not yet be implemented
            for all Document Types.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Atlas Document Properties</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Atlas Document Properties</td>
          <td>Core</td>
          <td>All Atlas Documents have five (5) standard properties that provide key information about them. The
            subdocuments of this document specify the characteristics of each of the five (5) standard
            properties.The standard properties of Atlas Documents should be listed in the following order:1.
            Name2. Version3. Last Modified4. Type5. Components</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Name Property</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Name Property</td>
          <td>Core</td>
          <td>The Name property is assigned to each Atlas Document to provide a human-readable name, making it
            easier for humans to identify the document and understand its purpose and function at a glance. This
            Name serves as an abstracted overview of the document's content, distinguishing it from other
            documents in a user-friendly manner.However, for data management and record-keeping purposes, the
            official designation of an Atlas Document is its unique Document Identifier. As a result, the Name
            property can be modified with no substantive consequences.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Version Property</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Version Property</td>
          <td>Core</td>
          <td>The Version property of Atlas Documents specifies how many times it has been modified. Every time an
            Atlas Document is modified, the newly modified Document gets its version number incremented, and the
            old version is recorded as a historical version with a Document Identifier equivalent to its version
            number. As an example, if an Atlas Document located at 1.1.1 with version number 3 is modified, the
            new Atlas Document will have version number 4, and the old Atlas Document will be located at
            1.1.1.v3. This ensures all historical versions of Atlas documents are retained permanently as a part
            of the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Last Modified Property</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Last Modified Property</td>
          <td>Core</td>
          <td>The Last Modified property specifies the exact date and time when the Atlas Document was updated to
            its current version. It is recorded in the UTC timezone and follows the format
            'YYYY-MM-DD-HH:MM:SS'. This property provides a timestamp for tracking modifications and ensuring
            transparency in the governance and update process. When an Atlas Document is at version 1, the Last
            Modified property denotes when the Atlas Document was created.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Type Property</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Type Property</td>
          <td>Core</td>
          <td>
            The Type property of Atlas Documents specifies the function, characteristic and purpose of the Atlas
            Document. The Type determines the data that must be contained in the Components Property. The
            various Document Types and their characteristics are specified in <dfn>A.1.2
              - A2 - Atlas Documents - Structure, Categories, And Types Of Atlas Documents</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Definition And Properties Of Atlas Documents - Components Property</dfn>
          </td>
          <td>Atlas Documents - Definition And Properties Of Atlas Documents - Components Property</td>
          <td>Core</td>
          <td>The Components property of Atlas Documents contains an object that specifies the data components of
            the Atlas Document as nested properties. The Components of an Atlas Document is determined by its
            Type. Some Document Types have no Components, in which the object is just empty. An Atlas Document
            with Components must always have all of its components properly filled according to the requirements
            defined by its Type Specification. Some documents have custom logic for how their Components behave,
            and this custom logic is specified through a special reserved component property called 'Custom'.
            Atlas Documents of Types with specified custom logic components can have variable number of
            components, and different characteristics of each component, for each instance of the Type. Custom
            components are always appended to the end of the list of components.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - A2 - Atlas Documents - Structure, Categories, And Types Of Atlas Documents</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents</td>
          <td>Section</td>
          <td>This Section defines the basic structure of Atlas Documents and their specifications, including
            their general categories and individual types, their syntax and content requirements, and their
            functions and composability in the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Atlas Document Type
              Categories</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Atlas Document Type
            Categories</td>
          <td>Core</td>
          <td>The Atlas Document Types can be broadly categorized into distinct groups that determine how they are
            modified and how they function in the Atlas. At the highest level there are the Immutable Documents
            and the Adaptive Documents. The Adaptive Documents are further subdivided into three (3) distinct
            groups: Primary Documents, Supporting Documents, and Accessory Documents. The category of an Atlas
            Document can be inferred from its Document Identifier, as each group has unique and non-overlapping
            rules for validity of their Document Identifiers.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Immutable Document
              Category</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Immutable Document Category
          </td>
          <td>Core</td>
          <td>Immutable Documents are the most important part of the Atlas: they record the Spirit of the Atlas,
            detailing the vision, purpose and unalienable principles of Sky. In the transition to Endgame State,
            Immutable documents remain modifiable by the governance processes specified elsewhere in the Atlas.
            Once the Endgame State has been reached, however, Immutable Documents become fully immutable, i.e.,
            they can never be changed. Immutable Documents have Document identifiers that are at most three (3)
            layers deep in the Document Tree.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Primary Document
              Category</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Primary Document Category
          </td>
          <td>Core</td>
          <td>Primary Documents are the cornerstone of the Adaptive Documents and ensure the practical
            operationalization and resilience of the Atlas. They detail specific, practical principles, rules,
            processes and roles necessary to operationalize the Spirit of the Atlas. In the transition to
            Endgame, Primary Documents can be modified with no restrictions, using the governance processes
            specified elsewhere in the Atlas. Once the Endgame State is reached, Primary Documents generally
            must be modified as slowly as possible, and as little as possible while remaining fully adapted to
            the external environment. Primary Documents have Document Identifiers that are 4 layers or deeper in
            the Document Tree, and cannot contain 0's.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Supporting Document
              Category</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Supporting Document Category
          </td>
          <td>Core</td>
          <td>Supporting Documents are attached to Immutable Documents and Primary Documents (called their "Target
            Document"). They provide context and in some cases advanced functionality to the Target Documents,
            enabling them to be fully operationally effective and unambiguous. The different Types of Supporting
            Documents have different functions. Some Supporting Document types are required for all Immutable
            Documents and Primary Documents; while others are only required for certain Primary Document Types.
            Most Supporting Document types can be freely modified through the governance processes specified
            elsewhere in the Atlas. The Active Data Supporting Document type can be modified in real time by
            processes outside of said governance processes. Supporting Documents always have Document
            Identifiers that contain at least one 0.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Accessory Document
              Category</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - Accessory Document Category
          </td>
          <td>Core</td>
          <td>Accessory Documents provide accessory data to every other Atlas Document type. There are two types
            of Accessory Documents: Translation Documents and Archive Documents. Translation Documents can be
            edited directly by Facilitators, while Archive Documents are Immutable. Accessory Documents always
            have Document Identifiers that contain letters in addition to the standard 'A' prefix of all Atlas
            Document Identifiers.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - List Of Document Types
              And Their Specifications</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - List Of Document Types And
            Their Specifications</td>
          <td>Core</td>
          <td>The subdocuments herein are Type Specification Documents defining the standardized characteristics
            and requirements that all Atlas Documents must adhere to in order to be considered valid and
            aligned.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - A3 - Atlas Documents - Conflict Resolution</dfn>
          </td>
          <td>Atlas Documents - Conflict Resolution</td>
          <td>Section</td>
          <td>The Governance Facilitators are responsible for evaluating and resolving community appeals regarding
            Atlas document misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Conflict Resolution - Request for Review</dfn>
          </td>
          <td>Atlas Documents - Conflict Resolution - Request for Review</td>
          <td>Core</td>
          <td>
            Where a potential instance of Atlas document misalignment is perceived, community members may submit
            a Request for Review to the Governance Facilitators. This Request for Review should be posted in the
            Sky Forum. The Request for Review need not follow any specific template. Pursuant to <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</dfn>, the
            Governance Facilitators have broad discretion in evaluating and resolving such Requests for Review.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.3
              - A1 - Governance Accessibility - Atlas Operational Platform</dfn>
          </td>
          <td>Governance Accessibility - Atlas Operational Platform</td>
          <td>Section</td>
          <td>This Section must define infrastructure and requirements pertaining to the development and
            deployment of the Atlas Operational Platform. The Atlas Operational Platform must enable accessible
            participation in the Governance Scope. It should provide a comprehensive and user-friendly overview
            of all data and processes relevant to the Governance Scope, ensuring legibility, transparency, and
            easy verification of processes and decisions.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - ACs Subject To Strict Requirements</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - ACs Subject To Strict Requirements</td>
          <td>Section</td>
          <td>Alignment Conservers are subject to strict requirements due to their critical role in safeguarding
            the resilience and alignment of the Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - Role Of Governance Facilitators</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - Role Of Governance Facilitators</td>
          <td>Core</td>
          <td>The Governance Facilitators must be vigilant in enforcing all rules applicable to Alignment
            Conservers. Governance Facilitators must take prompt action against Alignment Conservers if they
            break rules specified in the Atlas, or otherwise act misaligned.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - ACs Must Safeguard The Spirit Of The Atlas</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - ACs Must Safeguard The Spirit Of The Atlas</td>
          <td>Section</td>
          <td>Alignment Conservers must always act to preserve the Spirit of the Atlas and to protect Sky
            Ecosystem against all forms of corruption, organizational drift, and other misalignment threats.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - Universal Alignment Requirements</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - Universal Alignment Requirements</td>
          <td>Section</td>
          <td>Alignment Conservers must operate only within the clearly delineated processes and frameworks of the
            Immutable Documents. ACs are strictly prohibited from colluding or secretly organizing to circumvent
            or undermine the Spirit of the Atlas. Any action of an Alignment Conserver that disrupts the
            governance dynamic of Sky is considered misalignment, as is any inaction that allows such violations
            to occur.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - Standard of Proof In Universal Alignment
              Controversies</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - Standard of Proof In Universal Alignment
            Controversies</td>
          <td>Section</td>
          <td>Alignment Conservers are held to the highest standard when judging whether their actions are
            Universally Aligned.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - ACs Can Be Operationally Active In Only One
              Role At A Time</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - ACs Can Be Operationally Active In Only One Role At
            A Time</td>
          <td>Section</td>
          <td>An Alignment Conserver can assume one of two roles: Aligned Delegate (AD) and Facilitator. ACs may
            only be operationally active in a single AC role and may not simultaneously assume multiple AC roles
            or other ecosystem roles such as Ecosystem Actors.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - Temporary Exception for Facilitator "Ecosystem"</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - Temporary Exception for Facilitator "Ecosystem"</td>
          <td>Core</td>
          <td>The Facilitator "Ecosystem" is temporarily exempt from the general rule prohibiting Alignment Conservers from being operationally active in multiple ecosystem roles. “Ecosystem” will continue to act in the Facilitator role as well as provide operational services as an Ecosystem Actor. This exception must be resolved as soon as it is reasonably possible to do so.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - Exception for ADs Contributing To Atlas Core
              Development</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - Exception for ADs Contributing To Atlas Core
            Development</td>
          <td>Core</td>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Atlas Workstreams</dfn> is an
            exception to the general rule prohibiting Alignment Conservers from being operationally active in
            multiple ecosystem roles.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - ACs Subject To Both General And Role-specific
              Requirements</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - ACs Subject To Both General And Role-specific
            Requirements</td>
          <td>Section</td>
          <td>
            An Alignment Conserver is fully responsible for meeting all requirements tied to the general AC
            role, which requirements are specified in this Article. In addition, Aligned Delegates and
            Facilitators must adhere to the specific requirements tied to their specialized roles. These
            specific requirements are detailed in <dfn>A.1.5</dfn> and <dfn>A.1.6</dfn>. Breaching
            these role-specific requirements and responsibilities is misalignment equivalent to breaching the
            general AC-requirements.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - AC Requirements Of Anonymity And High
              Operational Security</dfn>
          </td>
          <td>Alignment Conservers - Powers And Constraints - AC Requirements Of Anonymity And High Operational
            Security</td>
          <td>Section</td>
          <td>The Alignment Conserver roles of Facilitator and Aligned Delegate require anonymity and high levels
            of operational security. Breaches of these anonymity and operational security requirements are
            considered serious misalignment. In the event of such breaches, the known identities of individuals
            holding these AC roles shall be promptly derecognized, and they will be barred from further
            participation as Alignment Conservers.</td>
        </tr>
        <tr>
          <td><dfn>A.1.4 - Alignment Conservers - Powers And Constraints - Exemption From Facilitator Anonymity Requirement</dfn></td>
          <td>Alignment Conservers - Powers And Constraints - Exemption From Facilitator Anonymity Requirement</td>
          <td>Core</td>
          <td>The Facilitator “Ecosystem” is exempt from the anonymity requirement, as well as the requirement of high levels of operational security insofar as the latter requirement relates to maintaining anonymity. This exemption applies solely to the Facilitator “Ecosystem”, as they onboarded into the role prior to the ratification of Atlas v1 (March 27, 2023), which introduced the anonymity requirement for Facilitators.
          This exemption applies to limit the effect of the following provisions: <dfn>A.1.6 - Facilitators - Facilitator Operational Security - Facilitators Must Maintain High Level Of Operational Security 1</dfn>; <dfn>A.1.6 - Facilitators - Facilitator Operational Security - Derecognition Required Where Facilitator Operational Security Is Compromised</dfn>; <dfn>A.1.6 - Facilitators - Facilitator Operational Security - Facilitators Must Err On Side Of Caution</dfn>; and <dfn>A.0.1 - Atlas Preamble - Definitions - Facilitator</dfn>.
          This limited exemption takes precedence over any conflicting provisions in the Atlas.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Swift Action Is Required
              From Facilitators To Redress AC Misalignment</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Swift Action Is Required From
            Facilitators To Redress AC Misalignment</td>
          <td>Section</td>
          <td>
            The Facilitators must act swiftly when an AC is suspected of breaching the requirements defined in
            this Article, or the requirements defined in the Articles specific to the Aligned Delegate or
            Facilitator role. Any Scope Facilitator has the authority to formally raise an allegation of AC
            misalignment with the Governance Facilitators, which then obligates the latter to initiate a formal
            adjudication pursuant to <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>.A
            Facilitator's failure to act promptly in addressing credible evidence of AC misalignment or to
            mitigate the risk of misalignment spreading among ACs is considered an act of misalignment itself.
            Formal allegations of such failure must be adjudicated by the Governance Facilitators pursuant to
            the same process referenced in the above-cited document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</td>
          <td>Section</td>
          <td>The Governance Facilitators are responsible for adjudicating formal allegations of misalignment or
            operational security breaches brought against Alignment Conservers (ACs).In the adjudication of
            these matters, the Governance Facilitators are mandated to hold ACs to the highest standard of
            Universal Alignment, without granting them the benefit of the doubt.The adjudication process is
            further defined in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Opportunity to Respond</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Opportunity to Respond</td>
          <td>Core</td>
          <td>As part of the formal adjudication of AC misalignment or operational security breach, the Governance
            Facilitators must provide the individual/entity subject to the allegation with an opportunity to
            respond.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Imposing Appropriate
              Penalty</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Imposing Appropriate Penalty</td>
          <td>Core</td>
          <td>If the Governance Facilitators conclude that the allegation of misalignment or operational security
            breach was justified, they can impose an appropriate penalty up to and including derecognition of
            the Alignment Conserver.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Warnings Appropriate For
              Mild Breach</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Warnings Appropriate For Mild
            Breach</td>
          <td>Core</td>
          <td>In cases of very mild "slippery slope" breaches of the Alignment Conserver requirements, a formal
            warning may be given and recorded in the subdocuments herein. Where such a breach was the first
            instance of misalignment by the Alignment Conserver, no disciplinary measures beyond a formal
            warning are required.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Warning Notice</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Warning Notice</td>
          <td>Core</td>
          <td>Formal warnings are issued publicly, and justification and reasoning must be provided by the issuing
            Governance Facilitator.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Warning Recording</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Warning Recording</td>
          <td>Active Data Controller</td>
          <td>
            Formal warnings are recorded by adding the identity and known aliases or associated entities to the
            Active Data list in <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - List of Formally Warned
              Alignment Conservers</dfn>.The Active Data is updated as follows:• The Responsible Party is the
            Governance Facilitators.• The Update Process must follow the protocol for 'Alignment Conserver
            Changes'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Mandated Derecognition For
              Severe Breaches</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Mandated Derecognition For Severe
            Breaches</td>
          <td>Core</td>
          <td>In cases where severe actions or violations occur that can be reasonably interpreted as Governance
            Attacks, the Alignment Conserver must be promptly derecognized by the Facilitators.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Issuing of Public Report</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Issuing of Public Report</td>
          <td>Core</td>
          <td>Where feasible, the Governance Facilitators should issue a report at the conclusion of their
            adjudication. The report should be posted on the Sky Forum and should summarize the findings and
            reasoning supporting their decision.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Governance Facilitator Is
              Subject Of Misalignment Allegation</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Governance Facilitator Is Subject
            Of Misalignment Allegation</td>
          <td>Core</td>
          <td>If a Governance Facilitator is the subject of an allegation of misalignment or operational security
            breach, the adjudication process may be initiated by a Responsible Facilitator from any Scope.
            Additionally, in such cases, a Responsible Facilitator from a Scope other than the Governance Scope
            is authorized to coordinate or otherwise actively participate in the adjudication process to ensure
            impartiality.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</td>
          <td>Section</td>
          <td>Derecognition is the ultimate accountability measure for misalignment and entails permanently
            removing the individual or entity from their role as an Alignment Conserver. An individual/entity
            who has been derecognized from a Facilitator role is not eligible to serve as an Aligned Delegate,
            and vice versa. The subdocuments herein define rules and processes related to Alignment Conserver
            Derecognition.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Derecognition Notice</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Derecognition Notice</td>
          <td>Core</td>
          <td>Derecognition notices are issued publicly, and justification and reasoning must be provided by the
            issuing Governance Facilitator.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Derecognition Recording</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Derecognition Recording</td>
          <td>Active Data Controller</td>
          <td>
            Derecognitions of Alignment Conservers are recorded by adding the identity and known aliases or
            associated entities to <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Derecognized Alignment
              Conservers</dfn>.The Active Data is updated as follows:• The Responsible Party is the Governance
            Facilitators.• The Update Process must follow the protocol for 'Alignment Conserver Changes'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - A1 - Aligned Delegates - Governance Facilitator Responsibilities</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities</td>
          <td>Section</td>
          <td>This Section defines specific responsibilities of Governance Facilitators with regard to Aligned
            Delegates.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - Mandate to Enforce Rules</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - Mandate to Enforce Rules</td>
          <td>Core</td>
          <td>The Governance Facilitators must enforce all rules governing Aligned Delegates.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - Mandate to Maintain Application
              Process</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - Mandate to Maintain Application
            Process</td>
          <td>Core</td>
          <td>The Governance Facilitators must oversee and maintain the process by which individuals/entities
            apply for recognition as an Aligned Delegate.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process</td>
          <td>Core</td>
          <td>Applicants must be formally recognized as Aligned Delegates by the Governance Facilitators upon
            fulfilling all requirements defined in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
              Contract Deployment</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process - Contract
            Deployment</td>
          <td>Core</td>
          <td>
            To be recognized as an Aligned Delegate, the applicant must deploy at least one (1) Delegate
            Contract. This should be done prior to posting their AD Recognition Submission Message pursuant to
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
              Submission Message</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
              Submission Message</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process - Submission
            Message</td>
          <td>Core</td>
          <td>To be recognized as an Aligned Delegate, the applicant must publicly post an AD Recognition
            Submission Message on the Sky Forum. This AD Recognition Submission Message must contain links to
            two (2) cryptographically signed messages as specified in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
              Cryptographically Signed Message By Ethereum Address Controlling Delegate Contract(s)</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
            Cryptographically Signed Message By Ethereum Address Controlling Delegate Contract(s)</td>
          <td>Core</td>
          <td>The first message must be cryptographically signed by the applicant's Ethereum address controlling
            the deployed Delegate Contract(s). The cryptographically signed message demonstrates that the
            applicant controls the Ethereum address that, in turn, controls their deployed Delegate
            Contract(s).This first message must include the following elements to be valid:1. A title of
            "Aligned Delegate Recognition - Delegate Contract", and2. A timestamp recording the time and date
            that the message was cryptographically signed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
              Cryptographically Signed Message By Ecosystem Actor Ethereum Address</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
            Cryptographically Signed Message By Ecosystem Actor Ethereum Address</td>
          <td>Core</td>
          <td>The second message must be cryptographically signed by the applicant's Ecosystem Actor Ethereum
            address.This second message must include the following elements to be valid:1. A title of "Aligned
            Delegate Recognition - Ecosystem Actor Address", and2. A timestamp recording the time and date that
            the message was cryptographically signed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Submission Message
              Template</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - AD Submission Message Template</td>
          <td>Core</td>
          <td>The AD Recognition Submission Message on the Sky Forum must follow this template:Title: AD
            Recognition Submission[Ecosystem Actor Ethereum address][Ethereum address of Delegate
            Contract][Cryptographically signed AD Recognition Submission Message from the Ethereum address
            controlling Delegate Contract][Cryptographically signed AD Recognition Submission Message from the
            Ecosystem Actor Ethereum address, where this address is not an address controlling a Delegate
            Contract]</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - List Of Recognized Aligned
              Delegates</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - List Of Recognized Aligned Delegates
          </td>
          <td>Active Data Controller</td>
          <td>
            The list of currently recognized Aligned Delegates is defined as Active Data in <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - Current Aligned
              Delegates</dfn>.The Active Data is updated as follows:• The Responsible Party is the Governance
            Facilitators.• The Update Process must follow the protocol for 'Alignment Conserver Changes'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Delegate Contracts - In General</dfn>
          </td>
          <td>Aligned Delegates - Delegate Contracts - In General</td>
          <td>Section</td>
          <td>Delegate Contracts are smart contracts that can receive delegated voting power from SKY holders and
            Sealing users.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Eligibility To Receive Budget</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Eligibility To Receive Budget</td>
          <td>Section</td>
          <td>Aligned Delegates are eligible to receive a budget from the Sky Protocol 
            if they fulfill two (2) requirements: 1) They rank among the top Aligned Delegates based on total Voting 
            Power delegated to their Delegate Contract, and 2) They fulfill specific participation requirements defined 
            in this Article.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Prime Delegates</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Prime Delegates</td>
          <td>Section</td>
          <td>
            Aligned Delegates with the greatest delegated Voting Power are designated as Prime Delegates and receive a budget. 
            The number of Prime Delegate slots is specified in <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Number of Prime Delegate
              Slots</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Number of Prime Delegate Slots</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Number of Prime Delegate Slots</td>
          <td>Section</td>
          <td>The six (6) Aligned Delegates with the greatest delegated Voting Power are the Prime Delegates.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Budget For Prime Delegate
              Slots</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Budget For Prime Delegate Slots</td>
          <td>Section</td>
          <td>
            Each Prime Delegate (PD) slot is allocated a continually accruing budget, the amount of which is
            specified in <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Budget Amount For Prime Delegate
              Slots</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Budget Amount For Prime Delegate
              Slots</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Budget Amount For Prime Delegate Slots
          </td>
          <td>Core</td>
          <td>The budget for each Prime Delegate slot is 48,000 USDS per year.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - AD Buffer</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - AD Buffer</td>
          <td>Section</td>
          <td>The AD Buffer is an account of USDS that begins accumulating funds when an Aligned Delegate attains Prime Delegate status. 
              The budget allocated to the AD is deposited into the AD Buffer. Funds within the AD Buffer cannot be accessed or spent until 
              they reach a minimum threshold equivalent to one (1) month's budget allocation.
              Once this threshold is met, the AD will receive payouts from the AD Buffer to the address that controls the AD Delegate 
              Contract. ADs may use this budget for various purposes, including personal compensation, compensation for team members, 
              research expenses, and other relevant activities.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - AD Monthly Compensation Cycle</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - AD Monthly Compensation Cycle</td>
          <td>Core</td>
          <td>Aligned Delegates are eligible to receive payments from their AD Buffers in a monthly compensation cycle. The Governance 
            Facilitators are responsible for calculating the payout due to each Aligned Delegate.
            This includes calculating:
              1. the Aligned Delegates ranked as Prime Delegate on a daily basis;
              2. the budget to be deposited into each Aligned Delegate's AD Buffer, which is modified pursuant to voting and communication metrics;
              3. the balance of each Aligned Delegate’s AD Buffer; and
              4. the amount to be paid out to each Aligned Delegate.
            Once calculated by the Governance Facilitators, AD payouts are bundled into the next Executive Vote.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - AD Buffer And Loss Of Budget</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - AD Buffer And Loss Of Budget</td>
          <td>Section</td>
          <td>If an AD loses its budget due to losing its Prime Delegate rank, the full contents of the AD Buffer can be paid out in the 
              next monthly compensation cycle, except as specified in <dfn>A.1.5 - Aligned Delegates - Budget And Participation 
              Requirements - Payout Limitations For ADs Triggering Atlas Edit Weekly Cycle Proposals</dfn>.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - 
              Payout Limitations For ADs Triggering Atlas Edit Weekly Cycle Proposals</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Payout Limitations 
            For ADs Triggering Atlas Edit Weekly Cycle Proposals</td>
          <td>Core</td>
          <td>If an AD has triggered an Atlas Edit Weekly Cycle Proposal pursuant to <dfn>A.1.11 - Weekly Governance Cycle - Atlas Edit 
            Weekly Cycle - Triggering Requirement</dfn>, no payouts may be made that would reduce their AD Buffer below one (1) month’s 
            worth of the budget specified in <dfn>A.1.5 - Aligned Delegates - Budget And Participation Requirements - Budget Amount For 
            Prime Delegate Slots</dfn> until the Proposal has been voted on or rejected by the Governance Facilitators for misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - AD Buffer Used For Whistleblower
              Bounties</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - AD Buffer Used For Whistleblower
            Bounties</td>
          <td>Section</td>
          <td>
            The AD Buffer also serves as collateral for a whistleblower bounty. This bounty is capped at half of
            one month's budget allocation. This bounty is payable to a whistleblower who responsibly provides
            evidence that is useful to the Facilitators' investigation of either 1) misalignment by the AD, or
            2) a breach of the AD's operational security or privacy.See <dfn>A.1.5
              - Aligned Delegates - Misalignment Handling - Whistleblower Bounty</dfn>; and <dfn>A.1.5
              - Aligned Delegates - Operational Security - Whistleblower Bounty</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Budget Contingency</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Budget Contingency</td>
          <td>Section</td>
          <td>
            A Prime Delegate's allocated budget can be reduced if they do not fully comply with the
            participation requirements defined in this Article at <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Voting-Activity Metrics</dfn>, <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Voting-Communication Metrics</dfn>, and <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Emergency Communications Requirement</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Voting-Activity Metrics</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Voting-Activity Metrics</td>
          <td>Section</td>
          <td>The budget stream allocated to a Prime Delegate (PD) is modified based on their voting-activity 
            metrics over the past six (6) months. This budget modification takes into account the overall 
            participation of the Prime Delegate in all votes they are eligible to cast as an Aligned Delegate
             (AD). If a PD participates in less than 95% of all eligible votes within the last six (6) months,
            their PD budget stream is reduced. The reduction is applied on a proportional linear scale: for
            every percentage point below 95% voting activity, the PD’s budget is reduced correspondingly.
            Should a PD’s voting activity fall to 75% of all eligible votes within the last six (6) months, 
            they become completely ineligible to receive PD income. Their PD rank, and the budget eligibility 
            associated with that rank, is transferred to the next highest-ranking AD, as determined by total 
            amount of SKY delegated to their Delegate Contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Voting-Communication Metrics</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Voting-Communication Metrics</td>
          <td>Section</td>
          <td>The budget stream allocated to a Prime Delegate (PD) is modified based on their voting-communication
             metrics over the past six (6) months. An AD is required to provide an explanation for each vote they 
             participate in. This budget modification takes into account the Prime Delegate’s fulfillment of this 
             voting-communication requirement in all votes they are eligible to cast as an Aligned Delegate (AD).
             If a PD provides the required voting-communication on less than 95% of all eligible votes within the 
             last six (6) months, their PD budget stream is reduced. The reduction is applied on a proportional 
             linear scale: for every percentage point below 95% voting-communication activity, the PD’s budget is 
             reduced correspondingly. Should a PD’s voting-communication activity fall to 75% of all eligible votes 
             within the last six (6) months, they become completely ineligible to receive PD income. Their PD rank,
             and the budget eligibility associated with that rank, is transferred to the next highest-ranking AD,
            as determined by total amount of SKY delegated to their Delegate Contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Emergency Communications Requirement</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Emergency Communications Requirement</td>
          <td>Section</td>
          <td>The budget stream allocated to a Prime Delegate (PD) is modified based on their correct usage of 
            required tools for emergency communications.
            Should a PD fail to correctly use the required communications tools, they become completely ineligible 
            to receive PD income. Their PD rank, and the budget eligibility associated with that rank, is transferred
            to the next highest-ranking AD, as determined by total amount of SKY delegated to their Delegate Contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Signal Account Requirement</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Signal Account Requirement</td>
          <td>Core</td>
          <td>PDs are required to maintain an active Signal account to facilitate communications related to emergency / urgent situations. 
              This requirement applies regardless of whether a PD has been appointed to the Emergency Response Group. See <dfn>A.1.8 - 
              Emergency Response System - Emergency Response - Emergency Response Signal Group</dfn>. PDs must provide their Signal 
              username to the Governance Facilitators.
              The Governance Facilitators are responsible for maintaining an internal registry of PDs’ Signal accounts. Because the ranked 
              PDs are continually changing, the Governance Facilitators must ensure that the internal registry is maintained on a frequent 
              basis. The Governance Facilitators must check the active status of the PDs’ Signal accounts by sending test messages and 
              confirming the PDs’ timely response; this must be done regularly, on a schedule known only to the Governance Facilitators. 
              If a PD fails to timely respond to the test messages, the Governance Facilitators must remove them from PD status.</td>
        </tr>        
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Atlas Workstreams</dfn>
          </td>
          <td>Aligned Delegates - Budget And Participation Requirements - Atlas Workstreams</td>
          <td>Section</td>
          <td>
            Aligned Delegates (ADs) are permitted to concurrently participate in workstreams related to Atlas
            Core Development, and to receive budgets for this purpose. Such workstreams can include research,
            data collection, data processing, data review, drafting, peer review, etc. This document constitutes
            an exception to <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - ACs Can Be Operationally Active In Only One
              Role At A Time</dfn>, which generally prohibits Alignment Conservers from being operationally
            active in multiple ecosystem roles.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - A4 - Aligned Delegates - Kickbacks Prohibited</dfn>
          </td>
          <td>Aligned Delegates - Kickbacks Prohibited</td>
          <td>Section</td>
          <td>Aligned Delegates are not allowed to provide "kickbacks" from their compensation to SKY holders who
            delegate to them. Violation of this requirement constitutes misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Misalignment Handling - Swift Action Is Required From Facilitators To
              Redress AD Misalignment</dfn>
          </td>
          <td>Aligned Delegates - Misalignment Handling - Swift Action Is Required From Facilitators To Redress AD
            Misalignment</td>
          <td>Section</td>
          <td>
            The Facilitators must act swiftly when an AD is suspected of breaching the requirements defined in
            this Article, or the requirements defined in <dfn>A.1.4</dfn>.Any Scope
            Facilitator has the authority to formally raise an allegation of AD misalignment with the Governance
            Facilitators, which then obligates the latter to initiate a formal adjudication pursuant to <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>.A
            Facilitator's failure to act promptly in addressing credible evidence of AD misalignment or to
            mitigate the risk of misalignment spreading among ADs is considered an act of misalignment itself.
            Formal allegations of such failure must be adjudicated by the Governance Facilitators pursuant to
            the same process referenced in the above-cited document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Misalignment Handling - Whistleblower Bounty</dfn>
          </td>
          <td>Aligned Delegates - Misalignment Handling - Whistleblower Bounty</td>
          <td>Section</td>
          <td>
            If the Governance Facilitators find that an AD has conducted a misaligned act warranting financial
            penalties or derecognition, that AD's Buffer will be confiscated and used as a whistleblower bounty
            to compensate any individual/entity who responsibly provided useful data, information or evidence
            that was helpful to the Facilitators' adjudication.The whistleblower bounty is subject to the
            restrictions specified in <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - AD Buffer Used For Whistleblower
              Bounties</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Mandate To Maintain High Level of Operational Security</dfn>
          </td>
          <td>Aligned Delegates - Mandate To Maintain High Level of Operational Security</td>
          <td>Section</td>
          <td>Aligned Delegates (ADs) are required to maintain a high level of operational security, adhering to
            best practices in privacy, cybersecurity, and physical resilience. These measures must be
            implemented at a level that sufficiently safeguards the Sky Ecosystem from physical risk posed by
            the potential for attacks against ADs. ADs' operational security protocols should be regularly
            reviewed and updated to address emerging risks and ensure continuous protection of the ecosystem.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Operational Security - Derecognition Required Where AD Operational
              Security Is Compromised</dfn>
          </td>
          <td>Aligned Delegates - Operational Security - Derecognition Required Where AD Operational Security Is
            Compromised</td>
          <td>Section</td>
          <td>
            All Facilitators must act swiftly to investigate ADs who are suspected of breaching their
            requirements regarding operational security and privacy.Any Scope Facilitator has the authority to
            formally raise an allegation concerning AD breach of operational security with the Governance
            Facilitators, which then obligates the latter to initiate a formal adjudication pursuant to <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>.If
            there is clear evidence or significant suspicion that the operational security of an AD has been
            compromised, or that they have failed to follow best practice or otherwise made operational security
            errors, the Governance Facilitators must promptly derecognize the AD.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Operational Security - Whistleblower Bounty</dfn>
          </td>
          <td>Aligned Delegates - Operational Security - Whistleblower Bounty</td>
          <td>Section</td>
          <td>
            Where a whistleblower responsibly provided useful information for determining that the operational
            security of an AD was compromised, part of the AD Buffer can be confiscated and used as a
            whistleblower bounty. See <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - AD Buffer Used For Whistleblower
              Bounties</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Operational Security - Facilitators Must Err On Side Of Caution</dfn>
          </td>
          <td>Aligned Delegates - Operational Security - Facilitators Must Err On Side Of Caution</td>
          <td>Section</td>
          <td>
            Facilitators are required to err on the side of caution and take action whenever there is any real
            possibility that the operational security of an Aligned Delegate (AD) is compromised. Facilitators
            are afforded significant discretion in making judgement calls related to operational security
            standards for ADs. Abuse of this power is severe misalignment. Any allegations of this abuse of
            power must be adjudicated by the Governance Facilitators pursuant to the process defined in <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - A7 - Aligned Delegates - Emergency Contact Mechanism</dfn>
          </td>
          <td>Aligned Delegates - Emergency Contact Mechanism</td>
          <td>Section</td>
          <td>
            Aligned Delegates must safeguard the security of the Sky Protocol through the Executive Vote process.
            To deal with emergencies related to Executive Votes, ADs are required to sign up for the approved
            emergency contact mechanism specified in <dfn>A.1.8 - Emergency Response System - Emergency Response
            - Approved Emergency Contact Mechanisms</dfn>. ADs must strictly adhere to all onboarding procedures
            and usage instructions associated with this emergency contact mechanism. ADs that fail to do so will
            be considered in misalignment and will be derecognized.<br> The high operational security requirements
            applicable to ADs extend to their use of the emergency contact mechanism.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - A1 - Facilitators - Bound by Scope Requirements And Rules</dfn>
          </td>
          <td>Facilitators - Bound by Scope Requirements And Rules</td>
          <td>Section</td>
          <td>
            When a Facilitator has responsibility for a given Scope, they are generally required to follow all
            of that Scope's associated rules, requirements and processes. In the transition to Endgame, this
            provision is subject to the discretionary capacity granted to Scope Facilitators in <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Enforcement of Facilitator Rules</dfn>
          </td>
          <td>Facilitators - Enforcement of Facilitator Rules</td>
          <td>Core</td>
          <td>
            All rules governing Facilitators are enforced by the Governance Facilitators. Where a Governance
            Facilitator is acting in misalignment, any active Scope Facilitator is empowered to initiate a
            formal adjudication pursuant to <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Governance Facilitator Is
              Subject Of Misalignment Allegation</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - A2 - Facilitators - Facilitator Management</dfn>
          </td>
          <td>Facilitators - Facilitator Management</td>
          <td>Section</td>
          <td>This Section designates the Scopes' Responsible Facilitators and defines key rules and processes
            related to Facilitator management.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Appointment Of Facilitators</dfn>
          </td>
          <td>Facilitators - Appointment Of Facilitators</td>
          <td>Core</td>
          <td>Sky Governance appoints the Facilitators that are responsible for each of the Scopes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Role Of Governance Scope</dfn>
          </td>
          <td>Facilitators - Role Of Governance Scope</td>
          <td>Core</td>
          <td>In the transition to Endgame, the Governance Scope designates all Scopes' responsible Facilitators
            and defines Facilitator budgets.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Scopes' Responsible Facilitators</dfn>
          </td>
          <td>Facilitators - Scopes' Responsible Facilitators</td>
          <td>Core</td>
          <td>
            The Scopes and their Responsible Facilitators are defined in <dfn>A.1.6
              - Facilitators - Scopes' Responsible Facilitators - List of Responsible Facilitators</dfn>. The
            List is modified through the Monthly Atlas Edit Cycle (i.e., the Atlas Edit Proposal Process).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Scopes' Responsible Facilitators - List of Responsible Facilitators</dfn>
          </td>
          <td>Facilitators - Scopes' Responsible Facilitators - List of Responsible Facilitators</td>
          <td>Core</td>
          <td>| Scope Framework | Responsible Facilitator | ETH Address (if relevant)
            ||-----------------|-------------------------|------------------------------------------------------||
            Governance | JanSky | 0xf3F868534FAD48EF5a228Fe78669cf242745a755 || Governance | Endgame Edge |
            0x9E72629dF4fcaA2c2F5813FbbDc55064345431b1 || Support | Ecosystem |
            0xFCa6e196c2ad557E64D9397e283C2AFe57344b75 || Protocol | Ecosystem |
            0xFCa6e196c2ad557E64D9397e283C2AFe57344b75 || Stability | Ecosystem |
            0xFCa6e196c2ad557E64D9397e283C2AFe57344b75 || Accessibility | Ecosystem |
            0xFCa6e196c2ad557E64D9397e283C2AFe57344b75 |</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Budgets</dfn>
          </td>
          <td>Facilitators - Budgets</td>
          <td>Core</td>
          <td>
            The Ecosystem Actor name, Ethereum address and budgets of Responsible Facilitators are defined in <dfn>A.1.6
              - Facilitators - Budgets - List of Facilitator Budgets</dfn>. This List is modified through the
            Monthly Atlas Edit Cycle (i.e., the Atlas Edit Proposal Process). Facilitator budgets are paid out
            even if the recipients are not active Facilitators, as long as they are using the budget to perform
            useful work for Sky Ecosystem.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Budgets - List of Facilitator Budgets</dfn>
          </td>
          <td>Facilitators - Budgets - List of Facilitator Budgets</td>
          <td>Core</td>
          <td>| Facilitator | ETH Address | USDS per Month | SKY per Month | Notes
            ||----------------|----------------------------------------------|---------------------|--------------------|-------||
            JanSky | 0xf3F868534FAD48EF5a228Fe78669cf242745a755 | 42,000 | 432,000 | N/A || Endgame Edge |
            0x9E72629dF4fcaA2c2F5813FbbDc55064345431b1 | 42,000 | 432,000 | N/A || Ecosystem |
            0xFCa6e196c2ad557E64D9397e283C2AFe57344b75 | 42,000 | 432,000 | N/A |</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Interim And Reserve Facilitators</dfn>
          </td>
          <td>Facilitators - Interim And Reserve Facilitators</td>
          <td>Core</td>
          <td>This document defines infrastructure and processes for managing the risks associated with a
            Facilitator becoming unavailable or otherwise unable to fulfill their duties.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Interim Facilitators</dfn>
          </td>
          <td>Facilitators - Interim Facilitators</td>
          <td>Core</td>
          <td>If a Facilitator of a Scope is unavailable, unresponsive or otherwise unable to fulfill their
            duties, a majority of the remaining active Facilitators can choose amongst themselves an Interim
            Facilitator to temporarily assume the role of Responsible Facilitator for that Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Reserve Facilitator Takeover</dfn>
          </td>
          <td>Facilitators - Reserve Facilitator Takeover</td>
          <td>Core</td>
          <td>
            Reserve Facilitators can help protect the continuity of Sky Governance in case other Facilitators
            become unavailable. If the Responsible Facilitators of a Scope become unresponsive or otherwise
            unavailable, the Reserve Facilitators can initiate a takeover as Interim Facilitators by posting
            their observations of inactivity or unavailability to the Sky Core Forum. If the takeover is not
            disputed by the existing Facilitators within 48 hours, the Governance Facilitators must change the
            Reserve Facilitators' status to Interim Facilitators in <dfn>A.1.6
              - Facilitators - Scopes' Responsible Facilitators - List of Responsible Facilitators</dfn>. The
            Interim Facilitators are accountable for the duties of the role until a new Facilitator is
            selected.The Governance Facilitators are responsible for coordinating the takeover process defined
            herein.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Expedited Onboarding Of Reserve Facilitators</dfn>
          </td>
          <td>Facilitators - Expedited Onboarding Of Reserve Facilitators</td>
          <td>Core</td>
          <td>
            The Governance Facilitators can propose expedited onboarding of Reserve Facilitators in order to
            ensure governance continuity in the event of emergencies. To propose such expedited onboarding, the
            Governance Facilitators can post the Ecosystem Actor Name(s), Ethereum address(es) and Scope(s) of
            responsibility to the Sky Core Forum.This triggers a Governance Poll following the Weekly Governance
            Cycle. If the Governance Poll is approved, the Reserve Facilitators are added to <dfn>A.1.6
              - Facilitators - Scopes' Responsible Facilitators - List of Responsible Facilitators</dfn> with
            the designation of 'Reserve' status.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Reserve Facilitator Takeover - Any Scope Facilitator Can Coordinate Reserve
              Facilitator Takeover</dfn>
          </td>
          <td>Facilitators - Reserve Facilitator Takeover - Any Scope Facilitator Can Coordinate Reserve
            Facilitator Takeover</td>
          <td>Core</td>
          <td>
            In the event that all Governance Facilitators are unresponsive or otherwise unable to fulfill their
            duties, any active Scope Facilitator is authorized to coordinate the takeover process defined in <dfn>A.1.6
              - Facilitators - Reserve Facilitator Takeover</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Assigning Sky Core Alignment Artifacts - Governance Scope Responsibility</dfn>
          </td>
          <td>Facilitators - Assigning Sky Core Alignment Artifacts - Governance Scope Responsibility</td>
          <td>Section</td>
          <td>All Facilitators always have responsibility for the Governance Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Assigning Sky Core Alignment Artifacts - Full Scopes Coverage</dfn>
          </td>
          <td>Facilitators - Assigning Sky Core Alignment Artifacts - Full Scopes Coverage</td>
          <td>Section</td>
          <td>
            The Governance Facilitators are responsible for ensuring that each Scope always has an active
            Facilitator assigned. If the current Scope Facilitator becomes unresponsive or otherwise unable to
            fulfill their duties, the procedures defined in <dfn>A.1.6
              - Facilitators - Interim And Reserve Facilitators</dfn> should be followed. In cases where the
            Governance Facilitators themselves become unresponsive or otherwise unavailable to fulfill their
            role, other active Scope Facilitators must assume responsibility over coordinating these procedures.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Assigning Sky Core Alignment Artifacts - Core Facilitators</dfn>
          </td>
          <td>Facilitators - Assigning Sky Core Alignment Artifacts - Core Facilitators</td>
          <td>Section</td>
          <td>If a Facilitator has responsibility for Sky Core's Support Scope or the Stability Scope, they are
            designated "Core Facilitators". Core Facilitators can only provide services to Sky Core and cannot
            be assigned responsibility for Star Scopes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Stars Scope Assignment</dfn>
          </td>
          <td>Facilitators - Stars Scope Assignment</td>
          <td>Section</td>
          <td>Stars can assign responsibility of their Scopes to Facilitators. Being assigned responsibility of a
            Star Scope requires the Facilitator to assume full responsibility for all aspects of that Scope. A
            Facilitator cannot accept partial responsibility or selectively manage certain elements of a Scope.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Eligibility For Star Scopes</dfn>
          </td>
          <td>Facilitators - Eligibility For Star Scopes</td>
          <td>Section</td>
          <td>If a Facilitator does not have responsibility for Sky Core's Support Scope or Stability Scope, they
            can be assigned responsibility for Star Scopes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Required Notice To Exit</dfn>
          </td>
          <td>Facilitators - Required Notice To Exit</td>
          <td>Section</td>
          <td>Once a Facilitator has agreed to take responsibility for a Star Scope, they must provide a minimum
            of three (3) months' notice before relinquishing their duties. This rule can be waived where the
            Facilitator can demonstrate a clear breach of good faith or other event of misalignment justifying
            the expedited exit.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Facilitator Operational Security - Facilitators Must Maintain High Level Of
              Operational Security</dfn>
          </td>
          <td>Facilitators - Facilitator Operational Security - Facilitators Must Maintain High Level Of
            Operational Security</td>
          <td>Section</td>
          <td>Facilitators are required to maintain a high level of operational security, adhering to best
            practices in privacy, cybersecurity, and physical resilience. These measures must be implemented at
            a level that sufficiently safeguards the Sky Ecosystem from physical risk posed by the potential for
            attacks against Facilitators. Facilitators' operational security protocols should be regularly
            reviewed and updated to address emerging risks and ensure continuous protection of the ecosystem.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Facilitator Operational Security - Derecognition Required Where Facilitator
              Operational Security Is Compromised</dfn>
          </td>
          <td>Facilitators - Facilitator Operational Security - Derecognition Required Where Facilitator
            Operational Security Is Compromised</td>
          <td>Section</td>
          <td>
            All Facilitators must act swiftly to investigate a Facilitator who is suspected of breaching their
            requirements regarding operational security and privacy.Any Scope Facilitator has the authority to
            formally raise an allegation concerning a Facilitator's breach of operational security with the
            Governance Facilitators, which then obligates the latter to initiate a formal adjudication pursuant
            to <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>.If
            there is clear evidence or significant suspicion that the operational security of a Facilitator has
            been compromised, or that they have failed to follow best practice or otherwise made operational
            security errors, the Governance Facilitators must promptly derecognize the Facilitator.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Facilitator Operational Security - Facilitators Must Err On Side Of Caution</dfn>
          </td>
          <td>Facilitators - Facilitator Operational Security - Facilitators Must Err On Side Of Caution</td>
          <td>Section</td>
          <td>
            Facilitators are required to err on the side of caution and take action whenever there is any real
            possibility that the operational security of a Facilitator is compromised. Facilitators are afforded
            significant discretion in making judgement calls related to operational security standards for
            Facilitators. Abuse of this power is severe misalignment. Any allegations of this abuse of power
            must be adjudicated by the Governance Facilitators pursuant to the process defined in <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Operational Requirements - Acting Against Misalignment</dfn>
          </td>
          <td>Facilitators - Operational Requirements - Acting Against Misalignment</td>
          <td>Section</td>
          <td>
            Facilitators are empowered with broad discretion in addressing situations where an Alignment
            Conserver, Ecosystem Actor or other relevant governance participant's actions are misaligned. See <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>,
            which defines the adjudication process that Facilitators must follow in addressing Alignment
            Conserver misalignment.Facilitators' abuse of this discretionary power is severe misalignment. Any
            allegations of this abuse of power must be adjudicated by the Governance Facilitators pursuant to
            the process defined in the above-cited document.A Facilitator's failure to act promptly in
            addressing credible evidence of misalignment is considered an act of misalignment itself. Formal
            allegations of such failure must be adjudicated by the Governance Facilitators pursuant to the same
            process referenced in the above-cited document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Operational Requirements - Justification For Operational Decisions</dfn>
          </td>
          <td>Facilitators - Operational Requirements - Justification For Operational Decisions</td>
          <td>Section</td>
          <td>All Facilitators must ensure that their decisions related to ordinary operations are clearly
            explained and justified using publicly available information. Facilitators are generally prohibited
            from basing their decisions on internal knowledge or undisclosed data that is not accessible to the
            public. Limited exceptions to this rule apply when Facilitators' decisions involve sensitive
            security matters. However, even in these situations, Facilitators should ensure that the rationale
            for their decisions is communicated in a manner that respects security concerns while maintaining as
            much transparency as possible.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Operational Requirements - Prohibition On Engaging With Counterparties</dfn>
          </td>
          <td>Facilitators - Operational Requirements - Prohibition On Engaging With Counterparties</td>
          <td>Section</td>
          <td>Facilitators are generally prohibited from engaging with counterparties. The sole exception to this
            rule is where Facilitators must communicate with counterparties to set up governance processes. In
            such cases, the Facilitators must clearly detail their interactions with the counterparties.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.6
              - Facilitators - Operational Requirements - Governance Process And Interaction Documentation</dfn>
          </td>
          <td>Facilitators - Operational Requirements - Governance Process And Interaction Documentation</td>
          <td>Section</td>
          <td>The operational security of Sky is reliant on clear, thorough documentation of governance processes.
            Such documentation ensures that the ecosystem can continue to function even if a Facilitator becomes
            inactive. To this end, Facilitators must document all operational and governance processes, as well
            as all interactions with ecosystem stakeholders.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.7
              - A1 - Professional Ecosystem Actors - Active Ecosystem Actors</dfn>
          </td>
          <td>Professional Ecosystem Actors - Active Ecosystem Actors</td>
          <td>Section</td>
          <td>Active or Incubating Ecosystem Actors work according to the specifications of the Atlas to receive
            funding for performing specific projects that benefit the Sky Ecosystem. Such projects can include
            developing new features; performing data collection or analysis; performing marketing, growth,
            outreach or educational activities; legal work or government outreach; and other operational
            activities. Active and Incubating Ecosystem Actors are the only type of actor that is permitted to
            do work that isn't strictly defined in, and bounded by, the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.8
              - A1 - Emergency Response System - Emergency Response</dfn>
          </td>
          <td>Emergency Response System - Emergency Response</td>
          <td>Section</td>
          <td>The Sky Protocol has often required changes outside of the standard Weekly Governance Cycle and Monthly 
            Governance Cycle to help maintain the peg or to quickly respond to changes in the Ecosystem. This Section 
            defines a general protocol for handling emergency or urgent situations. A.1.9 - A4 - Sky Core Governance Security - 
            Emergency Spells governs the resolution of emergency / urgent situations involving the Executive Process.</td>
        </tr>
              <tr>
          <td>
            <dfn>A.1.8
              - Emergency Response System - Emergency Response - Definition Of Emergency Situations</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Definition Of Emergency Situations</td>
          <td>Core</td>
          <td>An emergency situation is any situation that would require immediate intervention to prevent initiation of 
            Emergency Shutdown, severe peg divergence, or harm to members and users of the Ecosystem. Pursuant to A.0.1 - 
            Atlas Preamble - General Provisions - Facilitators’ Broad Discretionary Capacity, the Facilitators have broad 
            discretion to apply the emergency-situation processes defined in A.1.8 - A1 - Emergency Response System - Emergency 
            Response to urgent situations. Urgent situations are defined as any situation that involves a time-sensitive matter 
            that would need an expedited governance process, where following a standard governance cycle would be too slow, risk 
            a larger problem, or constitute an important missed opportunity.
        </td>
        </tr>
          <tr>
          <td>
            <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Group</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Group</td>
          <td>Core</td>
          <td>Emergency response is coordinated by the Emergency Response Group (”ERG”). The Emergency Response Group is a group 
            of Facilitators, Aligned Delegates, and Ecosystem Actors that include domain experts in different areas of the Sky 
            Ecosystem. The Emergency Response Group is tasked with reacting to emergency scenarios that are critical to the survival 
            of the Sky Protocol.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Group Membership Criteria</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Group Membership Criteria</td>
          <td>Core</td>
          <td>The membership of the Emergency Response Group may change at the discretion of Scope Facilitators, and as circumstances 
            require. Generally, the Emergency Response Group should contain domain-expert Ecosystem Actors as well as governance 
            decision-makers. The group must be able to diagnose a situation, suggest a short-term mitigation and act on such mitigation. 
            The group should also be able to define the path forward for a long-term solution to the problem and act on it.
        </td>
        </tr>
          <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Group Membership</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Group Membership</td>
          <td>Active Data Controller</td>
          <td>The membership of the Emergency Response Group is defined as Active Data in A.1.8 - Emergency Response System - Emergency 
            Response - Emergency Response Group Current Membership. The Active Data is updated as follows:<br> • The Responsible Party is 
            the Support Facilitators.<br> • The Update Process must follow the protocol for ‘Direct Edit’.
        </td>
        </tr>
          <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Group Team Members</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Group Team Members</td>
          <td>Core</td>
          <td>Where an Emergency Response Group Member is a team, that team should assign two (2) of its own team members to be responsible 
            for incident response. A team may assign more than two (2) of its team members to be responsible for incident response at the 
            discretion of the Support Facilitators. To the extent possible, the selected team members should be in different timezones and 
            jurisdictions for maximum operational and regulatory resilience. The team members assigned to the Emergency Response Group 
            should not be disclosed publicly under any circumstances as this could make them targets.
        </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.8
             - Emergency Response System - Emergency Response - Ecosystem Actor Embedding</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Ecosystem Actor Embedding</td>
          <td>Core</td>
          <td>As an extension of, and pursuant to A.1.15 - Scope Bootstrapping - Governance Security & Ecosystem Actor Embedding, Ecosystem 
            Actor Atlas Axis is permitted to assign more than two (2) of its team members to the permissioned Emergency Response 
            Communication Channels defined in A.1.8 - Emergency Response System - Emergency Response - Emergency Response Communication Channels, 
            as well as any Emergency Response calls.
        </td>
          </tr>
          <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Communication Channels</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Communication Channels</td>
          <td>Core</td>
          <td>The subdocuments herein specify the approved emergency-response communication channels.
        </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Signal Group</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Signal Group</td>
          <td>Core</td>
          <td>A unique Signal “Emergency Response” Group will be used for all incident response coordination.
            TechOps will create the Signal Group and assign its administrators. The Support Facilitators and 
            the Protocol Security Workstream Lead shall manage access to the Signal Group. All Emergency Response 
            Members must be added to the Group. Where an Emergency Response Group Member is a team, the two (2) 
            team members responsible for incident response are required to join the Signal Group. The Signal Group 
            should not be used for any purpose except communications concerning a potential emergency situation. 
            The Group must be configured to have a four-week message retention.
        </td>
        </tr>
         <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Contact Mechanism</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Contact Mechanism</td>
          <td>Core</td>
          <td>Emergency Response Group Members must use an emergency contact mechanism to deal with emergencies. 
            This emergency contact mechanism is selected and validated by the Protocol Security Workstream Lead.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Contact Mechanism Selection Criteria</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Contact Mechanism Selection Criteria</td>
          <td>Core</td>
          <td>A suitable emergency contact mechanism should meet the following criteria:<br> - The mechanism should use enterprise 
            grade infrastructure with correspondingly high levels of uptime.<br> - The mechanism should not require personal 
            information or KYC from users.<br> - The mechanism should allow segmenting of target user groups, so that required 
            individuals are only notified when necessary.<br> - The mechanism should be able to bypass silent / do not disturb 
            mode on devices to achieve an immediate response any time of day.<br> - It is recommended, but not required, that the 
            mechanism minimizes data tracking of individual users.<br> It is recommended, but not required, that the mechanism is open source.
        </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.8
              - Emergency Response System - Emergency Response - Approved Emergency Contact Mechanisms</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Approved Emergency Contact Mechanisms</td>
          <td>Core</td>
          <td>The currently approved emergency contact mechanism is PagerDuty.
        </td>
        </tr>
          <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Changes To Approved Emergency Contact Mechanisms</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Changes To Approved Emergency Contact Mechanisms</td>
          <td>Core</td>
          <td>The Governance Facilitators may recommend changing the approved emergency contact mechanism specified in A.1.8 - Emergency Response 
            System - Emergency Response - Approved Emergency Contact Mechanisms, but they must do so in consultation with the Protocol Security 
            Workstream Lead. The Governance Facilitators’ recommendation is subject to a poll through the Operational Weekly Governance Cycle.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Contact Mechanism Fire Drills</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Contact Mechanism Fire Drills</td>
          <td>Core</td>
          <td>The Protocol Security Workstream Lead and Governance Facilitators may run fire drills to test the preparedness of individuals 
            that have been added to the emergency contact mechanism. This will be done at the discretion of the Protocol Security Workstream 
            Lead and Governance Facilitators. The results of fire drills shall be published to maintain transparency.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Facilitators’ Roles And Responsibilities</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Facilitators’ Roles And Responsibilities</td>
          <td>Core</td>
          <td>The Support Facilitators are empowered to declare an emergency situation, in consultation with the responsible Facilitator of 
            the impacted Scope(s) and any relevant Scope Advisor(s).<br> After an emergency situation has been declared, the Support or 
            Governance Facilitators are responsible for coordinating emergency-situation processes to ensure they are civil, consistently 
            applied and aligned. The Governance Facilitators are responsible for publishing Polls and Executive Votes.<br> Any participant 
            in the Sky Ecosystem, including Ecosystem Actors, Aligned Delegates or other community members, can request that the Support 
            Facilitators declare an emergency. The Support Facilitators are granted broad discretion in handling such requests.
        </td>
        </tr>
           <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Considerations Before Expediting Protocol Changes</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Considerations Before Expediting Protocol Changes</td>
          <td>Core</td>
          <td>The Facilitators are required to consider several important factors before expediting changes to the protocol:<br> • Potential 
            for SKY holders to miss a poll or Executive Vote due to departure from the standard governance cycles.<br> • Expedited votes may 
            not allow for sufficient discussion, leading to a sub-optimal solution.<br> • Increased governance burden on community and increased 
            workload for domain teams.<br> • Frequent expedited votes may signal a lack of appreciation for a consistent and predictable governance process.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Process Definition</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Process Definition</td>
          <td>Core</td>
          <td>The subdocuments herein define the emergency response process.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Incident Validation</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Incident Validation</td>
          <td>Core</td>
          <td>The Support Facilitators are responsible for determining whether a reported incident is a valid emergency; where possible, this can be done 
            in consultation with the responsible Facilitator of the impacted Scope(s) and any relevant Scope Advisor(s).
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Incident Categorization</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Incident Categorization</td>
          <td>Core</td>
          <td>The Support Facilitators are responsible for categorizing emergencies according to their severity and other pertinent criteria.
        </td>
        </tr>
          <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency-Contact Mechanism Trigger</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency-Contact Mechanism Trigger</td>
          <td>Core</td>
          <td>Upon receiving notification from the Support Facilitators of a validated and categorized emergency situation, 
            TechOps must trigger a notification in the Emergency Contact Mechanism specified in A.1.8 - Emergency Response 
            System - Emergency Response - Emergency Contact Mechanism. All Emergency Response Group Members are required to 
            acknowledge the incident in a timely manner through the Emergency Contact Mechanism. The notification must include 
            a link to the official Emergency Response video call (”war room”).
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Video Call Coordination</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Video Call Coordination</td>
          <td>Core</td>
          <td>Emergency Response Group Members are required to promptly join the Video Call to coordinate incident response.
        </td>
        </tr>
         <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Known And Uncontentious Remedies</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Known And Uncontentious Remedies</td>
          <td>Core</td>
          <td>If a remedy is known and uncontentious, the Support and Governance Facilitators shall coordinate with the 
            necessary Ecosystem Actors to expedite an Executive Vote. Emergency procedures involving an Executive Vote 
            are defined in A.1.9 - A4 - Sky Core Governance Security - Emergency Spells.
        </td>
        </tr>
         <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Declaration Procedure</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Declaration Procedure</td>
          <td>Core</td>
          <td>The Support Facilitators are empowered to declare an emergency situation at their discretion, either on their own 
            initiative or in response to a request from a community member.<br> When declaring an emergency, the Support Facilitators 
            should create a formal post on the Sky Forum which provides sufficient detail regarding the issue and explains why immediate 
            action is required. If the situation allows, Facilitators should post the emergency declaration on the Sky Forum before 
            taking action. If the urgency of the situation requires immediate intervention without delay, the Facilitators should create 
            the Forum post as soon as possible after, or simultaneously with, the emergency action.<br> There may be situations in which 
            a public Emergency Declaration would be counterproductive to security objectives; the Support Facilitators are granted discretion 
            in these matters.<br> Creating a signal request thread or Governance Poll is optional.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Record Retention</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Record Retention</td>
          <td>Core</td>
          <td>To achieve continuous improvement of emergency response processes, records should be retained post-incident to enable review of 
            actions taken during the incident response. Such records may include but are not limited to:<br> 1. An incident response template filled 
            in with information from the coordination meeting;<br> 2. Incident artifacts, including files, screenshots, documents, and links;<br> 
            3. Chat transcripts from the approved communication channels specified in A.1.8 - Emergency Response System - Emergency Response - 
            Emergency Response Communication Channels.<br> It is at the discretion of the Support Facilitators as to whether incident records can be 
            shared with entities outside of the Emergency Response Group.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
             - Emergency Response System - Emergency Response - Accountability For Emergency Response Preparedness</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Accountability For Emergency Response Preparedness</td>
          <td>Core</td>
          <td>Emergency preparedness is a critical priority. The Support Facilitators, in consultation with the Protocol Security Workstream Lead, 
            must regularly evaluate the emergency preparedness of the Emergency Response Group. This can be done through running fire drills or 
            through extensive postmortems after an actual incident.
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Accountability Measures for Ecosystem Actor Individuals And Teams</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Accountability Measures for Ecosystem Actor Individuals And Teams</td>
          <td>Core</td>
          <td>For Ecosystem Actors appointed to the Emergency Response Group, fulfilling the responsibilities of this role is as critical to 
            their overall performance evaluation as their customary deliverables.<br> The Support Facilitators and Protocol Security Workstream 
            Lead are required to document all instances of Emergency Response Group Members’ failure to meet emergency-preparedness requirements. 
            Given their domain expertise and proximity to each emergency situation, the Support Facilitators and Protocol Security Workstream Lead 
            are granted the discretion to evaluate emergency-preparedness deficiencies. Generally, they are required to take swift action to address 
            non-negligible emergency-preparedness deficiencies in the following manner.<br> If the deficient Emergency Response Group Member is an 
            Ecosystem Actor individual, the individual should be removed from the Group.<br> If the deficient Emergency Response Group Member is part 
            of an Ecosystem Actor team, the specific member who has failed to meet requirements should be removed from the Group.<br> If different 
            Emergency Response Group Members from the same Ecosystem Actor team consistently fail to meet requirements, the Ecosystem Actor team as 
            a whole should be removed from the Group.<br> The removal of a Member from the Group is done at the discretion of the Support Facilitators 
            and the Protocol Security Workstream Lead. However, the Support Facilitators and Protocol Security Workstream Lead may not proceed with 
            removal unless it is supported with clear documentation. Such documentation must be made available to all Emergency Response Group 
            Members for review.<br> When an Ecosystem Actor is removed from the Emergency Response Group for deficient performance, the Support Facilitators
            must transparently announce this action via a post to the Sky Forum. Further, the removal must be incorporated into the evaluation of the Ecosystem 
            Actor’s overall performance.<br> The Support Facilitators has the discretion to decide if documentation supporting the removal should be retained 
            internally or publicly shared on the Forum (with redactions, if needed).
        </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Accountability Measures For Alignment Conservers</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Accountability Measures For Alignment Conservers</td>
          <td>Core</td>
          <td>For an Alignment Conserver who has been appointed to the Emergency Response Group, the requirements of this role become as critical to the assessment 
            of their overall performance as their customary obligations.<br> The Support Facilitators and Protocol Security Workstream Lead are required to document 
            all instances of Emergency Response Group Members’ failure to meet emergency-preparedness requirements. Given their domain expertise and proximity to each 
            emergency situation, the Support Facilitators and Protocol Security Workstream Lead are granted the discretion to evaluate emergency-preparedness 
            deficiencies. Generally, they are required to take swift action to address non-negligible emergency-preparedness deficiencies in the following manner.<br> 
            Where the deficient Member is an Alignment Conserver, that Member should be derecognized pursuant to A.1.4 - Alignment Conservers - Accountability And 
            Misalignment Handling - Adjudication Process.<br> Where the deficient Alignment Conserver is the Support Facilitators, the Protocol Security Workstream Lead 
            and a majority of active Scope Facilitators must reach consensus in order to initiate a derecognition proceeding against the Support Facilitators. Once this 
            threshold is met, the procedure defined in A.1.4 - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process should be followed. 
            In the interim, other Scope Facilitators must step in temporarily to coordinate emergency response.<br> The initiation of derecognition is done at the discretion 
            of the Support Facilitators (or other Scope Facilitator) and the Protocol Security Workstream Lead. However, the Support Facilitators and Protocol Security 
            Workstream Lead may not proceed with removal unless it is supported with clear documentation. Such documentation must be made available to all Emergency Response 
            Group Members for review.<br> When an Alignment Conserver is removed from the Emergency Response Group and derecognized for deficient performance, the Governance 
            Facilitators must transparently announce this action pursuant to A.1.4 - Alignment Conservers - Accountability And Misalignment Handling - Derecognition Notice.<br> 
            The Support Facilitators have the discretion to decide if documentation supporting the Alignment Conserver’s derecognition and removal should be retained internally 
            or publicly shared on the Forum (with redactions, if needed).
        </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - A1 - Sky Core Governance Security - General Provisions</dfn>
          </td>
          <td>Sky Core Governance Security - General Provisions</td>
          <td>Section</td>
          <td>This Section contains general provisions related to Sky Core Governance Security.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - General Provisions - Spell Team Anonymity</dfn>
          </td>
          <td>Sky Core Governance Security - General Provisions - Spell Team Anonymity</td>
          <td>Core</td>
          <td>The spell teams need not share their identities. Therefore, it is no longer a requirement that spell
            crafting teams publish the deployer of a smart contract. The spell Checklists have been amended
            accordingly.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - A2 - Sky Core Governance Security - Governance Security Delay Requirements</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements</td>
          <td>Section</td>
          <td>This subdocuments herein define critical processes and requirements concerning the Governance
            Security Module (GSM) Pause Delay.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Pause Delay</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Pause Delay</td>
          <td>Core</td>
          <td>
            The GSM (Governance Security Module) Pause Delay parameter sets the minimum amount of time after an
            Executive Vote has passed before changes will come into effect in the Sky Protocol. Once an
            Executive Vote passes, the GSM Pause Delay must pass before the changes within that Executive Vote
            can affect the Sky Protocol. The Sky Protocol only has one GSM Pause Delay, and all parameter
            changes are subject to it. The GSM Pause Delay is usually expressed in terms of hours.It is possible
            to move functionality outside of the GSM Pause Delay; however, this requires additional engineering
            work. A list of exceptional functionality can be found in <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Exceptions</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Pause Delay
              Adjustment</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Pause Delay Adjustment</td>
          <td>Core</td>
          <td>Adjusting the GSM Pause Delay parameter is a manual process that requires an Executive Vote. Changes
            to the GSM Pause Delay are subject to the pre-change GSM Pause Delay.An increase to the GSM Pause
            Delay parameter should be considered if the risk of governance attack is considered especially high
            for whatever reason. In the past, the GSM Pause Delay has been increased due to the risk from flash
            loans combined with increasing liquidity of the MKR token on the open market.A decrease should be
            considered if time-critical governance actions are projected to be needed in the near future. For
            example, if extreme market volatility is expected, it may be beneficial to reduce the GSM Pause
            Delay temporarily to allow Governance to better react to the changing conditions.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Pause Delay Current
              Value</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Pause Delay Current Value
          </td>
          <td>Core</td>
          <td>The GSM Pause Delay is: 18 hours</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Exceptions</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Exceptions</td>
          <td>Core</td>
          <td>The current exceptions to the GSM Pause Delay are specified in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Executive Drop
              Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Executive Drop Exception
          </td>
          <td>Core</td>
          <td>The MCD_PAUSE contract manages the general governance timelock of the GSM Pause Delay; however, it
            also contains an in-built exception to its own rule.The executive drop functionality allows a
            successful governance proposal to cancel a previous governance proposal that has not yet passed the
            GSM Pause Delay period and been executed. As in any other situation, the new Executive proposal must
            be the hat proposal, meaning more SKY is voting for it than is voting for any other Executive
            proposal.This functionality allows Sky Governance to prevent a malicious attack on the protocol if
            they are able to exceed the attacker's SKY weight before the GSM Pause Delay expires.The risk opened
            up by this exceptional functionality is that a malicious attacker may be able to delay or
            permanently block a legitimate governance proposal.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Oracle Freeze
              Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Oracle Freeze Exception</td>
          <td>Core</td>
          <td>The OSM_MOM contract manages the freezing of Sky's oracles. The freeze functionality allows a
            successful governance proposal to immediately freeze the oracle price for any or all of the vault
            types in the Sky Protocol. Once frozen, the oracle price will remain at its current value.The oracle
            cannot be unfrozen without waiting for the GSM Pause Delay as part of a regular governance
            proposal.The risk opened up by this exceptional functionality is that the oracles may be frozen by
            an attacker in order to either:• Prevent an expensive liquidation.• Take advantage of a significant
            drop in collateral prices to mint unbacked USDS.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Debt Ceiling Breaker
              Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Debt Ceiling Breaker
            Exception</td>
          <td>Core</td>
          <td>
            The LINE_MOM contract manages the breaker for the Debt Ceilings of a configurable subset of the
            vault types in the Sky Protocol. This Debt Ceiling Breaker allows a successful governance proposal
            to reduce the debt ceilings of a pre-configured whitelist of vault types to zero without waiting for
            the GSM Pause Delay to expire.The Debt Ceiling Breaker affects both the Debt Ceiling and the Maximum
            Debt Ceiling of a given vault type when activated, disabling the Dynamic Debt Ceiling functionality
            for that vault type if enabled. To reverse the effect, parameters of affected vault types must be
            reconfigured with an Executive Vote which is subject to GSM Pause Delay.The whitelist may be
            configured via a successful governance proposal, but must wait for the GSM Delay before changes come
            into effect. The whitelist is defined in <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Debt Ceiling Breaker
              Exception Whitelist</dfn> and can be changed via the Weekly Governance Cycle.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Debt Ceiling Breaker
              Exception Whitelist</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Debt Ceiling Breaker
            Exception Whitelist</td>
          <td>Core</td>
          <td>• PSM (USDC) - PSM-USDC-A• PSM (PAX) - PSM-PAX-A• PSM (GUSD) - PSM-GUSD-A• ETH-A• ETH-B• ETH-C•
            WSTETH-A• WSTETH-B• WBTC-A• WBTC-B• WBTC-C</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Liquidations Circuit
              Breaker Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Liquidations Circuit Breaker
            Exception</td>
          <td>Core</td>
          <td>The CLIPPER_MOM contract manages the circuit breaker for vault types using Liquidations 2.0. The
            circuit breaker functionality allows a successful governance proposal to impose Sky Governance's
            choice of limitations on liquidations for any or all of the vault types in the Sky Protocol.• Level
            0 - Liquidations Enabled - The breaker is not tripped, new vaults can be liquidated and old
            liquidations can proceed.• Level 1 - New Liquidations Disabled - No new liquidations can take
            place.• Level 2 - New Liquidations and Resets Disabled - No new liquidations can take place. No
            existing auctions can be reset if they expire.• Level 3 - All Liquidations Disabled - No new
            liquidations, no resets, no bidding in active auctions.This functionality is exceptional because
            liquidations at non-market prices have the potential to be irreversibly damaging to both users and
            the Sky Protocol. The circuit breaker allows Sky Governance to attempt to limit the damage in the
            event of an issue affecting liquidations without waiting for the GSM Pause Delay.Additionally, the
            contract allows for permissionless activation of the circuit breaker, if the price decrease in a
            collateral exceeds a preset percentage value between oracle price updates. The permissionless
            activation triggers the circuit breaker at Level 2 because both new auctions and resets reference
            the current oracle price.When Level (0, 1, 2, 3) of liquidations circuit breaker is altered via
            Executive Vote, Sky Governance has the ability to set locked time, which is a specified duration
            which needs to pass before the liquidations circuit breaker can be triggered again via
            permissionless activation.The risk opened up by this exceptional functionality is that liquidations
            may be halted by an attacker in order to either:• Prevent an expensive liquidation.• Take advantage
            of a significant drop in collateral prices to mint unbacked USDS.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Liquidations Circuit
              Breaker Exception Price Tolerance</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Liquidations Circuit Breaker
            Exception Price Tolerance</td>
          <td>Core</td>
          <td>Breaker Price Tolerance is a parameter which determines the condition for the permissionless
            activation of circuit breaker. Adjusting the Breaker Price Tolerance requires an Executive Vote,
            which is subject to GSM Pause Delay.The Breaker Price Tolerance is expressed as a number between
            zero and one, and works with the following equation: next_oracle_price &lt; current_oracle_price *
            breaker_price_tolerance.In instances where the price oracle model does not support the price delay
            function, the permissionless activation of the liquidation circuit breaker ceases to function, since
            there is no next oracle price.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Liquidations Circuit
              Breaker Exception Price Tolerance Current Value</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Liquidations Circuit Breaker
            Exception Price Tolerance Current Value</td>
          <td>Core</td>
          <td>The Breaker Price Tolerance is: 0.5</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Direct Deposit Breaker
              Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Direct Deposit Breaker
            Exception</td>
          <td>Core</td>
          <td>The DIRECT_MOM contract manages the breaker for Direct Deposit Modules (D3Ms). The breaker
            functionality allows a successful governance proposal to disable any or all of the active D3Ms. In
            practice, this will set the bar parameter to zero, which (contrary to intuition) disables the module
            by setting the allowed Debt Ceiling to zero. At this point, no further USDS can be minted through
            the Direct Deposit Module. To reverse the effect, parameters of affected Direct Deposit Modules must
            be reconfigured with an Executive Vote which is subject to GSM Pause Delay.The risk opened up by
            this exceptional functionality is that a given line of USDS credit is unexpectedly shut down. This
            has the potential to disrupt the protocol in question, which may impact Sky indirectly.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Dynamic Debt Ceiling
              Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Dynamic Debt Ceiling
            Exception</td>
          <td>Core</td>
          <td>The MCD_IAM_AUTO_LINE contract manages the debt ceiling parameters for many of Sky's vault types
            according to preset rules. Keepers can use the contract to attempt to maintain a Target Available
            Debt in a given vault type. The contract modifies the debt ceiling up or down to maintain a level of
            available debt.This functionality is exceptional so that the Sky protocol can react to changes in
            debt demand more quickly than waiting for the GSM delay.The risk opened up by this exceptional
            functionality is a theoretical griefing attack on the IAM that prevents debt from being accessible
            in affected vault types.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - SparkLend Freezer Mom
              Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - SparkLend Freezer Mom
            Exception</td>
          <td>Core</td>
          <td>The SparkLend Freezer Mom contract allows Sky Governance to bypass the GSM delay to either freeze or
            pause any markets in SparkLend. The contract also allows the undoing of such actions for any market
            in SparkLend.This functionality allows Sky Governance to react faster in an emergency. Freezing
            markets does not allow for new supplies or borrows, while pause restricts all market functionality,
            including deposits/withdrawals/borrows/repays and liquidations.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - Smart Burn Engine
              Breaker Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - Smart Burn Engine Breaker
            Exception</td>
          <td>Core</td>
          <td>The SplitterMom contract allows for the disabling of the Smart Burn Engine without the GSM delay. This 
            functionality is available so that Sky Governance can react to emergencies regarding the Smart Burn Engine. 
            Since the Splitter contract also allocates USDS from the Surplus Buffer to USDS Seal Rewards, the activation 
            of SplitterMom also disables these rewards until the activation is reversed by Sky Governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - PSM Breaker
              Exception</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Delay Requirements - PSM Breaker Exception</td>
          <td>Core</td>
          <td>The PSM_MOM contract manages the breaker for swaps through the LitePSM. The PSM Breaker allows a
            successful governance proposal to halt swaps through the LitePSM.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - A3 - Sky Core Governance Security - Governance Security Culture And Research</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research</td>
          <td>Section</td>
          <td>This Section must define processes to cultivate and maintain a strong security culture within the
            Sky Ecosystem. This Section must implement continuous research and integration of best practices to
            ensure that the Ecosystem's security remains effective and up-to-date.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Culture And Research - Spark Star</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research - Spark Star</td>
          <td>Core</td>
          <td>Spark is one of the initial Stars focused on developing crypto on-chain lending engines. Spark will
            be governed by Spark Star token holders pursuant to the conditions specified in the Atlas.SparkLend
            Protocol is the first such on-chain lending engine, structured as a Conduit in the upcoming
            Allocation System. SparkLend will be adopted by Spark Star once Stars are launched.The subdocuments
            below outline the governance security procedures specifically in development for the SparkLend
            Protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Culture And Research - Multisig Freeze Of
              SparkLend</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research - Multisig Freeze Of
            SparkLend</td>
          <td>Core</td>
          <td>
            In addition to the SparkLend Freezer Mom contract defined in <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Delay Requirements - SparkLend Freezer Mom
              Exception</dfn>, an external SparkLend Security Access Multisig has been established that allows 
            for pausing and/or freezing SparkLend markets. The SparkLend Security Access Multisig can enable or 
            disable the SparkLend Freezer Mom contract without the need for inclusion in a spell through the 
            standard Executive Vote process.<br> Each action executed by the Multisig, including any function 
            calls and their parameters, must be reported to the Sky community within a reasonable time frame 
            through a post on the Sky Forum. Such actions include activating or disabling the pause or freeze function.
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Usage Standards</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Usage Standards</td>
          <td>Core</td>
          <td>
            The SparkLend Security Access Multisig can only be used in urgent or emergency situations (e.g., 
            potential code exploits). Such situations are characterized by the fact that 1) they have the potential 
            to harm the Sky Ecosystem or SparkLend users; and 2) the preparation time required for an Executive 
            Vote would leave the ecosystem vulnerable to harm (e.g., an exploit).<br> The Multisig should be used to 
            prevent technical vulnerabilities; prevent unwanted functionality of the smart contracts or corresponding 
            parts of the system (e.g., price oracles); or prevent unwanted usage of the smart contracts or corresponding 
            parts of the system which deviates from intended behavior.<br> The Multsig can also be used in cases where 
            a vulnerability or exploit is discovered in other protocols using the same codebase as SparkLend, and a 
            timely action can prevent or mitigate the damage.<br> The Governance Facilitators must ensure that use of 
            the Multisig is generally aligned and specifically accords with the requirements defined herein.
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Number Of Signers</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Number Of Signers</td>
          <td>Core</td>
          <td>
            The SparkLend Security Access Multisig currently has a 2/5 signing requirement.
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Current Signers</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Current Signers</td>
          <td>Core</td>
          <td>
            The SparkLend Security Access Multisig currently has the following signers:• VoteWizard• LDR• Hexonaut• MonetSupply• Rema
        </tr>
         <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Signer Modifications</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Signer Modifications</td>
          <td>Core</td>
          <td>
            Modification of the signers of the SparkLend Security Access Multisig must be approved through a Governance 
            Poll; no Executive Vote is required.<br>The only exceptions to this are if: 1) a signer self-reports a loss 
            of access to their private key due to any reason; or 2) a signer explicitly expresses their wish to be removed 
            as a signer. In both cases, the signer is required to communicate the loss of access to their private key, or the 
            wish to be removed as a signer, in the form of a public Sky Forum post. The specific signer should be replaced 
            as soon as possible.<br> Any changes to the Multisig signers that do not fall within the two exceptions listed above, 
            or that have not been ratified by Sky Governance, should be questioned immediately and treated as malicious. The 
            Governance Facilitators should consider preparing an expedited Executive Vote so that Sky Governance can vote on 
            removing external security access from the Multisig.
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Address</dfn>
          </td>
          <td>Sky Core Governance Security - Governance Security Culture And Research - SparkLend Multisig Address</td>
          <td>Core</td>
          <td>
            The current whitelisted SparkLend Security Access Multisig address is:<br> 0x44efFc473e81632B12486866AA1678edbb7BEeC3
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - A4 - Sky Core Governance Security - Emergency Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells</td>
          <td>Section</td>
          <td>The subdocuments herein govern the management of emergencies whose resolution requires an Executive Vote.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Emergency Spells Definition</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Emergency Spells Definition</td>
          <td>Core</td>
          <td>Emergency Spells are expedited ad hoc spells that, while typically compliant with all customary quality-assurance processes, 
              do not adhere to the normal spell cadence. Emergency Spells solve the root issue of an emergency / urgent situation 
              impacting the Protocol and are used when a rapid response time is needed. The Support and Governance Facilitators are 
              responsible for managing the use of Emergency Spells pursuant to <dfn>A.1.8 - Emergency Response System - Emergency Response 
              - Facilitators’s Roles And Responsibilities</dfn> and <dfn>A.1.8 - Emergency Response System - Emergency Response - Known 
              And Uncontentious Remedies</dfn>.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Standby Spells</td>
          <td>Core</td>
          <td>A subset of Emergency Spells is Standby Spells.
              Standby Spells allow Sky Governance to bypass the GSM Pause Delay and directly perform crucial actions such as stopping an 
              oracle, setting a debt ceiling to zero, disabling a D3M integration, or stopping liquidations for a collateral. Standby 
              Spells or the factory contracts used to deploy them are reusable, meaning they can be executed several times if needed, or 
              voted on again on a later date to be executed again.
              The subdocuments herein specify the authorized use of Standby Spells.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Standby Spells Definition</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Standby Spells Definition</td>
          <td>Core</td>
          <td>Sky Protocol uses circuit-breakers to mitigate undesired scenarios, which circuit-breakers are called MOM contracts. MOM 
            contracts must first be triggered through a spell, after which they bypass the GSM Pause Delay and can immediately act on the 
            Protocol. See <dfn>A.1.9 - Sky Core Governance Security - Governance Security Delay Requirements - Exceptions</dfn>.
            In emergency scenarios, time is a scarce resource. Therefore, Standby Spells are used in validated emergency scenarios to 
            trigger a MOM contract. In an emergency situation, spell teams can then focus on crafting an ad hoc Emergency Spell to solve 
            the root cause of an issue, if appropriate. Due to Standby Spells, it is no longer necessary in an emergency for spell teams 
            to spend time crafting and reviewing a spell whose sole purpose is to trigger a mitigation of the issue, i.e., the MOM 
            contract.
            Standby Spells open new attack vectors that must be mitigated pursuant to <dfn>A.1.9 - Sky Core Governance Security - 
            Emergency Spells - ADs’ Role In Standby Spells</dfn>.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Standby Spell Incorporation Into New MOM Contracts</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Standby Spell Incorporation Into New MOM Contracts</td>
          <td>Core</td>
          <td>Each new MOM contract created must incorporate a Standby Spell or Standby Spell factory, which can be used to create new 
              Standby Spells that can trigger the MOM contract. With a Standby Spell per every MOM contract, the generation of technical 
              debt can be avoided.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Available Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Available Standby Spells</td>
          <td>Core</td>
          <td>The currently available Standby Spells are defined in the subdocuments herein.
              The following list of Standby Spells is not exhaustive: that is, the Support Facilitators, in collaboration with the 
              Emergency Response Group and spell teams, have the discretion to develop and use a Standby Spell that is not listed in the 
              subdocuments below. When that occurs, however, the Support Facilitators must ensure that the new Standby Spell is 
              subsequently added to the subdocuments below.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Single-Collateral Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Single-Collateral Standby Spells</td>
          <td>Core</td>
          <td>The subdocuments herein define currently available single-collateral Standby Spells. For each instance of use, 
            single-collateral Standby Spell contracts require a transaction to deploy the Standby Spell from a factory.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - SingleOsmStopSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - SingleOsmStopSpell</td>
          <td>Core</td>
          <td>This Standby Spell can be used in an emergency to freeze an OSM for a single collateral. If the oracle price provider fails 
              for any reason, Governance can act before the OSM registers the next price; this allows for the problem to be fixed with no 
              impact on the system.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - SingleDdmDisableSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - SingleDdmDisableSpell</td>
          <td>Core</td>
          <td>This Standby Spell can be used in an emergency to disable a D3M integration. If a D3M partner is experiencing a problem such 
              as a hack, this emergency spell can be used to prevent abuse. While it cannot recover Dai already injected into the 
              compromised protocol, the Emergency Spell can prevent additional exposure.</td>
        </tr>
        <tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - SingleLitePsmHaltFactory</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - SingleLitePsmHaltFactory</td>
          <td>Core</td>
          <td>This Standby Spell can be used in an emergency to halt a LitePSM completely.</td>
        </tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Grouped Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Grouped Standby Spells</td>
          <td>Core</td>
          <td>The subdocuments herein define currently available grouped Standby Spells. For each instance of use, grouped Standby Spell 
            contracts require a transaction to deploy the Standby Spell from a factory. Unlike single-collateral Standby Spells, a grouped 
            Standby Spell is configured at the time of deployment with a specific list of collaterals it can operate on. This setup enables 
            a single grouped Standby Spell to operate on multiple related collaterals.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - GroupedLineWipeSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - GroupedLineWipeSpell</td>
          <td>Core</td>
          <td>This Standby Spell will perform a Line MOM Wipe (set debt ceiling to zero) for the specified collaterals. It can be used if 
            the specified collaterals fail - for example, if a stablecoin depegs or the protocol that provides the token is hacked. Users 
            will still be able to exit their positions, but no new debt will be allowed to be created for the collaterals.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - GroupedClipBreakerSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - GroupedClipBreakerSpell</td>
          <td>Core</td>
          <td>This Standby Spell can be used in an emergency to stop liquidations for the specified collaterals.</td>
        </tr>
        <tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Multi-Collateral Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Multi-Collateral Standby Spells</td>
          <td>Core</td>
          <td>The subdocuments herein define currently available multi-collateral Standby Spells. Multi-collateral Standby Spell contracts are 
            spells in themselves and are thus reusable; beyond the initial deployment of the contract, no further deployment is needed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - MultiLineWipeSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - MultiLineWipeSpell</td>
          <td>Core</td>
          <td>This Standby Spell will wipe all lines, setting the debt ceilings for all collaterals (lines) to zero. Users will still be 
              able to exit their positions, but no new debt will be allowed to be created for any collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - MultiClipBreakerSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - MultiClipBreakerSpell</td>
          <td>Core</td>
          <td>This Standby Spell will freeze liquidations for all collaterals.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - MultiOsmStopSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - MultiOsmStopSpell</td>
          <td>Core</td>
          <td>This Standby Spell will freeze all OSMs. If the oracle price provider fails for any reason, Governance can act before the 
              OSM registers the next price; this allows for the problem to be fixed with no impact on the system.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Global Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Global Standby Spells</td>
          <td>Core</td>
          <td>The subdocuments herein define currently available global Standby Spells. Global Standby Spell contracts are spells in 
            themselves and are thus reusable; beyond the initial deployment of the contract, no further deployment is needed. Global 
            Standby Spells differ from multi-collateral Standby Spells in that the former operates on the Protocol globally and not 
            on some set of collaterals.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - SplitterStopSpell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - SplitterStopSpell</td>
          <td>Core</td>
          <td>This Standby Spell can be used in an emergency to disable the Smart Burn Engine.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Standby Spell Process Definition</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Standby Spell Process Definition</td>
          <td>Core</td>
          <td>The subdocuments herein define the process for using Standby Spells.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Support Scope Facilitators’ Role In Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Support Scope Facilitators’ Role In Standby Spells</td>
          <td>Core</td>
          <td>The role of the Support Facilitators in the Standby Spell process is as follows:
              • Standby Spells can only be used in response to a properly validated and categorized emergency scenario, for which the 
              Support Facilitators are responsible. See <def>A.1.8 - Emergency Response System - Emergency Response - Incident 
              Validation</def> and <dfn>A.1.8 - Emergency Response System - Emergency Response - Incident Categorization</dfn>.
              The decision to use a Standby Spell is reserved for the Support Facilitators; where possible, the Support Facilitators 
              should consult with the responsible Facilitator of the impacted Scope(s) and any relevant Scope Advisor(s). See <dfn>A.1.8 - 
              Emergency Response System - Emergency Response - Facilitators’s Roles And Responsibilities</dfn>.
              • The Support Facilitators must explicitly communicate the decision to use a Standby Spell in the secure, private 
              communication channel specified in <dfn>A.1.8 - Emergency Response System - Emergency Response - Emergency Response Signal 
              Group</dfn> or on a “war room” video call.
              • If the decision to use a Standby Spell is first reached on a video call, the Support Facilitators are required thereafter 
              to promptly document their decision in the secure, private communication channel specified in <dfn>A.1.8 - Emergency 
              Response System - Emergency Response - Emergency Response Signal Group</dfn>.
              • After the Support Facilitators decide to use a Standby Spell, TechOps must promptly trigger an incident to the Emergency 
              Response Group as specified in <dfn>A.1.8 - Emergency Response System - Emergency Response - Emergency-Contact Mechanism 
              Trigger</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Governance Facilitators’ Role In Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Governance Facilitators’ Role In Standby Spells</td>
          <td>Core</td>
          <td>All Governance Facilitators must promptly acknowledge receipt of the Support Facilitators’ decision to use a Standby Spell. 
            This acknowledgment must take place in the communication channel specified in <dfn>A.1.8 - Emergency Response System - 
            Emergency Response - Emergency Response Signal Group</dfn>.
            The Governance Facilitators are responsible for actioning the Standby Spell and liaising with the Prime Delegates (and other 
            Aligned Delegates as needed) to gather the necessary support for it.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Requirement To Validate Authenticity Of Standby Spell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Requirement To Validate Authenticity Of Standby Spell</td>
          <td>Core</td>
          <td>All Governance Facilitators, as defined in the subdocument below, are required to validate the authenticity of the Standby Spell.
              This validation must be in the form of a written communication in the secure channel specified in <dfn>A.1.8 - Emergency 
              Response System - Emergency Response - Emergency Response Signal Group</dfn>. Only the entities specified in <dfn>A.1.9 - 
              Sky Core Governance Security - Emergency Spells - Current Entities Authorized To Validate Authenticity of Standby 
              Spell</dfn> are authorized to provide the validation of authenticity.
              Pursuant to <dfn>A.1.9 - Sky Core Governance Security - Emergency Spells - ADs’ Role In Standby Spells</dfn>, ADs are 
              prohibited from voting for a Standby Spell without this validation of authenticity.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Current Entities Authorized To Validate Authenticity of Standby Spell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Current Entities Authorized To Validate Authenticity of Standby Spell</td>
          <td>Core</td>
          <td>This document defines the term “Governance Facilitators” as used in <dfn>A.1.9 - Sky Core Governance Security - Emergency 
              Spells - Requirement To Validate Authenticity of Standby Spell</dfn>.
              The entities listed below are authorized to validate the authenticity of a Standby Spell:
              • JanSky
              • VoteWizard
              The authorized entities are not to be interpreted as the collective identity of the Governance Facilitator teams. Rather, the authorized entities are synonymous with the Sky Forum account holders with the following handles:
              • JanSky
              • votewizard
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Custom Spell Voting For Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Custom Spell Voting For Standby Spells</td>
          <td>Core</td>
          <td>The Governance Facilitators may use the Custom Spell Voting Page when it is beneficial to coordinate voting without having a 
              visible spell on the Voting Portal. The Governance Facilitators must not use this method unless domain expert Ecosystem 
              Actors in the Emergency Response Group have recommended this approach; such recommendation must be explicitly documented in 
              the communication channel specified in <dfn>A.1.8 - Emergency Response System - Emergency Response - Emergency Response 
              Signal Group</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - ADs’ Role In Standby Spells</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - ADs’ Role In Standby Spells</td>
          <td>Core</td>
          <td>ADs are strictly prohibited from acting on a Standby Spell unless they have first confirmed all of the following 
              requirements:
              • Receipt of the Support Facilitator’s official notification of the emergency scenario in the Emergency Contact Mechanism 
              specified in <dfn>A.1.8 - Emergency Response System - Emergency Response - Emergency-Contact Mechanism Trigger</dfn>.
              • Receipt of the Support Facilitators’ announcement of a Standby Spell in the communication channel specified in <dfn>A.1.8 
              - Emergency Response System - Emergency Response - Emergency Response Signal Group</dfn>; and
              • All Governance Facilitators have validated the authenticity of the Standby Spell. This validation must fulfill two 
              requirements: (1) the validation must be in the form of a written communication in the secure channel specified in <dfn>A.1.8 
              - Emergency Response System - Emergency Response - Emergency Response Signal Group</dfn>; and (2) the validation must be 
              provided by the authorized entities listed in <dfn>A.1.9 - Sky Core Governance Security - Emergency Spells - Current 
              Entities Authorized To Validate Authenticity of Standby Spell</dfn>.
              After ADs have confirmed all requirements are met, they must either promptly vote to approve the Standby Spell, or 
              communicate any concerns to the Governance Facilitators and collaborate with the latter for a speedy resolution.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - AD Reliance On Governance Facilitators In Standby Spell Process Where Governance Facilitator Is Nonresponsive</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - AD Reliance On Governance Facilitators In Standby Spell Process Where Governance Facilitator Is Nonresponsive</td>
          <td>Core</td>
          <td>There is an exception to the requirement that all Governance Facilitators must validate the authenticity of a Standby Spell. 
              In situations where a Governance Facilitator has failed to respond to the emergency situation, the Support Facilitators may 
              temporarily grant the responding Governance Facilitator(s) the sole authority to validate the authenticity of the Emergency 
              Spell pursuant to <dfn>A.1.9 - Sky Core Governance Security - Emergency Spells - ADs’ Role In Standby Spells</dfn>. The 
              Support Facilitators must communicate this in writing in the secure channel specified in <dfn>A.1.8 - Emergency Response 
              System - Emergency Response - Emergency Response Signal Group</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Misalignment To Vote For Unvalidated Standby Spell</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Misalignment To Vote For Unvalidated Standby Spell</td>
          <td>Core</td>
          <td>It is severe misalignment for an Aligned Delegate to vote for a Standby Spell whose authenticity has not been validated 
            pursuant to <dfn>A.1.9 - Sky Core Governance Security - Emergency Spells - ADs’ Role In Standby Spells</dfn>. Aligned 
            Delegates in breach of this requirement must be immediately derecognized and their full AD Buffer should be confiscated.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.9
              - Sky Core Governance Security - Emergency Spells - Accountability</dfn>
          </td>
          <td>Sky Core Governance Security - Emergency Spells - Accountability</td>
          <td>Core</td>
          <td>Breach of any requirement concerning Emergency Spells - including Standby Spells - constitutes misalignment and must be 
              addressed pursuant to <dfn>A.1.8 - Emergency Response System - Emergency Response - Accountability For Emergency Response 
              Preparedness</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - A1 - Weekly Governance Cycle - Operational Weekly Cycle</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle</td>
          <td>Section</td>
          <td>This Section defines the Operational Weekly Cycle, a predictable weekly framework for recurring
            operational decisions. The Operational Weekly Cycle is implemented via Governance Polls and
            Executive Votes. The Cycle complements the Monthly Governance Cycle by enabling recurring weekly
            decisions to be made that require quicker action than is allowed by the Monthly Governance Cycle.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Edits To The Atlas</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Edits To The Atlas</td>
          <td>Core</td>
          <td>The Operational Weekly Cycle may be used to edit the Atlas only if the pertinent Atlas document specifies 
            that it, or a related unit of governance logic which it expressly controls, is modifiable through the 
            Operational Weekly Cycle.<br>The general rule is that an Operational Weekly Cycle proposal requires a Governance 
            Poll followed by an Executive Vote. The general rule, by default, is assumed wherever the Atlas provides that a 
            document, or a unit of governance logic controlled by said document, is modifiable through the Operational 
            Weekly Cycle.<br>Any exception to the general rule must be specifically stated in the pertinent Atlas document. 
            The possible exceptions include documents that can be modified subject to a Governance Poll only; and documents 
            that can be modified subject to an Executive Vote only, without requiring a previous Governance Poll.
          </td>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Definitions</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Definitions</td>
          <td>Core</td>
          <td>The subdocuments herein contain essential definitions pertinent to the Operational Weekly Cycle.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Weekly Poll</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Weekly Poll</td>
          <td>Core</td>
          <td>A Weekly Poll ("Governance Poll" or "Poll") is a non-binding poll that determines the bi-weekly
            Executive Vote contents. In this context, a non-binding weekly poll refers to the fact that a weekly
            poll cannot change the system parameters independently; it merely dictates what will be included in
            the next Executive Vote.Governance Polls occur on-chain and are used to measure the sentiment of SKY
            voters. Polls often run concurrently, allowing voters to participate in any number of them at the
            same time. Polls may have different formats like Binary Voting, Instant Run-Off Voting, or Approval
            Voting depending on the topic. The voting period of a given Governance Poll varies; the most common
            are three (3) and fourteen (14) day periods. Concurrently-posted polls do not necessarily have the
            same voting periods.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Non-Standard Weekly
              Poll</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Non-Standard Weekly Poll</td>
          <td>Core</td>
          <td>A Non-Standard Weekly Poll is a non-binding weekly poll that has arbitrary time-sensitive decisions
            that SKY holders have to make in a relatively short period of time. The use of Non-Standard Weekly
            Polls is exclusive to Facilitators and is limited to situations where the Weekly Governance Cycle is
            determined to operate too slowly to be usable.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Executive Vote</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Executive Vote</td>
          <td>Core</td>
          <td>An Executive Vote (also "Executive") is a formalized governance proposal that requires on-chain
            voting. Through the Executive Vote mechanism, SKY holders steward Sky Governance by voting on
            Executive proposals that pertain to operations maintaining the Protocol. Executive Votes execute
            technical changes to the Sky Protocol.The Executive Vote occurs approximately every two weeks. Its
            contents are often determined by weekly Governance Polls that pre-approve the inclusion of proposals
            in the Executive Vote. However, the Atlas can explicitly authorize proposals to go directly to an
            Executive Vote.Note that the terms 'Executive' and 'spell' are distinct concepts. The term
            'Executive' or 'Executive Vote' is used in all instances where the formal governance vote is being
            referenced. The term 'Executive Process' refers to the end-to-end process of the development of an
            Executive Vote, in which Facilitators, spell teams (also referred to collectively as the "Governance
            Security Engineering Team") and other recognized Ecosystem Actors participate. The term 'spell'
            refers to the smart contract that executes the changes to the protocol approved by Sky Governance in
            an Executive Vote. Generally, when referring to spell team operations and their technical outcome or
            product (including code base, code operations, code reviews and code quality), the term 'spell' will
            be used. The term 'spell process' refers to the end-to-end process of developing a spell, a process
            in which the Governance Facilitators and the current spell team participate. The term 'spell
            development process' is a subset of the 'spell process' and pertains solely to the technical
            development of the spell by the current spell team.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Full Cycle Breakdown</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Full Cycle Breakdown</td>
          <td>Core</td>
          <td>Every Monday, the Operational Weekly Cycle begins. It implements standard recurring operational
            decisions, proposed in the form of polls.Operational Weekly Cycle proposals ("proposals") can be
            proposed by Facilitators and recognized Ecosystem Actors. The proposals should be posted to the Sky
            Forum by Friday at 8:00 am UTC to ensure the Governance Facilitators have sufficient time to prepare
            the needed polls for the following Monday.After confirming that the proposer has the authority to
            request a poll, the relevant Scope Facilitator must post an explicit approval of the poll request as
            a reply to the proposer's Forum thread. The Governance Facilitators must then prepare and publish
            the Governance Poll.The Operational Weekly Cycle polls run for three days.The outcome of the polls
            determines the contents of the upcoming Executive Vote.The Governance Facilitators confirm the
            Executive Vote contents and deliver the Executive Sheet to the spell team. The spell team prepares
            and reviews the Mainnet spell. The spell team deploys the Mainnet spell; and then creates and
            reviews a Mainnet fork.The Governance Facilitators add the Executive Vote to the Voting Portal and
            communicate this to the Sky Ecosystem community. The Executive Vote has an expiration of thirty (30)
            days; if an Executive proposal does not pass within this timeframe, it expires and can no longer
            have any effect on the Sky Protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Executive Vote Contingencies</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Executive Vote Contingencies</td>
          <td>Core</td>
          <td>The subdocuments herein define contingencies related to Executive Votes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Executive Vote Cadence</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Executive Vote Cadence</td>
          <td>Core</td>
          <td>The Executive Vote occurs approximately every two weeks, although this cadence can vary based on
            decisions made by the Governance Facilitators and the current spell team.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Postponement Of Executive Vote</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Postponement Of Executive Vote</td>
          <td>Core</td>
          <td>A scheduled Executive Vote can be postponed if deemed necessary by the Governance Facilitators and
            the current spell team.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Additional Executive Votes</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Additional Executive Votes</td>
          <td>Core</td>
          <td>Additional Executive Votes outside the regular schedule may be introduced if deemed necessary by the
            Governance Facilitators and the current spell team.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Decision To Not Publish Executive
              Vote</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Decision To Not Publish Executive Vote</td>
          <td>Core</td>
          <td>If there are no substantive changes due to be made to the Sky Protocol, the Governance Facilitators,
            in conjunction with the spell teams, may opt not to publish an Executive Vote. This decision should
            be announced and justified on the Sky Forum.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Use Of Non-standard Weekly Poll</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Use Of Non-standard Weekly Poll</td>
          <td>Core</td>
          <td>If a non-standard weekly poll ("Signal Request") has been proposed, it will also be put in the
            weekly poll.To create a non-standard weekly poll requires an urgent and apparent reason from a
            timing perspective to justify it. It is important to note that a non-standard weekly poll cannot be
            used for long-term decisions and requires consensus from the Governance Facilitators before it can
            be accepted and published.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Governance Facilitators' Authority To
              Create Proposals</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Governance Facilitators' Authority To Create
            Proposals</td>
          <td>Core</td>
          <td>The Governance Facilitators may create proposals using the Weekly Governance Cycle to enable them to
            fulfill their responsibilities.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Governance Facilitators' Role in Adding Housekeeping Items In Executive Votes
            </dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Governance Facilitators' Role in Adding Housekeeping Items In Executive Votes</td>
          <td>Core</td>
          <td>
              Governance Facilitators are authorized to add housekeeping items in an Executive Vote pursuant to the procedure defined in A.1.11 - Weekly Governance Cycle - Operational Weekly Cycle - Process for Adding Housekeeping Items In Executive Vote. Governance Facilitators can propose housekeeping items of their own accord; or, they can do so in consultation with the spell teams.
          
              Where housekeeping items are proposed by the spell teams, the Governance Facilitators must always conduct an independent assessment of the justification for, and security risks associated with, the housekeeping items. After the proposed housekeeping items have passed this independent assessment, the Governance Facilitators may propose adding these items in an Executive Vote pursuant to the procedure defined in A.1.11 - Weekly Governance Cycle - Operational Weekly Cycle - Process for Adding Housekeeping Item In Executive Vote.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Housekeeping Items
            </dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Definition Of Housekeeping Items</td>
          <td>Core</td>
          <td>Housekeeping items are defined as maintenance and record-keeping actions necessary to the correct functionality of the Sky Protocol. Housekeeping items do not include actions that modify risk parameters or introduce new elements into the protocol.
            Examples of housekeeping items include, but are not limited to, (1) cleaning up technical debt, (2) updating the Chainlog, and (3) cancelling payment streams that are no longer used.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle -  Process for Adding Housekeeping Item In Executive Vote
            </dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle -  Process for Adding Housekeeping Item In Executive Vote</td>
          <td>Core</td>
          <td>Housekeeping items can be directly included in Executive Votes without a Governance Poll through the following process. The Governance Facilitators must first create a post on the Sky Forum detailing the housekeeping items and the rationale for their inclusion. The Governance Facilitators must request a confirmation of the technical accuracy of the housekeeping items from the technical Ecosystem Actor (or spell team) who is leading spell development for the pertinent Executive Vote. The Technical Ecosystem Actor (spell team) must reply to the Forum Post confirming the accuracy of the housekeeping item. Finally, the Protocol Facilitator must approve the inclusion of the housekeeping items in an Executive Vote, via a reply to the Forum Post.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Operational Weekly Cycle - Signal Requests</dfn>
          </td>
          <td>Weekly Governance Cycle - Operational Weekly Cycle - Signal Requests</td>
          <td>Core</td>
          <td>Signal Requests are only permitted when they are specifically triggered and required by the Atlas.
            In all other circumstances, they are prohibited.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - A2 - Weekly Governance Cycle - Atlas Edit Weekly Cycle</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle</td>
          <td>Section</td>
          <td>This Section defines the Atlas Edit Weekly Cycle which provides a predictable framework for weekly
            edits to the Atlas. The Atlas Edit Weekly Cycle is implemented via Governance Polls.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Cycle Breakdown</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Cycle Breakdown</td>
          <td>Core</td>
          <td>The subdocuments herein provide a breakdown of the Atlas Edit Weekly Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Proposals In General</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Proposals In General</td>
          <td>Core</td>
          <td>In the transition to Endgame, the Atlas can be edited through the submission of an Atlas Edit Weekly
            Cycle Proposal (also "Weekly Cycle Proposal" or "Proposal"). Multiple amendments to multiple
            components of the Atlas are allowed to be submitted in a single Weekly Cycle Proposal. A single
            Weekly Cycle Proposal may seek to remove multiple components of the Atlas. Atlas Edits must always
            adhere to the Spirit of the Atlas and remain within the bounds of Universal Alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Origination Via Forum Post</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Origination Via Forum Post</td>
          <td>Core</td>
          <td>The Author of an Atlas Edit Weekly Cycle Proposal (also "Weekly Cycle Proposal" or "Proposal") must
            post the Proposal in the Sky Forum in the appropriate category and signal their intent to submit the
            Proposal to the Weekly Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Triggering Requirement</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Triggering Requirement</td>
          <td>Core</td>
          <td>
            An Atlas Edit Weekly Cycle Proposal (also “Weekly Cycle Proposal” or “AEW Proposal”) can proceed to 
            a vote only if it is triggered by a Prime Delegate whose AD Buffer contains at least one (1) month’s 
            worth of budget at the time of triggering the Proposal. The value of this threshold in USDS is currently 
            specified in <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Budget Amount For Prime Delegate
              Slots</dfn>. The Governance Facilitators are responsible for confirming that these requirements are met.<br>Aligned 
            Delegates (including Prime Delegates) are prohibited from authoring an Atlas Edit Weekly Cycle Proposal. Prime Delegates 
            are limited to triggering Proposals authored by others. To trigger a Proposal, the Prime Delegate must post a reply to 
            the Author’s Weekly Cycle Proposal on the Forum. The Prime Delegate’s post should signal their intent to trigger 
            the Weekly Cycle Proposal.<br>Where more than one Prime Delegate posts an intention to trigger a Weekly Cycle Proposal, 
            the first Prime Delegate to post a reply to the Author’s Forum post shall be treated as the triggering Prime Delegate.<br>If 
            the Weekly Cycle Proposal is subsequently voted down, the triggering Prime Delegate loses their entire AD Buffer.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Preparation And Publication of Governance
              Poll</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Preparation And Publication of Governance Poll
          </td>
          <td>Core</td>
          <td>An Atlas Edit Weekly Cycle Proposal should be posted to the Forum by Friday at 8:00 am UTC to ensure
            the Governance Facilitators have sufficient time to prepare the needed polls for the following
            Monday.Every Monday, the Atlas Edit Weekly Cycle is carried out via Governance Polls. The Governance
            Facilitators must publish the set of Governance Polls to the community Github and the official
            Voting Portal.The Polls run for three days. Successful polls trigger direct edits to the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Rejecting A Proposal For Misalignment</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Rejecting A Proposal For Misalignment</td>
          <td>Core</td>
          <td>The Governance Facilitators can reject an Atlas Edit Weekly Cycle Proposal if they deem it to be
            misaligned. If a Facilitator rejects an Atlas Edit Weekly Cycle Proposal for misalignment, the Prime
            Delegate who triggered the poll loses their AD buffer.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Minimum Positive Participation</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Minimum Positive Participation</td>
          <td>Core</td>
          <td>Atlas Edit Weekly Cycle Proposals must have at least 480,000,000 SKY equivalents of Yes votes to be
            accepted.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Reconciliation Process</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Reconciliation Process</td>
          <td>Core</td>
          <td>If multiple Atlas Edit Weekly Cycle Proposals editing the same component of the Atlas are approved
            by voters in the same Governance Cycle, the Reconciliation Process documented herein must be
            followed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Language Disallowing Simultaneous Edits
              Not Allowed</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Language Disallowing Simultaneous Edits Not
            Allowed</td>
          <td>Core</td>
          <td>Atlas Edit Weekly Cycle Proposals cannot include language that aims to prevent other Atlas Edit
            Weekly Cycle Proposals from editing the same component of the Atlas within the same Governance
            Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.11
              - Weekly Governance Cycle - Atlas Edit Weekly Cycle - Simultaneous Edit Reconciliation Process
              Definition</dfn>
          </td>
          <td>Weekly Governance Cycle - Atlas Edit Weekly Cycle - Simultaneous Edit Reconciliation Process
            Definition</td>
          <td>Core</td>
          <td>Where voters approve multiple Atlas Edit Weekly Cycle Proposals that seek to edit the same component
            or components of the Atlas within the same Governance Cycle, the process described below must be
            followed. This process only applies to the specific components that are being simultaneously edited.
            Other amended components that do not have edits in simultaneous proposals may be merged, unless they
            are dependent on the component that does have simultaneous edits.Where simultaneous edits are
            non-conflicting / logically compatible: Governance Facilitators will consolidate them into a single
            edit either by stitching them together in the affected component or by stringing one after the other
            as a new component. Any action taken by the Governance Facilitators in this regard will be
            documented publicly and should be available for examination prior to the end date of the relevant
            polls.Where simultaneous edits are conflicting / logically incompatible and cannot be coherently
            reconciled: it falls to voters to decide which of the conflicting Atlas Edit Weekly Cycle Proposals
            they wish to accept. If there are two conflicting Atlas Edit Weekly Proposals, a subsequent binary
            vote actioned via a single Reconciliation Process Poll is appropriate. In the event there are more
            than two conflicting Atlas Edit Weekly Cycle Proposals, the Governance Facilitators may choose a
            suitable polling method that allows voters to choose between multiple options. The difference
            between the conflicting amendments must be clearly presented so that voters can make an informed
            choice on their preferred option.A Reconciliation Process Poll will take place during the
            Operational Weekly Cycle immediately following the closure of the originating polls. The
            Reconciliation Process Poll will last for three days.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - A1 - Monthly Governance Cycle - Calendar Exceptions</dfn>
          </td>
          <td>Monthly Governance Cycle - Calendar Exceptions</td>
          <td>Section</td>
          <td>Due to the multitude of cultural and religious holidays occurring in and around the month of
            December, there will be no Monthly Governance Cycle in the December of each year.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - A2 - Monthly Governance Cycle - Atlas Edit Monthly Cycle</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle</td>
          <td>Section</td>
          <td>This Section defines the Atlas Edit Monthly Cycle, which provides a predictable framework for
            monthly edits to the Atlas. The Atlas Edit Monthly Cycle is implemented via the Atlas Edit Proposal
            (AEP) framework. In the transition to Endgame, the Atlas can be edited through the submission of an
            AEP. Multiple amendments to multiple components of the Atlas are allowed to be submitted in a single
            AEP. A single AEP may seek to remove multiple components of the Atlas.AEPs must always adhere to the
            Spirit of the Atlas and remain within the bounds of Universal Alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Cycle Breakdown</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Cycle Breakdown</td>
          <td>Core</td>
          <td>The subdocuments herein define infrastructure and processes for the Atlas Edit Monthly Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Origination</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Origination</td>
          <td>Core</td>
          <td>The author of an Atlas Edit Monthly Cycle proposal (”proposal”, “Atlas Edit Proposal”, “AEP”, “Monthly Cycle Proposal”, 
            or “AEM Proposal”) must post the proposal in the Sky Forum under the appropriate category.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Governance Facilitators' Initial
              Verification</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Governance Facilitators' Initial Verification
          </td>
          <td>Core</td>
          <td>
            The Governance Facilitator must verify that the Atlas Edit Proposal follows the template specified
            in <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Template</dfn>.The
            Governance Facilitator must also verify that the AEP has been submitted to the Atlas Github
            repository with a Pull Request by the AEP Author. Alternatively, the AEP author can request the
            Governance Facilitators to create the Pull Request for them. If the AEP is successfully verified,
            the Governance Facilitator must◦ Approve the AEP and assign it a formal #◦ Update the Preamble to
            the AEP◦ Merge the Pull Request
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Request for Comments</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Request for Comments</td>
          <td>Core</td>
          <td>After the Atlas Edit Proposal is verified, a period of reviewing by the community and attendant
            redrafting begins. The minimum duration of this period is determined by the Feedback Period and the
            Frozen Period. The Feedback Period is the minimum amount of time within which the community can give
            feedback in response to an Atlas Edit Proposal before it can advance to Formal Submission. The
            Frozen Period is the minimum amount of time during which an Atlas Edit Proposal must remain
            unchanged before it can advance to Formal Submission. These periods can overlap.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Fulfilled Feedback Period
              Requirements</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Fulfilled Feedback Period Requirements</td>
          <td>Core</td>
          <td>After the Atlas Edit Proposal has fulfilled the requirements for a community feedback period, it is
            ready for Formal Submission.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Submitting To Formal Submission</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Submitting To Formal Submission</td>
          <td>Core</td>
          <td>When the Atlas Edit Proposal is ready for Formal Submission, the AEP Author submits their AEP to the
            Monthly Governance Cycle by posting a Forum comment that states "Formal Submission". This can only
            be done within the Formal Submission window of a Monthly Governance Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Governance Facilitators' Review</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Governance Facilitators' Review</td>
          <td>Core</td>
          <td>The Governance Facilitators are required to review all Atlas Edit Proposals (AEPs) submitted for
            Formal Submission to determine whether they are misaligned.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Procedure For Blocking AEP For
              Misalignment</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Procedure For Blocking AEP For Misalignment
          </td>
          <td>Core</td>
          <td>An Atlas Edit Proposal can be blocked by the Governance Facilitators for misalignment. Unanimity
            among the Governance Facilitators is not required to block an AEP for misalignment. Where an AEP has
            been blocked for misalignment, the Governance Facilitators must update the AEP status as
            "Rejected-Misaligned." Each Governance Facilitator should issue a written advisory opinion
            containing their findings/reasoning either supporting or rejecting the blocking of the AEP.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Resubmitting A Blocked AEP To A Future
              Monthly Cycle</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Resubmitting A Blocked AEP To A Future Monthly
            Cycle</td>
          <td>Core</td>
          <td>An Atlas Edit Proposal that has been blocked for misalignment can be amended and re-submitted in a
            future Atlas Edit Monthly Governance Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Update Status</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Update Status</td>
          <td>Core</td>
          <td>If an AEP has passed the Governance Facilitators' review, the Governance Facilitators must update
            the status of the AEP to "Formal Submission."</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Proposal Enters Monthly Cycle</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Proposal Enters Monthly Cycle</td>
          <td>Core</td>
          <td>Once an Atlas Edit Proposal has been formally submitted and has passed the Governance Facilitators'
            review, the AEP enters the Monthly Governance Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Accepted / Rejected Status</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Accepted / Rejected Status</td>
          <td>Core</td>
          <td>The Atlas Edit Proposal is voted on. If it passes, it is officially accepted and given the
            "Accepted" status. If not, the AEP is rejected and given the "Rejected" status.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Requirements</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Requirements</td>
          <td>Core</td>
          <td>The requirements for an Atlas Edit Proposal are defined in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Parameters</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Parameters</td>
          <td>Core</td>
          <td>Atlas Edit Proposals have the following parameters:◦ Default Feedback Period: one (1) week◦ Frozen
            Period: one (1) week◦ Governance Cycle: Monthly</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Frozen Period Requirement</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Frozen Period Requirement</td>
          <td>Core</td>
          <td>The final version of an Atlas Edit Proposal must be posted on Sky Forum seven (7) days before
            Formal Submission, and cannot move into Formal Submission if it was changed within the last seven
            (7) days.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Template</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Template</td>
          <td>Core</td>
          <td>All Atlas Edit Proposals must use the following template:PreambleAEP#:
            #Author(s):Contributors:Status:Date Proposed: &lt;yyyy-mm-dd&gt;Date Ratified:
            &lt;yyyy-mm-dd&gt;Forum URL:Motivation- Explain the motivation behind this AEP.Edited Atlas
            Documents- List the Atlas Documents that are being edited. Please include the Portal URL pointing to
            the specific Atlas Documents to facilitate identification.Edit Pull Request- Link to the Pull
            Request containing the proposed Atlas Edit. Governance Facilitators can create the Pull Request on
            request.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Statuses</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Atlas Edit Proposal Statuses</td>
          <td>Core</td>
          <td>An Atlas Edit Proposal can be assigned several different statuses: RFC, Formal Submission,
            Rejected-Misaligned, Accepted, Rejected, and Obsolete.RFC (Request For Comments): An AEP is in the
            Request For Comments Period.Formal Submission:An AEP has been moved into Formal Submission to the
            Monthly Governance Cycle.Rejected - Misaligned:An AEP has been blocked by the Governance
            Facilitators from entering the Monthly Cycle due to misalignment.Accepted:An AEP has been voted on
            and is officially accepted. Rejected:An AEP has been voted on and is not officially accepted.
            Obsolete:An AEP is assigned the status Obsolete when:◦ an AEP has been superseded or deprecated• an
            AEP has been deferred for over six (6) months• an AEP Author has abandoned the proposal and no
            person has communicated willingness to take over the responsibility of a AEP Author.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Process Definition</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Process Definition</td>
          <td>Core</td>
          <td>
            The first Monday of each calendar month marks the beginning of the Monthly Governance Cycle.Time is
            inclusive and based on UTC (Coordinated Universal Time) and the Gregorian Calendar.<strong>First
              Wednesday after the first Monday of the month:</strong>◦ The Authors of Atlas Edit Proposals
            must formally submit their AEP before this Day.◦ The Formal Submission must be done through a
            message on the Author's Forum thread that contains the AEP.<strong>Week 1, Friday</strong>After
            reviewing the AEPs, the Governance Facilitators must decide whether each submitted AEP warrants
            moving forward to a Ratification Poll.<strong>Week 2, Monday</strong>The Governance Facilitators
            publish the set of Ratification Polls. The format of these is defined in <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Ratification Poll
              Requirements</dfn>.Ratification Polls are published to the community GitHub, submitted on-chain,
            and appear on the official Voting Portal.<strong>Week 4, Monday</strong>The Ratification Polls
            conclude, and each proposal or set of proposals is marked as either Accepted or Rejected by the
            Governance Facilitators.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Ratification Poll Requirements</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Ratification Poll Requirements</td>
          <td>Core</td>
          <td>Ratification Polls under the Atlas Edit Monthly Governance Cycle must meet these requirements:•
            Duration: two (2) Weeks.• Minimum Positive Participation: 240,000,000 SKY.• Type: Binary Poll
            (yes/no/abstain).Ratification Polls under the Atlas Edit Monthly Governance Cycle must contain:•
            Links to a specific version of a single Atlas Edit Proposal within the official Atlas GitHub.In
            order for a Ratification Poll to conclude successfully and the contained proposal(s) moved to
            Accepted status, triggering an edit of the Atlas, each of the following conditions must be true:•
            Yes vote-weight must exceed No vote-weight when the poll closes.• Yes vote-weight must exceed the
            Minimum Positive Participation value of 240,000,000 SKY when the poll closes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Revision of Minimum Positive
              Participation</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Revision of Minimum Positive Participation
          </td>
          <td>Core</td>
          <td>
            The Minimum Positive Participation value defined in <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Ratification Poll Requirements</dfn> may
            be modified via a successful Governance Poll under the Operational Weekly Governance Cycle.If such a
            vote is successful, the new Minimum Positive Participation value will come into effect in the
            following Monthly Governance Cycle. The Minimum Positive Participation value may not be changed for
            Ratification Polls that are in progress under any circumstances.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Reconciliation Process</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Reconciliation Process</td>
          <td>Core</td>
          <td>If multiple Atlas Edit Proposals editing the same component of the Atlas are approved by voters in
            the same Monthly Governance Cycle, the Reconciliation Process documented herein must be followed.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Language Disallowing Simultaneous Edits
              Not Allowed</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Language Disallowing Simultaneous Edits Not
            Allowed</td>
          <td>Core</td>
          <td>Atlas Edit Proposals cannot include language that aims to prevent other Atlas Edit Proposals from
            editing the same component of the Atlas within the same Governance Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.12
              - Monthly Governance Cycle - Atlas Edit Monthly Cycle - Simultaneous Edit Reconciliation
              Process</dfn>
          </td>
          <td>Monthly Governance Cycle - Atlas Edit Monthly Cycle - Simultaneous Edit Reconciliation Process</td>
          <td>Core</td>
          <td>Where voters approve multiple Atlas Edit Proposals that seek to edit the same component or
            components of the Atlas within the same Governance Cycle, the process described below must be
            followed. This process only applies to the specific components that are being simultaneously edited.
            Other amended components that do not have edits in simultaneous proposals may be merged, unless they
            are dependent on the component that does have simultaneous edits.Where simultaneous edits are
            non-conflicting / logically compatible: Governance Facilitators will consolidate them into a single
            edit either by stitching them together in the affected component or by stringing one after the other
            as a new component. Any action taken by the Governance Facilitators in this regard will be
            documented publicly and should be available for examination prior to the end date of the relevant
            ratification polls.Where simultaneous edits are conflicting / logically incompatible and cannot be
            coherently reconciled: it falls to voters to decide which of the conflicting AEPs they wish to
            accept. If there are two conflicting AEPs, a subsequent binary vote is appropriate in the form of a
            Reconciliation Process Poll. In the event there are more than two conflicting AEPs, the Governance
            Facilitators may choose a suitable polling method that allows voters to choose between multiple
            options. The difference between the conflicting amendments must be clearly presented so that voters
            can make an informed choice on their preferred option.A Reconciliation Process poll will take place
            during the Operational Weekly Cycle immediately following the closure of the ratification polls. The
            Reconciliation Process poll will last for three days.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13
              - A1 - Updating Active Data</dfn>
          </td>
          <td>Updating Active Data</td>
          <td>Section</td>
          <td>This Section defines the processes by which Active Data documents are updated.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13
              - Updating Active Data - Overview</dfn>
          </td>
          <td>Updating Active Data - Overview</td>
          <td>Core</td>
          <td>
            Active Data documents must be maintained and frequently updated as part of the Sky Ecosystem's
            routine operational tasks. See <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Active Data
              Type</dfn>.Therefore, Active Data documents can be directly modified outside of the standard
            Weekly Governance Cycle and Monthly Governance Cycle. Each Active Data document has an Active Data
            Controller document associated with it, which latter defines two elements: 1) the "Responsible
            Party", or the entity who is obligated to update the Active Data, and2) the "Update Process", or the
            authorized process by which the Active Data is updated.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13
              - Updating Active Data - Responsible Party</dfn>
          </td>
          <td>Updating Active Data - Responsible Party</td>
          <td>Core</td>
          <td>The Responsible Party is the entity responsible for updating the Active Data. The Responsible Party
            has the permissions and obligation to update the Active Data through the Update Process specified in
            the respective Active Data Controller Document.Since the Responsible Party element is defined in an
            Active Data Controller Document, modification of that Responsible Party element is subject to a SKY
            vote pursuant to standard governance processes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13
              - Updating Active Data - Update Process</dfn>
          </td>
          <td>Updating Active Data - Update Process</td>
          <td>Core</td>
          <td>The Active Data Update Process specified in any Active Data Controller document must conform to one
            of the processes defined in the subdocuments herein.Since the Update Process element is defined in
            an Active Data Controller Document, modification of that Update Process element is subject to a SKY
            vote pursuant to standard governance processes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13
              - Updating Active Data - Update Process - Direct Edit</dfn>
          </td>
          <td>Updating Active Data - Update Process - Direct Edit</td>
          <td>Core</td>
          <td>Active Data with the "Direct Edit" Update Process may be edited pursuant to the following process.
            The Responsible Party must post on the Sky Forum their proposed changes to the Active Data, using
            the category specified by the relevant Facilitator. After confirming that the Responsible Party has
            the authority to request a Direct Edit, the Governance Facilitators shall then modify the Atlas to
            reflect the Responsible Party's proposed change.It is permissible for an Active Data Controller to
            specify unique requirements in addition to the general "Direct Edit" Update Process described above.
            These additional requirements, if any, must be specified directly in the Active Data Controller
            Document; this can be done through a reference or citation to the pertinent Atlas document
            containing the additional requirements. The additional requirements may supplement, but cannot
            conflict with, any aspect of the "Direct Edit" Update Process defined herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13
              - Updating Active Data - Update Process - Corrections By Governance Facilitators</dfn>
          </td>
          <td>Updating Active Data - Update Process - Corrections By Governance Facilitators</td>
          <td>Core</td>
          <td>
            To correct a clear error, the Governance Facilitators may directly update an Active Data document at
            any time. Prior to taking such action, the Governance Facilitators should notify the respective
            Responsible Party charged with maintaining the Active Data document.However, if the error or issue
            is not clearly evident, the Active Data document must be updated in accordance with the established
            procedure defined in <dfn>A.1.13
              - Updating Active Data - Update Process - Direct Edit</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.13
              - Updating Active Data - Update Process - Alignment Conserver Changes</dfn>
          </td>
          <td>Updating Active Data - Update Process - Alignment Conserver Changes</td>
          <td>Core</td>
          <td>Active Data with the "Alignment Conserver Changes" Update Process pertains to the Governance
            Facilitators' maintenance of the Atlas' official listing of some subset of Alignment Conservers. The
            triggers of such updates can include, but are not limited to, recognizing a new Alignment Conserver;
            offboarding an Alignment Conserver at the request of that Alignment Conserver; adding an Alignment
            Conserver to the list of ACs who have received a formal warning; or derecognizing an Alignment
            Conserver for misalignment.The Governance Facilitators can modify the pertinent Active Data
            documents to reflect such changes immediately; they are not required to create a post on Sky Forum.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.15
              - A1 - Scope Bootstrapping</dfn>
          </td>
          <td>Scope Bootstrapping</td>
          <td>Section</td>
          <td>This Section defines bootstrapping measures that can override requirements and specifications in the
            Atlas. These bootstrapping measures are temporary.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.15
              - Scope Bootstrapping - Multiple Conflicting Atlas Edit Proposals</dfn>
          </td>
          <td>Scope Bootstrapping - Multiple Conflicting Atlas Edit Proposals</td>
          <td>Core</td>
          <td>When conflicting Atlas Edit Proposals are approved within a short period of each other, the
            Governance Facilitators can decide to merge parts of the proposals together to ensure that the
            aggregate changes incorporate the best updates from each of the conflicting proposals.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.15
              - Scope Bootstrapping - Governance Security & Ecosystem Actor Embedding</dfn>
          </td>
          <td>Scope Bootstrapping - Governance Security & Ecosystem Actor Embedding</td>
          <td>Core</td>
          <td>As a temporary bootstrapping measure, incubating Ecosystem Actor Atlas Axis will be embedded in
            Governance Facilitator-permissioned communication channels where Executive Vote-coordination work is
            performed. Atlas Axis will have no decision-making authority in the Executive Vote workstreams. The
            objective is solely to facilitate Atlas Axis' preparation of comprehensive, robust and resilient
            Atlas data for Governance Security by enabling it to directly observe patterns and issues as they
            arise.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.2
              - A1 - Governance Process Support</dfn>
          </td>
          <td>Governance Process Support</td>
          <td>Section</td>
          <td>The Support Scope must facilitate the routine governance processes of the Sky Ecosystem, pursuant to
            the principles and procedures defined herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.2
              - Governance Process Support - In General</dfn>
          </td>
          <td>Governance Process Support - In General</td>
          <td>Core</td>
          <td>Sky Governance deploys various core processes to implement its decisionmaking, including Aligned
            Delegate processes, the Weekly Governance Cycle, the Monthly Governance Cycle and the modification
            of Active Data. The Support Scope regulates routine governance processes based in the explicit rules
            of the Atlas. In contrast, the Governance Scope governs situations in which a document is appealed
            or is otherwise contentious for reasons of ambiguity or conflict with other documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.2
              - Governance Process Support - Coordination Of Scope Framework Processes</dfn>
          </td>
          <td>Governance Process Support - Coordination Of Scope Framework Processes</td>
          <td>Core</td>
          <td>The Scopes establish various specialized processes, including those for submitting governance
            proposals or modifying the Atlas. Support Facilitators are responsible for monitoring and ensuring
            that these processes are executed in accordance with the established rules. An action carried out
            through a Scope-defined process is considered valid only if the Support Facilitators have been
            properly notified.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.2
              - Governance Process Support - Designation Of Governance Process Support Ecosystem Actors</dfn>
          </td>
          <td>Governance Process Support - Designation Of Governance Process Support Ecosystem Actors</td>
          <td>Core</td>
          <td>The Support Facilitators can designate Ecosystem Actors (including individuals, companies or Forum
            or Chat pseudonyms) as Governance Process Support Ecosystem Actors. This designation can include
            granting them moderation rights and other forms of administration rights on the relevant
            communication channels. Governance Process Support Ecosystem Actors can assist with governance
            processes including verifying Atlas Edit Proposals (AEPs), preparing and merging Pull Requests,
            updating the status of AEPs, preparing Polls, editing the Atlas, etc.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.2
              - Governance Process Support - Resources</dfn>
          </td>
          <td>Governance Process Support - Resources</td>
          <td>Core</td>
          <td>
            The Support Facilitators are granted a budget to procure the necessary administrative support and
            services from Governance Process Support Ecosystem Actors. The budget can only be used to perform
            tasks described in <dfn>A.2.2
              - A1 - Governance Process Support</dfn> and its subdocuments. The Support Facilitators can modify
            the budget using an Operational Weekly Governance Cycle poll.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.2
              - Governance Process Support - Resources - Current Budget</dfn>
          </td>
          <td>Governance Process Support - Resources - Current Budget</td>
          <td>Core</td>
          <td>The budget available to fund Governance Process Support tasks is 0 USDS per quarter.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.3
              - A1 - Atlas Core Development</dfn>
          </td>
          <td>Atlas Core Development</td>
          <td>Section</td>
          <td>Atlas development is a critical infrastructure priority, essential for the stability, security, and
            efficient operation of the Sky Ecosystem. It must be fully supported to ensure that all necessary
            elements for safeguarding, managing, and operating the Ecosystem are comprehensively addressed. This
            Section defines processes to support Atlas development.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.3
              - Atlas Core Development - Funding</dfn>
          </td>
          <td>Atlas Core Development - Funding</td>
          <td>Core</td>
          <td>Atlas Core Development can be performed by Ecosystem Actors paid through the Launch Project, or
            through direct funding from Executive Votes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.3
              - Atlas Core Development - Funding - Executive Votes</dfn>
          </td>
          <td>Atlas Core Development - Funding - Executive Votes</td>
          <td>Core</td>
          <td>The Support Facilitators can initiate direct funding through monthly Executive Votes to key Atlas
            contributors.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.3
              - Atlas Core Development - Funding - Direct Funding Cap</dfn>
          </td>
          <td>Atlas Core Development - Funding - Direct Funding Cap</td>
          <td>Core</td>
          <td>The direct funding can at most be 150,000 USDS and 1,000,000 SKY per month.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.3
              - Atlas Core Development - Funding - Direct-Funding Payment Procedure</dfn>
          </td>
          <td>Atlas Core Development - Funding - Direct-Funding Payment Procedure</td>
          <td>Core</td>
          <td>Direct funding payments to Atlas contributors are initiated through requests submitted by the
            contributors themselves. These funding requests are approved by the Support Facilitator, in
            consultation with Atlas Axis or another relevant Ecosystem Actor. Payments are triggered directly by
            the Support Facilitator. Payments can be requested to multiple addresses at once to accommodate
            contributor teams.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.3
              - Atlas Core Development - Funding - Aligned Delegates Eligible to Receive Budget</dfn>
          </td>
          <td>Atlas Core Development - Funding - Aligned Delegates Eligible to Receive Budget</td>
          <td>Core</td>
          <td>
            Aligned Delegates are eligible to receive budgets through this funding process. This constitutes an
            exception to <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - ACs Can Be Operationally Active In Only One
              Role At A Time</dfn>, which generally prohibits ACs from simultaneously assuming multiple
            ecosystem roles.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.5
              - A1 - Star Incubation - Spark Star-Specific Support</dfn>
          </td>
          <td>Star Incubation - Spark Star-Specific Support</td>
          <td>Section</td>
          <td>This Section defines elements and infrastructure to support Spark, the first Sky Star.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.5
              - Star Incubation - Spark Star-Specific Support - Spark Pre-launch Token Rewards</dfn>
          </td>
          <td>Star Incubation - Spark Star-Specific Support - Spark Pre-launch Token Rewards</td>
          <td>Core</td>
          <td>Spark has a pre-launch token rewards program based on the usage of its lending platform. Users of
             the platform will receive an airdrop of SPK tokens, depending on how much and how long they have used
             the platform during the pre-launch token reward period. These rewards are only for users on Ethereum Mainnet.
             <br>There are two seasons of the Spark pre-launch token rewards: Season 1 and Season 2.<br>
             Season 1 of pre-launch token rewards was active from August 20 2023 and lasted for nine months, ending on
             May 20 2024. 60m SPK tokens were allocated in this period. In Season 2 6.66M SPK will be rewarded per month
             to SparkLend users who qualify for the airdrop. Season 2 is an additional pre-farming period, which runs
             until the Spark Star launches as part of Sky Endgame launch season.<br>
             The monthly SPK rewards are allocated as follows:<br>
             • 80 % is allocated to users borrowing DAI and/or USDS • 20 % is allocated to users supplying ETH<br>
            The proposed full anti-cheat SPK Airdrop for SparkLend is calculated using the following formula:<br>
            Airdrop = 80% * (DAI Borrows + USDS Borrows - sDAI Supplies * sDAI Liquidation Threshold - sUSDS Supplies *
            sUSDS Liquidation Threshold) + 20% * (ETH Supplies - ETH Borrows / ETH Liquidation Threshold)<br>
            All supplies and borrows are denominated in USD based on the on-chain oracle price at that block to determine
            the conversion.
        </tr>
        <tr>
          <td>
            <dfn>A.2.5
              - Star Incubation - Spark Star-Specific Support - Special Pre-launch Token Reward Programs</dfn>
          </td>
          <td>Star Incubation - Spark Star-Specific Support - Special Pre-launch Token Reward Programs</td>
          <td>Core</td>
          <td>
            The Support Facilitators can activate a new SPK token pre-launch token reward airdrop program to
            capture other growth opportunities.The program can last until the moment SPK launches, or a shorter
            duration, which must be declared by the Support Facilitators. When activated by the Support
            Facilitators, the exact details of the special pre-launch token reward airdrop program must be
            specified in <dfn>A.2.5
              - Star Incubation - Star Specific Support - Special Pre-launch Token Reward Programs
              Details</dfn>.The SPK tokens for the future Spark Airdrop are allocated between all borrowers
            based on a formula announced by the Support Facilitators and specified in the above cited document.
            The rate of SPK tokens being earned is 3.33 million SPK per month, distributed on a per block basis
            proportional to the formula specified in the above cited document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.5
              - Star Incubation - Spark Star-Specific Support - Special Pre-launch Token Reward Program
              Details</dfn>
          </td>
          <td>Star Incubation - Spark Star-Specific Support - Special Pre-launch Token Reward Program Details</td>
          <td>Active Data Controller</td>
          <td>
            The special pre-launch token reward airdrop program is defined as Active Data in <dfn>A.2.5
              - Star Incubation - Star Specific Support - Special Pre-launch Token Reward Programs
              Details</dfn>.The Active Data is updated as follows:• The Responsible Party is the Support
            Facilitators.• The Update Process must follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.6
              - A1 - Ecosystem Actor Incubation</dfn>
          </td>
          <td>Ecosystem Actor Incubation</td>
          <td>Section</td>
          <td>The Support Scope is responsible for incubating Ecosystem Actors. This Section defines the elements
            to support this objective.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.6
              - Ecosystem Actor Incubation - Incubating Ecosystem Actors</dfn>
          </td>
          <td>Ecosystem Actor Incubation - Incubating Ecosystem Actors</td>
          <td>Core</td>
          <td>Incubating Ecosystem Actors are Ecosystem Actors that are being developed to support the Sky
            Protocol or its current and future Stars. Sky Governance can assign these actors projects that
            benefit the Sky Protocol or incubating Stars, such as solutions for branding, marketing, user
            acquisition; referral marketing and revenue share systems; smart contract development; and protocol
            development.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.6
              - Ecosystem Actor Incubation - Budgets</dfn>
          </td>
          <td>Ecosystem Actor Incubation - Budgets</td>
          <td>Core</td>
          <td>The Support Facilitators have budgets available to support the tasks described in this Section,
            including the Incubation Overhead budget and the Incubation budget.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.6
              - Ecosystem Actor Incubation - Currently Incubating Ecosystem Actors</dfn>
          </td>
          <td>Ecosystem Actor Incubation - Currently Incubating Ecosystem Actors</td>
          <td>Active Data Controller</td>
          <td>
            Incubating Ecosystem Actors and their current key terms and data are defined as Active Data in <dfn>A.2.6
              - Ecosystem Actor Incubation - Currently Incubating Ecosystem Actors - List</dfn>. The Active Data
            is updated as follows:• The Responsible Party is the Support Facilitators.• The Update Process must
            follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.6
              - Ecosystem Actor Incubation - Currently Incubating Ecosystem Actors Template</dfn>
          </td>
          <td>Ecosystem Actor Incubation - Currently Incubating Ecosystem Actors Template</td>
          <td>Core</td>
          <td>The list of Incubating Ecosystem Actors must follow this template for each recorded Incubating
            Ecosystem Actor:• <strong>.x:</strong> [Incubating Ecosystem Actor name and short description]•
            <strong>.1:</strong> [Budget information]• <strong>.2:</strong> [Deliverables and focus areas]•
            <strong>.3:</strong> [Team information, including headcount grouped by skill sets]
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.7
              - A1 - Ecosystem Communication Channels</dfn>
          </td>
          <td>Ecosystem Communication Channels</td>
          <td>Section</td>
          <td>The Support Scope maintains the overall unified communication infrastructure used for governance
            ecosystem communication. This Section defines key elements and infrastructure supporting this
            objective.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.7
              - Ecosystem Communication Channels - Communications Infrastructure</dfn>
          </td>
          <td>Ecosystem Communication Channels - Communications Infrastructure</td>
          <td>Core</td>
          <td>The Support Facilitators are tasked with maintaining an ecosystem-wide communications infrastructure
            to enable Star participants and Ecosystem Actors to interact with each other and discuss the Sky
            Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.7
              - Ecosystem Communication Channels - Communications Infrastructure - Forum</dfn>
          </td>
          <td>Ecosystem Communication Channels - Communications Infrastructure - Forum</td>
          <td>Core</td>
          <td>The communications infrastructure must include an ecosystem Forum devoted to discussions on
            Star-related business proposals, partnerships and interactions, as well as casual conversation for
            the broader Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.7
              - Ecosystem Communication Channels - Communications Infrastructure - Chatroom</dfn>
          </td>
          <td>Ecosystem Communication Channels - Communications Infrastructure - Chatroom</td>
          <td>Core</td>
          <td>The communications infrastructure must include a chatroom for broad discussion related to Stars,
            Ecosystem Actors and Sky. As an initial bootstrapping measure, the Support Facilitators can use
            Discord.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.7
              - Ecosystem Communication Channels - Communications Infrastructure Budget</dfn>
          </td>
          <td>Ecosystem Communication Channels - Communications Infrastructure Budget</td>
          <td>Core</td>
          <td>The ecosystem communication infrastructure budget is 0 USDS per quarter.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.8
              - A1 - Ecosystem Agreements - List Of Active Ecosystem Agreements</dfn>
          </td>
          <td>Ecosystem Agreements - List Of Active Ecosystem Agreements</td>
          <td>Section</td>
          <td>The subdocuments herein record currently active Ecosystem Agreements.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.8
              - Ecosystem Agreements - List Of Active Ecosystem Agreements - Spark Protocol-Aave Revenue
              Share</dfn>
          </td>
          <td>Ecosystem Agreements - List Of Active Ecosystem Agreements - Spark Protocol-Aave Revenue Share</td>
          <td>Core</td>
          <td>Spark Protocol must pay out 10% of the income it generates from operating the borrowing and lending
            functionality of the protocol that is based on the Aave codebase. The payment must be calculated
            manually at the end of each quarter by the Spark Star Facilitators and manually paid as Dai to a
            smart contract under the control of Aave Governance from the Spark Star Surplus Buffer. The payments
            must occur for the revenue share duration of two (2) years, starting from the moment this amendment
            is approved by Sky Governance. If at any point in time after the launch of Star tokens, Spark
            Protocol is generating less than 1 million Dai per year in income for Spark Star, accrual towards
            the revenue share payments are paused (unpaid revenue share that already accrued is still paid out
            at the end of the quarter), and the counting down of the revenue share duration is paused. The
            revenue share payments and the counting down of the remaining revenue share duration is resumed when
            Spark Protocol is generating more than 1 million Dai per year in income again.Before the launch of
            Star tokens, Sky Governance is temporarily responsible for paying out a "virtual revenue share" on
            behalf of Spark Protocol. It is calculated by taking the total amount of Dai borrowed from Spark
            Protocol, and then assuming a "virtual income" equivalent to 1% of this supply, and calculating a
            revenue share of 10% on that basis. The calculations and payments must be done manually by the
            Support Facilitators at the end of each quarter. As an example: if, before the launch of Star
            tokens, 200 million Dai is borrowed on Spark Protocol, then the virtual income is 1% of 200 million
            Dai, which gives 2 million Dai; and of that 2 million Dai the virtual revenue share is 200,000 Dai.
            This 200,000 Dai must be paid out in incremental payments each quarter directly by Sky Governance
            from the Sky Surplus Buffer to a smart contract under the control of Aave Governance. If, before the
            launch of Star tokens, less than 100 million Dai is borrowed from Spark Protocol by the Sky
            Protocol, accrual towards the virtual revenue share payments are paused (unpaid virtual revenue
            share that already accrued is still paid out at the end of the quarter), and the counting down of
            the revenue share duration is paused. The virtual revenue share payments and the counting down of
            the remaining revenue share duration is resumed when at least 100 million Dai is again borrowed from
            Spark Protocol by the Sky Protocol.Once Star tokens launch, the virtual revenue share system will be
            discontinued, and the standard rules of the Spark Protocol Aave Revenue Share Ecosystem Agreement
            shall take effect.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - A1 - Legal Resilience</dfn>
          </td>
          <td>Legal Resilience</td>
          <td>Section</td>
          <td>This Section manages the Resilience Fund (also "RF") and other infrastructure for legal risk
            management and legal governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources</td>
          <td>Core</td>
          <td>This document defines the resources available for legal defense. Over time, it can include both Sky
            Governance-controlled assets and external third-party resources and may be used to cover additional
            risks.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund</td>
          <td>Core</td>
          <td>
            The Resilience Fund (RF) is a self-insurance instrument fully controlled by Sky Governance, which
            will cover legal defense expenses in case of legal or regulatory action against Sky or active
            participants in the Sky Ecosystem. The RF will be the primary source for direct legal defense
            funding. The conditions of use are defined in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Management Process</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Budget</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Budget</td>
          <td>Core</td>
          <td>
            The budget of the Resilience Fund is defined in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Current Budget</dfn>. The Support
            Facilitator can propose to pay out the budget manually through a Weekly Governance Cycle, according
            to the rules related to claims described in this Section. The Support Facilitator can propose
            modifications to the document cited above through the Weekly Governance Cycle.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Current Budget</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Current Budget</td>
          <td>Core</td>
          <td>The current active budget for the Resilience Fund is: 5,000,000 USDS per year, with the full amount
            available at the start of each calendar year.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Transition Funding</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Transition Funding</td>
          <td>Core</td>
          <td>Legal defense expenses directly related to Sky may be temporarily financed using the resources of
            the Resilience Fund. However, a separate Claim Protocol and Standard Operational Protocol must be
            developed to govern cases where Sky is the target of a legal or regulatory action.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee</td>
          <td>Core</td>
          <td>The Resilience Technical Committee is a group of Ecosystem Actors authorized by Sky to provide
            operational support such as onboarding new beneficiaries to the RF, approving quotes, and assessing
            claims to be supported by the RF. Additional operational support includes providing general advice
            on the further development of the fund, amendments to the claim procedure, resilience measures and
            other risk-management topics.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Selection And
              Compensation</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Selection And
            Compensation</td>
          <td>Core</td>
          <td>
            The Support Facilitator selects the members of the Resilience Technical Committee and manages
            payments for their services on a project basis. The associated budget is defined in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Current Budget</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member
              Requirements</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member Requirements
          </td>
          <td>Core</td>
          <td>The individual members of the Resilience Technical Committee who are directly involved in providing
            operational services on behalf of Sky must fulfill the requirements defined in the subdocuments
            herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member Skill
              Set Requirement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member Skill Set
            Requirement</td>
          <td>Core</td>
          <td>Members of the Resilience Technical Committee must have relevant experience or current employment in
            the legal industry, or with a world-leading insurance broker, insurance company, or risk management
            firm.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member
              Experience Requirement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member Experience
            Requirement</td>
          <td>Core</td>
          <td>Members of the Resilience Technical Committee must have at least three (3) years of experience
            managing self-insurance instruments or experience in legal or regulatory risk analysis.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member
              Professional Degree Requirement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member Professional
            Degree Requirement</td>
          <td>Core</td>
          <td>Members of the Resilience Technical Committee must have a law, management, risk, or insurance
            professional degree.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member No
              Conflicts Requirement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member No Conflicts
            Requirement</td>
          <td>Core</td>
          <td>Members of the Resilience Technical Committee must not be involved in any business activity outside
            Sky or in any role within Sky that could result in a conflict of interest, either directly or
            indirectly.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member
              Technology Experience Requirement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Member Technology
            Experience Requirement</td>
          <td>Core</td>
          <td>Members of the Resilience Technical Committee must have at least three (3) years of experience in
            the cryptocurrency, DeFi, Web3, or emerging technology sectors.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Current
              Membership</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee Current Membership
          </td>
          <td>Active Data Controller</td>
          <td>
            Approved Resilience Technical Committee members are defined as Active Data in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee List Of
              Current Members</dfn>.The Active Data is updated as follows:• The Responsible Party is the Support
            Facilitators.• The Update Process must follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Policy</td>
          <td>Core</td>
          <td>This provision and its subdocuments will govern the conditions and terms of use of the Resilience
            Fund.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Loss Events</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Policy Loss Events</td>
          <td>Core</td>
          <td>The Resilience Process covers legal defense or legal representation expenses incurred by a
            participant of the Sky Ecosystem when they are the defendant or respondent in a legal or regulatory
            action ("The Loss Event"). There must be a direct relationship between the legal or regulatory
            action and the Beneficiary's activity at Sky.A (non-exhaustive) list of legal or regulatory actions
            that may qualify is:• Official requirements, or communications, from a regulatory body, governmental
            authority, or a court• Subpoenas• Lawsuit• Writs</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Exclusions</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Policy Exclusions</td>
          <td>Core</td>
          <td>The cases specified in the following subelements will generally be excluded from coverage by the
            legal defense process:• Prior or pending claims• Claims between persons involved in the Sky
            Ecosystem• Loss covered by other insurance• Willful criminal offenses, fraud, or dishonesty•
            Conflict of interest</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Beneficiaries</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Policy Beneficiaries</td>
          <td>Core</td>
          <td>
            Eligible beneficiaries of the Resilience Fund are persons who fulfill the following requirements:a)
            act on their own behalf OR b) act on behalf of a legal entity OR c) act on behalf of a collective
            AND have one of the following roles:Previous Structure:• Recognized Delegates• Core Unit
            Facilitators• Core Unit Contributors• Dai Foundation Board MembersCurrent Structure:• Active SKY or
            Star token holders that participate regularly in governance (e.g., voting, writing proposals)•
            Alignment Conservers ◦ Aligned Delegates (ADs)• Scope Facilitators• The Guardian( <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - The Guardian</dfn>) or actors that fulfill an
            equivalent role.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - No Acquired Right Or Claim For Resilience Fund
              Policy Beneficiaries</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - No Acquired Right Or Claim For Resilience Fund Policy
            Beneficiaries</td>
          <td>Core</td>
          <td>
            Persons qualified as beneficiaries do not have any acquired right or claim. The claim decision
            process is described in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Processes And Principles</dfn>, and
            the payout of a claim is subject to the approval of the Resilience Technical Committee (at their
            sole and absolute discretion) and further contingent on a SKY vote endorsing payment of the claim.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Geographic Coverage</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Policy Geographic Coverage</td>
          <td>Core</td>
          <td>Geographical coverage is worldwide.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Effective Date</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Policy Effective Date</td>
          <td>Core</td>
          <td>A Beneficiary's eligibility for coverage under this Artifact will start after ratification of
            MIP106: 2023-03-27. ("Effective Date") and expire twenty-four (24) months after cessation of their
            role as a Beneficiary.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Base Of Coverage</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Policy Base Of Coverage</td>
          <td>Core</td>
          <td>
            Coverage is "Claims made". This means the Loss Event (<dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Loss Events</dfn>) must
            occur after the Effective Date (<dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Policy Effective Date</dfn>).The
            facts and circumstances that originated the Loss Event may have occurred in the past for a maximum
            period of up to twenty-four (24) months before the date representing the later of (a) the Effective
            Date and (b) the date the Beneficiary is first eligible for coverage under this Artifact (the
            "Retroactivity Period").
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Processes And Principles</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Processes And Principles</td>
          <td>Core</td>
          <td>Overview of the related processes and principles:• Application process• Claim management process•
            Caps and Exclusions• Refund of amounts to the Resilience Fund</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Application Process</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Application Process</td>
          <td>Core</td>
          <td>The Resilience Fund application process is defined in the subdocuments of this document.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Proof Of Eligibility</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Proof Of Eligibility</td>
          <td>Core</td>
          <td>To become recognized as a Beneficiary, an Applicant must first select an Ethereum address that is
            linked to their activity at Sky ("Proof of Eligibility" or "POE"). Each Beneficiary type will have
            specific Proofs of Eligibility that are suitable for their role.Valid PoE:• Address set as owner and
            used to sign transactions from Sky multisigs, such as Core Unit operational wallets, auditor wallets
            or SPFs (old structure), or a Facilitator multisig (Endgame Structure) ◦ PoE valid for former Core
            Unit Contributors, Core Unit Facilitators, and Scope Facilitators.• Address that voted directly or
            through delegation in at least ten Governance Polls or Executive Votes. ◦ PoE valid for active MKR
            or SKY holders, former Recognized Delegates (old structure), and Aligned Delegates (new structure)•
            Address that received compensation from Sky, with the following conditions: ◦ at least six (6)
            payouts spread over at least six (6) months in Dai or USDS OR ◦ Dai or USDS DssVest stream spanning
            at least six (6) months OR ◦ 3 MKR or SKY payouts spread over at least three (3) months OR ◦ MKR or
            SKY DssVest stream spanning at least three (3) months ◦ PoE valid for former Core Unit Contributors
            and Facilitators• Address that holds &gt;1 MKR or &gt;24,000 SKY• Attestation ◦ If no PoE is
            available, a verified Beneficiary must attest eligibility on behalf of the applicant. ◦ This PoE
            will be used exceptionally if no other Proof is available and will be assessed individually by the
            Resilience Fund Technical Committee.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Proof Of Eligibility Template</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Proof Of Eligibility Template</td>
          <td>Core</td>
          <td>Applications for the Resilience Fund must follow this template:• .x: [Application RF]• .x.1: [PoE]•
            .x.2: [Active Period]• .x.3: [Relevant Executive Proposal: Governance decision ratified by a
            governance vote]• .x4: [Signature hash]</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Proof Of Eligibility Digital
              Signature</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Proof Of Eligibility Digital Signature
          </td>
          <td>Core</td>
          <td>
            The Applicant for the Resilience Fund must additionally sign an application message from the
            Ethereum Address (Digital Signature) used as PoE <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Proof Of Eligibility</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Application Resilience Fund Application Terms And
              Conditions</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Application Resilience Fund Application Terms And
            Conditions</td>
          <td>Core</td>
          <td>
            By signing this message, the Applicant accepts and agrees:• To comply with the terms and rules of
            <dfn>A.2.9</dfn> (the "Legal
            Resilience Fund Terms").• That participation in the program is opt-in and voluntary and can be
            waived anytime by the Beneficiary.• The Legal Resilience Fund Terms can be amended at any time
            through the established governance processes.• That being registered as Beneficiary does not give
            rise to any right, benefit, entitlement, or claim, nor creates an obligation on any party to pay the
            Beneficiary.Additionally, the Beneficiary declares that:• No situation currently involves or appears
            to involve a conflict of interest, and any emerging potential conflict of interest shall be
            disclosed as soon as it happens.• Any role change in Sky or termination of active engagement will be
            immediately communicated to the Resilience Technical Committee.The Resilience Technical Committee
            will elaborate a user-friendly onboarding manual for the RF.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Application Confirmation</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Application Confirmation</td>
          <td>Core</td>
          <td>The Applicant for the Resilience Fund will additionally send an encrypted message to the Resilience
            Technical Committee Member in charge of the onboarding process to confirm the application.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Approval Process And
              Verifiability</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Approval Process And Verifiability</td>
          <td>Core</td>
          <td>PoEs rely on a governance decision that was ratified by an Executive Vote.The Resilience Technical
            Committee Member must identify this governance decision by verifying the spell that enacted the
            Executive Vote ratifying the respective governance decision. This spell contains the hash of the
            respective Executive Vote. Exceptional circumstances where no direct governance decision is
            available or difficult to assert will be handled case by case.The Resilience Technical Committee
            Member will confirm the onboarding decision via an encrypted message to the Applicant.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Management Process</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Management Process</td>
          <td>Core</td>
          <td>Overview of the claim management processes:• Legal Counsel Pre-approval• Claim approval / Advance
            Payment• Reimbursement</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Legal Counsel And Quote
              Pre-Approval</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Legal Counsel And Quote Pre-Approval
          </td>
          <td>Core</td>
          <td>The first step in the claim management process is to approve the Legal Counsel to undertake legal
            defense or representation and the quote presented to commence legal work. The Beneficiary must
            present the quote from the law firm they selected for their legal defense/representation. The
            request must indicate at least the following:• Name of Legal Counsel• Name of Law Firm• If not in
            the Lawyer Registry, Proof of Eligibility• QuoteThe quote must include:1. The initial payment
            required by Counsel to commence work immediately. This is the initial amount to be claimed against
            the Resilience Fund.2. A global estimated fee based on an hourly rate OR fixed fee OR monthly
            retainer fee.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Qualified Counsel</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Qualified Counsel</td>
          <td>Core</td>
          <td>
            If the Legal Counsel is RF-qualified in the Lawyer Registry (<dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry</dfn>), the claim is automatically
            submitted to the Claim Approval process (<dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval</dfn>).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Not Resilience Fund Qualified Counsel</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Not Resilience Fund Qualified Counsel</td>
          <td>Core</td>
          <td>
            If Legal Counsel is NOT RF-qualified in the Lawyer Registry (<dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry</dfn>), then the Support
            Facilitators, or alternatively the Resilience Fund Technical Committee Member, will verify if the
            Legal Counsel complies with requisites in Lawyer Registry Acceptance Criteria and LR Resilience Fund
            Acceptance Criteria. See: <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Acceptance Criteria</dfn> and <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Representation
              Requirements</dfn>.If the Legal Counsel of the quote is determined by the Resilience Technical
            Committee to comply with the requirements of this Artifact, the quote is pre-approved and the legal
            counsel is added to the LR.If the Legal Counsel doesn't comply with the LR requirements, the claim
            is rejected and the Beneficiary must propose a different Legal Counsel.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval</td>
          <td>Core</td>
          <td>If a Beneficiary incurs a Loss Event, they can submit a Reimbursement Payout Claim against the LD RF
            according to the process specified in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Payout Claim</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Payout Claim</td>
          <td>Core</td>
          <td>The Support Facilitator must review the Reimbursement Claim and decide whether to trigger a
            Governance Poll to perform a claims payout, by developing an internal model with input from experts
            and professionals.The Payout Reimbursement Claim must contain the following elements: ◦ Description
            of Loss Event with relevant commentaries and context ◦ Advance Payment or Reimbursement ◦ Type of
            process ◦ Date of writ/subpoena/lawsuit ◦ Supportive Documentation ▪ Law firm's proposal and invoice
            OR quote ▪ Copy of the Lawsuit/writ/ communication OR official requirement issued by a Court or
            Governmental Agency Supportive documentation is highly sensible. It is required to use encryption
            tools.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Coverage
              Framework</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Coverage Framework</td>
          <td>Core</td>
          <td>In consultation with the Resilience Technical Committee, the Support Facilitators must develop a
            framework for establishing limits and coverage amounts per case, and apply these limits to
            individual claims.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Support
              Facilitators Review</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Support Facilitators
            Review</td>
          <td>Core</td>
          <td>The Support Facilitators will review the Payout Claim and if it contains all required elements and
            supportive documentation, will immediately transmit it to the Resilience Fund Technical Committee.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Technical Commitee
              Review</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Technical Commitee
            Review</td>
          <td>Core</td>
          <td>The Resilience Fund Technical Committee will verify the merits of the claim according to the
            following substantial criteria (non-exhaustive list):• Absence of Exclusions• Identity and Role of
            Beneficiary• Time scope• Authenticity of writ/lawsuit• Reasonability of lawyer fees, which must take
            into account market rates in the respective jurisdiction</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Technical
              Committee Review Process</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Technical Committee
            Review Process</td>
          <td>Core</td>
          <td>From the moment the Payout Claim is filed, the Resilience Technical Committee will have five (5)
            working days to provide a payout recommendation. The recommendations of the Technical Committee are
            made in their sole and absolute discretion, are definitive, and are not subject to appeal.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Quorum And
              Decision Majorities</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Quorum And Decision
            Majorities</td>
          <td>Core</td>
          <td>Decisions related to claim payouts require a quorum of three (3) experts from the Resilience
            Technical Committee with a simple majority (&gt;50%).</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Decision
              Protections</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Decision Protections
          </td>
          <td>Core</td>
          <td>The recommendations of the Resilience Technical Committee are non-binding and will not give rise to
            any right or claim to the beneficiaries nor give rise to any obligation or responsibility.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Support
              Facilitators Decision</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Claim Approval Support Facilitators
            Decision</td>
          <td>Core</td>
          <td>Based on the recommendation of the Resilience Technical Committee, the Support Facilitators will
            decide whether to trigger a Governance Poll through the Weekly Governance Cycle to perform a claim
            payout.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Payout / Reimbursement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Payout / Reimbursement</td>
          <td>Core</td>
          <td>
            If the Governance Poll for paying out a claim is successful, an Executive Vote must be created and
            approved through Sky Governance processes to draw the funds from the Surplus Buffer and send them to
            the Beneficiary's registered wallet. The spend must be accounted for in the budget in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Current Budget</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Caps And Exclusions</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Caps And Exclusions</td>
          <td>Core</td>
          <td>Unless otherwise approved by a governance vote of Sky, claim funds approved under this Section are
            subject to the caps and exclusions specified in the subdocuments of this document.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Aggregate Cap</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Aggregate Cap</td>
          <td>Core</td>
          <td>Claims will be subject to an aggregate cap for all claims in relation to a Claim Event determined by
            the risk models elaborated by the Resilience Technical Committee.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Direct Costs And Legal Expenses
              Cap</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Direct Costs And Legal Expenses Cap
          </td>
          <td>Core</td>
          <td>Claims can only be used to reimburse Beneficiaries for their losses and disbursements directly
            arising from a Claim Event, and reasonable legal expenses. "Reasonable legal expense" is a variable
            amount that will be determined taking into account the average market rates of the respective
            jurisdiction.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Caps Government Or Regulatory
              Fines Or Damages Exclusion</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Caps Government Or Regulatory Fines Or
            Damages Exclusion</td>
          <td>Core</td>
          <td>Must not be used to reimburse the payment of government or regulatory fines or damages awarded by
            the court.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Refund Of Amounts To Resilience Fund</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Refund Of Amounts To Resilience Fund</td>
          <td>Core</td>
          <td>Where Beneficiaries receive financial benefit or reimbursement of any type as a result of orders of
            a court, governmental or investigative body or regulatory agency that results in a windfall to the
            Beneficiary, these windfall amounts will be returned by the Beneficiary to the Resilience Fund
            within 14 days of receipt.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Refund Of Amounts To Resilience Fund Examples</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Refund Of Amounts To Resilience Fund Examples</td>
          <td>Core</td>
          <td>
            By way of example only and without limiting the generality of the principle described in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Refund Of Amounts To Resilience Fund</dfn>, such
            amounts include, without limitation:• Amounts awarded by a court towards the Beneficiary's legal
            fees or disbursements;• An award of damages to a Beneficiary in relation to a Claim Event;• Monies
            or digital assets located by police or other investigative bodies that were identified as the
            property of Sky; and• Interest payable to a Beneficiary in relation to a Claim Event.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Litigation / Defense
              Management</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Litigation / Defense Management</td>
          <td>Core</td>
          <td>Beneficiaries and their legal teams must, in the conduct of the litigation and as a condition of
            receiving reimbursement from the Resilience Fund, satisfy all of the conditions listed in the
            subdocuments of this document.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Good Faith In Resilience Fund Litigation /
              Defense Management</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Good Faith In Resilience Fund Litigation / Defense
            Management</td>
          <td>Core</td>
          <td>Beneficiaries and their legal teams must act honestly, consistently, and fairly in handling claims
            and litigation.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Promptness In Resilience Fund Litigation /
              Defense Management</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Promptness In Resilience Fund Litigation / Defense
            Management</td>
          <td>Core</td>
          <td>Beneficiaries and their legal teams must make an early assessment of the prospects of success and
            deal with claims promptly.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Cost Control In Resilience Fund Litigation /
              Defense Management</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Cost Control In Resilience Fund Litigation / Defense
            Management</td>
          <td>Core</td>
          <td>Beneficiaries and their legal teams must keep costs to a minimum and avoid reliance on technical
            defenses which have low probability of success.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Alternative Dispute Resolution In Resilience Fund
              Litigation / Defense Management</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Alternative Dispute Resolution In Resilience Fund
            Litigation / Defense Management</td>
          <td>Core</td>
          <td>Beneficiaries and their legal teams must consider alternative dispute resolution (ADR) options at
            all times.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry</td>
          <td>Core</td>
          <td>
            The Lawyer Registry (also "LR") is a registry of specialized Ecosystem Actors who are qualified to
            perform legal work for Sky Ecosystem or participants in the Sky Ecosystem, including, but not
            limited to, legal representation or legal defense.Lawyers will be onboarded in the Lawyer Registry
            covering at least the areas specified in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Covered Areas</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Covered Areas</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Covered Areas</td>
          <td>Core</td>
          <td>| Category | Areas of Law | Examples
            ||----------------------------------|------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------||
            Disputes/Investigations | Regulatory Enforcement - Securities/Finance Law | SEC/FinCEN/CFTC/Central
            Bank matters, Tax authority actions, OFAC Orders, Sanctions || | Securities Law Disputes (private
            party claims, class actions, etc.) | SKY investor claims, Lawsuits against Sky CORE actors || |
            Intellectual Property | Patent Claims/Trolls, Trademark Claims/Trolls || | General Litigation - Any
            other Party-Party Disputes | Disputes between Sky and 3rd party suppliers, Breach of contract
            disputes, Employment law disputes, Disputes between Sky and Ecosystem actors || Commercial Matters
            (non-litigious) | Commercial and Contracts | Commercial transactions (Audits, listing agreements,
            inter-Star agreements affecting Sky Core etc.), Contracts and Procurement (includes contract
            management), Competition/Anti-Trust Law, Data protection and Privacy, Insurance Law || |
            Intellectual Property, Information Technology | IT procurement, licenses, and contracts, Convergent
            technologies, Intellectual property rights, Data protection and privacy, Trademark/Patent
            applications || | Corporate Structuring, Entity Formation/Reporting, Corporate Financing and Tax |
            Entity formation assistance provided to Sky Core, Annual Reporting/Filings, Company Law, Corporate
            Finance, Tax Law |</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Acceptance Criteria</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Acceptance Criteria</td>
          <td>Core</td>
          <td>To be included in the Lawyer Registry, lawyers must satisfy all requirements described in the
            following subelements.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Licensing Criterion</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Licensing Criterion</td>
          <td>Core</td>
          <td>Licensed legal professionals in their respective jurisdiction.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Technology Experience
              Criterion</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Technology Experience Criterion</td>
          <td>Core</td>
          <td>Proven experience with Sky Ecosystem crypto, or emerging technologies.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry No Conflicts Criterion</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry No Conflicts Criterion</td>
          <td>Core</td>
          <td>No Conflict of Interest in the matter over which they have carriage.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Conflict Checks Criterion</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Conflict Checks Criterion</td>
          <td>Core</td>
          <td>Lawyers must have internal processes to conduct conflict checks prior to any engagement under this
            Section.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Conflict Handling Criterion</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Conflict Handling Criterion</td>
          <td>Core</td>
          <td>Where conflicts arise within the lawyer's firm, the firm must:1. In the case where a Beneficiary is
            handling the claim, cease all further work and immediately notify the Resilience Technical Committee
            in writing and cooperate with the Resilience Technical Committee to avoid a continuing conflict or,
            where this is not practicable, transfer the matter to another LR registered Lawyer, and2. In the
            case where the Guardian is handling the claim, cease all further work and immediately notify the
            Guardian in writing and cooperate with the Guardian to avoid a continuing conflict or, where this is
            not practicable, transfer the matter to another LR registered Lawyer.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Representation Requirements</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Representation Requirements</td>
          <td>Core</td>
          <td>Legal counsel providing services funded through the RF must fulfill additional requirements
            specified in the subdocuments herein. Legal counsel qualified for RF will be listed as such in the
            Lawyer Registry.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Representation Experience
              Requirement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Representation Experience Requirement
          </td>
          <td>Core</td>
          <td>Lead Counsel, Lead Barristers, and Lead Trial Attorneys (as applicable) must each have a minimum of
            ten (10) years of relevant legal experience and demonstrable expertise in the specific areas of law,
            legal processes, and jurisdictions listed on the Lawyer Registry.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Representation Expertise
              Requirement</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Representation Expertise Requirement
          </td>
          <td>Core</td>
          <td>
            Lawyers included on the Lawyer Registry for litigious categories, must have been Lead Counsel in at
            least 15 cases in the relevant area of law, type of process, and jurisdiction for which they are
            listed. Lawyers included on the Lawyer Registry for non-litigious matters must have demonstrable
            experience in the relevant area of law, type of process and jurisdiction indicated in the table set
            out under <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Covered Areas</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Template</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Template</td>
          <td>Core</td>
          <td>Entries in the LR must follow this template:• .x: [Advisor name and short description]• .x.1: [Name
            of Firm]• .x.2: [Specialization Area]• .x.3: [Jurisdiction]• .x.4: [RF qualified (y/n)]</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Requirements For Resilience Technical
              Committee</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Requirements For Resilience Technical Committee</td>
          <td>Core</td>
          <td>The Resilience Technical Committee will verify the eligibility criteria of new candidates in the
            Lawyer Registry and submit a list of approved candidates to the Support Facilitators.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Update Process</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Update Process</td>
          <td>Active Data Controller</td>
          <td>
            The current approved lawyers in the Lawyer Registry are defined as Active Data in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Current Approved Legal
              Counsels</dfn>. The Active Data is updated as follows:• The Responsible Party is the Support
            Facilitators.• The Update Process must follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - The Guardian</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - The Guardian</td>
          <td>Core</td>
          <td>The Guardian is a specialized Ecosystem Actor that will be exclusively mandated to retain and
            instruct counsel to assist with the legal defense of actors in the Sky Ecosystem that, due to their
            organizational structure or circumstances, may be unable to obtain legal representation when
            pursuing or defending claims against adversarial parties.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Legal Defense Standard Operational Protocols</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Legal Defense Standard Operational Protocols</td>
          <td>Core</td>
          <td>This document must define the Standard Operational Protocols (SOPs) for reacting against legal or
            regulatory actions against a participant of the Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Risk Management</dfn>
          </td>
          <td>Legal Resilience - Legal Risk Management</td>
          <td>Core</td>
          <td>This document defines the framework for managing, retaining, transferring, and structuring legal
            risk through instruments such as self-insurance and insurance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Risk Management - The Policyholder</dfn>
          </td>
          <td>Legal Resilience - Legal Risk Management - The Policyholder</td>
          <td>Core</td>
          <td>
            The Policyholder is a specialized Ecosystem Actor in charge of executing agreements with external
            entities with the exclusive purpose of structuring and transferring risk to third parties through
            instruments such as insurances, reinsurances, mutuals, or other types of arrangements. These
            instruments will provide extended risk coverage for participants of the Sky Ecosystem and Stars.The
            object of the Policyholder is to• Act as a legal counterparty with insurance brokers, insurance,
            reinsurance, underwriters, or risk management companies.• Act as a policyholder of insurance
            contracts, which will have as beneficiaries participants of the Sky Ecosystem.• Hire suppliers and
            contractors necessary for the operation of self-insurance or insurance instruments, such as ◦ The
            Resilience Technical Committee for claim management ◦ Managers, Directors, and other executive staff
            of the legal vehicle. The power of directors will be limited to administrative and operative
            roles.Sky Governance will have all necessary control mechanisms over the Policyholder:• Sky
            Governance can designate and remove Directors, Supervisor, and Committees• Sky Governance can
            instruct the entity to act and ratify decisions• Power of directors is limited to
            administrative/operative roles• The Policyholder will not manage Sky's assets nor will be legally
            affiliated with Sky.The setup and operational budget of the legal vehicle will be sourced initially
            from the <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Current Budget</dfn>. This is
            intended to move later to a separate budget.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Risk Management - Policyholder Management</dfn>
          </td>
          <td>Legal Resilience - Legal Risk Management - Policyholder Management</td>
          <td>Core</td>
          <td>
            This document governs the adding and removing of Policyholders. SKY holders must first approve the
            structure and associated costs of the Policyholder, based on a Governance Poll initiated by
            Facilitators if they deem it necessary.The list of currently approved Policyholders is maintained in
            <dfn>A.2.9
              - Legal Resilience - Legal Risk Management - Current Active Policyholders</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Risk Management - Current Active Policyholders</dfn>
          </td>
          <td>Legal Resilience - Legal Risk Management - Current Active Policyholders</td>
          <td>Core</td>
          <td>There are currently no active Policyholders.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Privacy and Operational Security</dfn>
          </td>
          <td>Legal Resilience - Privacy and Operational Security</td>
          <td>Core</td>
          <td>This document must define policies pertaining to operational security, privacy, and pseudonymity for
            participants in the Sky Ecosystem. The general purpose of this framework is to maximize security and
            safety for contributors and users and minimize potential attack vectors for the Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Advocacy And Public Policy</dfn>
          </td>
          <td>Legal Resilience - Advocacy And Public Policy</td>
          <td>Core</td>
          <td>This document defines the framework and processes for public policy, advocacy, and governmental
            relations. The general purpose of this framework is to develop innovative regulatory frameworks and
            standards that protect open source resources and position the Public Good Purpose of the Sky
            Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal And Regulatory Risk Monitoring</dfn>
          </td>
          <td>Legal Resilience - Legal And Regulatory Risk Monitoring</td>
          <td>Core</td>
          <td>This document defines the general framework and standard processes for monitoring and assessing risk
            and implementing responses. Risk assessment will include external/jurisdictional risk monitoring and
            internal risk monitoring.Responses will be structured as Standard Operational Protocols (SOPs). The
            categories of Legal and Regulatory Risk Monitoring responses are:• Preventive responses that reduce
            the likelihood of occurrence of a risk event• Reactive responses that reduce the severity of
            consequences if the risk event materializes.• Emergency Responses and Contingency Plans.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Public Procurement Framework</dfn>
          </td>
          <td>Legal Resilience - Public Procurement Framework</td>
          <td>Core</td>
          <td>This document defines a Public Procurement Framework for contributors and actors involved in the Sky
            Ecosystem. The purpose is to develop a standard framework that governs the entire lifecycle of
            service providers, which includes the following processes:• Application process• Selection process
            (scoring / evaluating proposals or applications)• Hiring and payment process• Performance evaluation
            and reporting• Terminating involvement and resolving disputes</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Audit Procedure for Atlas Amendments</dfn>
          </td>
          <td>Legal Resilience - Audit Procedure for Atlas Amendments</td>
          <td>Core</td>
          <td>This document must define the procedure for performing ex-post legal and technical audits of amended
            Atlas documents. The general purpose of this procedure is to ensure internal consistency and
            alignment of the Atlas as a whole.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Technical And Legal Standards</dfn>
          </td>
          <td>Legal Resilience - Technical And Legal Standards</td>
          <td>Core</td>
          <td>
            This document defines the required technical-legal standards and tools such as, but not limited to,
            legal agreements (<dfn>A.2.8</dfn>),
            templates, and legal structures required to perform specific functions or roles in the Sky
            Ecosystem. The general purpose of this framework is to minimize trust assumptions and dependencies
            on specific actors, minimize personal exposure, and increase the accountability and predictability
            in their behavior.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Code And Asset Licenses</dfn>
          </td>
          <td>Legal Resilience - Code And Asset Licenses</td>
          <td>Core</td>
          <td>Ecosystem Actors should generally release code and assets under the Apache 2.0 license, unless there
            are specific and clear reasons to use a different license, as determined by the Support
            Facilitators.The Support Facilitators must ensure that a Foundation and other appropriate legal
            entities exists to properly protect intellectual property and trademarks related to the Sky
            Ecosystem.Such Foundations or other entities must over time be set up to follow instructions from
            Sky Governance.All Ecosystem Actors must take steps to protect the brands and trademarks relevant to
            the Sky Ecosystem, and in doing so must follow guidelines and best practice defined by the
            Foundations related to Trademarks, Code and Asset licenses.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - A1 - Resilience Research And Preparedness</dfn>
          </td>
          <td>Resilience Research And Preparedness</td>
          <td>Section</td>
          <td>The Support Scope is responsible for conducting ongoing resilience and preparedness research.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Role Of Support Facilitators</dfn>
          </td>
          <td>Resilience Research And Preparedness - Role Of Support Facilitators</td>
          <td>Core</td>
          <td>The Support Facilitators must ensure that resilience research and preparedness efforts are
            continuously maintained to ensure the ecosystem is well-positioned to handle any legal uncertainty
            or risk that should arise. These projects must generally be broadly diversified across all
            jurisdictions where the Sky Ecosystem could be directly or indirectly exposed, but efforts and
            resources must be prioritized towards jurisdictions where risks are more likely to emerge.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Budget</dfn>
          </td>
          <td>Resilience Research And Preparedness - Budget</td>
          <td>Core</td>
          <td>
            The Resilience Research and Preparedness budget is specified in <dfn>A.2.10
              - Resilience Research And Preparedness - Budget - Current Budget</dfn>. The Support Facilitators
            can trigger a payout from the budget to a relevant recipient address through a Governance Poll.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Budget - Current Budget</dfn>
          </td>
          <td>Resilience Research And Preparedness - Budget - Current Budget</td>
          <td>Core</td>
          <td>The Resilience Research and Preparedness budget is• Up to 2,000,000 USDS available per year.The full
            amount is immediately available at the start of the calendar year.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Research Objectives</dfn>
          </td>
          <td>Resilience Research And Preparedness - Research Objectives</td>
          <td>Core</td>
          <td>Resilience Research and Preparedness (also "Resilience Research") projects must fulfill at least one
            of the following objectives:• Bootstrap necessary infrastructure to develop one of the high-order
            legal resilience objectives as defined in this Article: ◦ Legal Defense ◦ Legal Risk Management ◦
            Privacy and Operational Security ◦ Advocacy and Public Policy ◦ Legal and Regulatory Risk Monitoring
            ◦ Public Procurement Framework ◦ Atlas Amendment and Audit ◦ Technical and Legal Standards• Design
            and implement processes that contribute directly to one of the high-order legal resilience
            objectives defined in this Article.• Implement specific preventive or reactive legal risk mitigation
            tools.• Execute specific activities or tasks necessary to fulfill one of the high-order legal
            resilience objectives defined in this Article.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Application Process</dfn>
          </td>
          <td>Resilience Research And Preparedness - Application Process</td>
          <td>Core</td>
          <td>
            Ecosystem Actors can apply for a Resilience Research Project by submitting a proposal to be
            processed by the Support Scope. To submit a Resilience Research Proposal, the Ecosystem Actor must
            make a post on the Sky Forum following the template provided in <dfn>A.2.10
              - Resilience Research And Preparedness - Application Process - Application Template</dfn> and
            comply with all requirements described in the subdocuments herein.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Application Process - Costs And Benefits</dfn>
          </td>
          <td>Resilience Research And Preparedness - Application Process - Costs And Benefits</td>
          <td>Core</td>
          <td>Resilience Research Proposals must provide a clear and detailed account of both direct and indirect
            costs, as well as the anticipated results and benefits in relation to the Resilience Research
            Objectives.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Application Process - Team</dfn>
          </td>
          <td>Resilience Research And Preparedness - Application Process - Team</td>
          <td>Core</td>
          <td>Resilience Research Proposals must detail their headcount, team skillset composition, and reliance
            on third parties.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Application Process - Timeline And Milestones</dfn>
          </td>
          <td>Resilience Research And Preparedness - Application Process - Timeline And Milestones</td>
          <td>Core</td>
          <td>Resilience Research Proposals must provide a clear timeline with detailed, granular milestones and
            the KPIs to review at each milestone.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Application Process - Risk Mitigation Impact</dfn>
          </td>
          <td>Resilience Research And Preparedness - Application Process - Risk Mitigation Impact</td>
          <td>Core</td>
          <td>Resilience Research Proposals must justify how the project will mitigate a specific risk or help
            bootstrap resources necessary to improve legal resilience.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Application Process - Application Template</dfn>
          </td>
          <td>Resilience Research And Preparedness - Application Process - Application Template</td>
          <td>Core</td>
          <td>
            Applications for Resilience Research projects must follow this template:• .x: [Project Name]• .x.1:
            [Project Abstract: In 3-5 sentences, what problem are you trying to solve?]• .x.2: [Objectives: What
            are you hoping to accomplish? How do you define and measure success for this project?]• .x.3:
            [Outcomes: How does this project benefit the Sky Ecosystem? How does this project help fulfill one
            of the Legal Resilience Objectives in <dfn>A.2.9</dfn>]• .x.4:
            [Scope: What will you research/build /design/implement? What is the expected output?]• .x.5:
            [Project Team: How many people are working on this project? Please list their names and roles for
            the project and how many hours per month each person will work on this project?]• .x.6: [Background:
            Relevant links, reference to other projects or research papers]• .x.7: [Methodology: How do you plan
            to achieve your objectives?]• .x.8: [Timeline: Please include a brief explanation of the
            milestones/roadmap, along with expected deliverables and KPIs.]• .x.9: [Budget: Requested grant
            amount and how this will be used. Please provide the requested amount and outline how the funds will
            be used.]
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Review Process</dfn>
          </td>
          <td>Resilience Research And Preparedness - Review Process</td>
          <td>Core</td>
          <td>The Support Facilitators must ensure the highest quality Research Proposals are thoroughly reviewed.
            The Support Facilitators should document their application evaluations and publish these in the Sky
            Forum prior to triggering a governance vote to fund a proposal.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Review Process - Budget Availability</dfn>
          </td>
          <td>Resilience Research And Preparedness - Review Process - Budget Availability</td>
          <td>Core</td>
          <td>Proposals should only be reviewed if there is an available budget in the Resilience Research and
            Preparedness budget.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Review Process - Factors To Consider</dfn>
          </td>
          <td>Resilience Research And Preparedness - Review Process - Factors To Consider</td>
          <td>Core</td>
          <td>
            Multiple factors should be considered holistically when reviewing Resilience Research Proposals,
            including the amount of remaining budget, the potential impact on the Resilience Research
            Objectives, and, whether the Resilience Research Proposals help improve legal resilience as
            described in <dfn>A.2.9</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Review Process - Approval Process</dfn>
          </td>
          <td>Resilience Research And Preparedness - Review Process - Approval Process</td>
          <td>Core</td>
          <td>Resilience Research Projects require different approval processes depending on the total cost of the
            project. Projects with a total cost under 15,000 USDS can be directly approved by the Support
            Facilitator. Projects with a total cost above 15,000 USDS will require a vote on the Weekly
            Governance Cycle, which can be triggered by the Support Facilitator.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.10
              - Resilience Research And Preparedness - Review Process - Active Projects</dfn>
          </td>
          <td>Resilience Research And Preparedness - Review Process - Active Projects</td>
          <td>Core</td>
          <td>There are currently no active resilience research projects.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - A1 - Ecosystem Security Infrastructure</dfn>
          </td>
          <td>Ecosystem Security Infrastructure</td>
          <td>Section</td>
          <td>This Section manages Sky Ecosystem security infrastructure and initiatives.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure</td>
          <td>Core</td>
          <td>As one of the most important DeFi protocols with a high TVL, the Sky Protocol is a honeypot for
            hackers and other nefarious actors. The Sky Protocol must always be protected by an active Bug
            Bounty Program. This document regulates the budget and processes of the Bug Bounty Program, which
            serves to protect the Sky Protocol and its users from hacks and exploits. The Bug Bounty Program is
            conducted on the Immunefi platform.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure -
              Introduction</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Introduction
          </td>
          <td>Core</td>
          <td>The Bug Bounty Program aims to create incentives for hackers to contribute to the resilience of the
            Sky Protocol as opposed to exploiting vulnerabilties for personal gain. Immunefi is the party
            responsible for conducting the Bug Bounty Program; its setup and operations are based on standards
            set by Immunefi. The Sky Ecosystem must continue to maintain a Bug Bounty Program for SparkLend
            until the launch of the Spark Star.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Scope</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Scope</td>
          <td>Core</td>
          <td>The subdocuments herein describe the scope of the Sky Bug Bounty Program, which currently includes
            both Sky Protocol and Spark Protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Assets In
              Scope</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Assets In Scope
          </td>
          <td>Core</td>
          <td>
            The Assets In Scope of the Sky Core Bug Bounty Program will be those identified as critical
            infrastructure for the Sky Ecosystem.For Sky Core, the Assets In Scope accepted for this Bug Bounty
            Program are specified on Sky's listing on the Immunefi platform, which can be found at (<a
              href="https://immunefi.com/bounty/makerdao/">https://immunefi.com/bounty/makerdao/</a>). Assets
            in Scope include smart contracts, frontend applications, data infrastructure and oracles.For
            SparkLend, the Assets In Scope for the Bug Bounty Program is specified on SparkLend's listing on the
            Immunefi platform, which can be found at (<a
              href="https://immunefi.com/bounty/sparklend/">https://immunefi.com/bounty/sparklend/</a>). For
            SparkLend, the Assets In Scope only include smart contracts.The Support Facilitator is responsible
            for maintaining these lists of Assets In Scope, in consultation with the relevant stakeholders.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Severity
              Classification</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Severity
            Classification</td>
          <td>Core</td>
          <td>
            The Immunefi Vulnerability Severity Classification System (<a
              href="https://immunefi.com/severity-updated/">https://immunefi.com/severity-updated/</a>) is
            applicable to both Sky Core and SparkLend. The Support Facilitator is authorized to adopt a new
            severity system for the Bug Bounty Programs in consultation with relevant technical stakeholders.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Impacts
              In Scope</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Impacts In
            Scope</td>
          <td>Core</td>
          <td>
            For Sky Core, the Impacts In Scope accepted for the Bug Bounty Program is specified on Sky's listing
            on the Immunefi platform, which can be found at (<a
              href="https://immunefi.com/bounty/makerdao/">https://immunefi.com/bounty/makerdao/</a>). The
            impacts are categorized into 'smart contract' and 'websites and applications.'For SparkLend, the
            Impacts In Scope for the Bug Bounty Program is specified on SparkLend's listing on the Immunefi
            platform, which can be found at (<a
              href="https://immunefi.com/bounty/sparklend/">https://immunefi.com/bounty/sparklend/</a>).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Out Of
              Scope Vulnerabilities And Other Limitations</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Out Of Scope
            Vulnerabilities And Other Limitations</td>
          <td>Core</td>
          <td>
            A selection of vulnerabilities is deemed out of scope for the Bug Bounty Program. An overview of
            these out of scope vulnerabilities can be found on Sky's listing on the Immunefi platform (<a
              href="https://immunefi.com/bounty/makerdao/">https://immunefi.com/bounty/makerdao/</a>).
            Feasibility limitations also apply, which can be found in the aforementioned listing on the Immunefi
            website.Specific rules applying to the Bug Bounty Program can be found at the website above, listed
            under the following categories:• Repeatable attack limitations• Restrictions on security researcher
            eligibility• Public disclosure of known issues• Proof of Concept (PoC) requirements• Other terms and
            information• Prohibited activitiesFor SparkLend, the rules, terms, and exceptions can be found on
            SparkLend's listing on the Immunefi platform (<a
              href="https://immunefi.com/bounty/sparklend/">https://immunefi.com/bounty/sparklend/</a>).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              Terms And Conditions</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards Terms
            And Conditions</td>
          <td>Core</td>
          <td>The subelements herein describe the Bug Bounty Program's terms and conditions for rewards.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              For Smart Contract Vulnerabilities</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards For
            Smart Contract Vulnerabilities</td>
          <td>Core</td>
          <td>
            The Rewards per Threat Level for Smart Contract Vulnerabilities, including related terms, conditions
            and exceptions, are specified in Sky's listing on the Immunefi platform (<a
              href="https://immunefi.com/bounty/makerdao/">https://immunefi.com/bounty/makerdao/</a>).For
            SparkLend, the Rewards per Threat Level for Smart Contract Vulnerabilities, including related terms,
            conditions and exceptions, are specified on SparkLend's listing on the Immunefi platform (<a
              href="https://immunefi.com/bounty/sparklend/">https://immunefi.com/bounty/sparklend/</a>).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              For Website And Application Vulnerabilities</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards For
            Website And Application Vulnerabilities</td>
          <td>Core</td>
          <td>
            The Rewards per Threat Level for Website and Application Vulnerabilities, including related terms,
            conditions and exceptions, are specified in Sky's listing on the Immunefi platform (<a
              href="https://immunefi.com/bounty/makerdao/">https://immunefi.com/bounty/makerdao/</a>).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              Payment Terms</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards Payment
            Terms</td>
          <td>Core</td>
          <td>The subelements herein describe the payment terms for the Bug Bounty Program for Sky Critical
            Infrastructure.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              Denomination</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
            Denomination</td>
          <td>Core</td>
          <td>Payments are denominated in USD. However, payouts are done in USDS assuming a full 1:1 ratio with
            the USD. However, if the price of USDS deviates from the USD value by more than 1%, the amount of
            USDS will be adjusted.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              Payout Process</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards Payout
            Process</td>
          <td>Core</td>
          <td>All bounty payouts are handled by Sky Governance. Upon confirmation, bug bounty payouts should be
            included in the next possible Executive Vote. This would involve sending USDS directly from the
            protocol's buffer to the whitehat hacker.Immunefi will publicly contact one of the Governance
            Facilitators with the request, including a specification of the respective vulnerability report, the
            requested amount and the Ethereum mainnet addresses of the beneficiaries. This should also include
            the payment details of the Immunefi fee, if it applies. Immunefi and the Sky Governance Facilitators
            should make sure the payout is made within one full calendar month after the report was approved.For
            Bug Bounty rewards over USD 1,000,000: after the first million is paid out, the remaining amount is
            paid out over time with up to USD 1,000,000 per consecutive month until the determined amount for
            payout is reached.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              Budget</dfn>
          </td>
          <td>Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards Budget
          </td>
          <td>Core</td>
          <td>
            The Bug Bounty Programs incur fixed and variable costs.• Variable costs: Bug bounty payouts
            including related fees to Immunefi are considered variable costs and are covered by the process
            described in <dfn>A.2.11
              - Ecosystem Security Infrastructure - Bug Bounty Program For Critical Infrastructure - Rewards
              Payment Terms</dfn>.• Fixed costs: Fixed costs comprise service fees for the Immunefi Premium
            Triaging Service, and compensation of a part-time Bug Bounty program steward. These costs are funded
            by the Launch Project budget, as specified in <dfn>A.5.9
              - Launch Project - Budget</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.12
              - A1 - Purpose System - Funding</dfn>
          </td>
          <td>Purpose System - Funding</td>
          <td>Section</td>
          <td>This Section must define the elements and infrastructure necessary to implement the Purpose System
            effectively. This includes defining the process by which the Sky Protocol will emit SKY tokens to
            fund the system, as well as establishing a process for allocating purpose funds to individual Stars.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.12
              - A2 - Purpose System - Direct And Specific Impact Solutions</dfn>
          </td>
          <td>Purpose System - Direct And Specific Impact Solutions</td>
          <td>Section</td>
          <td>At all times, at least 10% of the Purpose System funds must be used for more direct and specific
            impact solutions.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.1
              - A1 - Scope Improvement</dfn>
          </td>
          <td>Scope Improvement</td>
          <td>Section</td>
          <td>To ensure continuous improvement of the Stability Scope, the Stability Facilitators may retain Scope
            Advisors, experts with relevant domain expertise. The Stability Scope Advisors shall take on
            projects identified by the Stability Facilitators. The Scope Advisors will serve under the terms and
            conditions set forth in an agreement to be negotiated by the Stability Facilitators and each Scope
            Advisor, which agreement shall be publicly disclosed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.1
              - Scope Improvement - Scope Advisor Requirements</dfn>
          </td>
          <td>Scope Improvement - Scope Advisor Requirements</td>
          <td>Core</td>
          <td>Stability Scope Advisors must be Ecosystem Actors who have no involvement in any business,
            political, or governance-related activities that could create a conflict of interest, either
            directly or indirectly. Additionally, they must possess the relevant expertise and professional
            skills necessary to provide informed and objective input on the specific content areas covered by
            the Stability Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.1
              - Scope Improvement - Scope Advisor Requirements - BA Labs Conflict Of Interest Waiver</dfn>
          </td>
          <td>Scope Improvement - Scope Advisor Requirements - BA Labs Conflict Of Interest Waiver</td>
          <td>Core</td>
          <td>BA Labs is granted a limited waiver to the rule prohibiting Stability Scope Advisors from engaging
            in other business activities that could result in a conflict of interest. This waiver applies only
            to BA Labs' work with Ethena. This waiver provides Sky with greater transparency and responsiveness
            in the event of any issue with Ethena. It also allows BA Labs to align Ethena's risk strategy with
            Sky.However, should additional Stability Scope Advisors be appointed, they will be required to
            assume full responsibility for all risk management activities associated with Ethena.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.1
              - Scope Improvement - Current Scope Advisors</dfn>
          </td>
          <td>Scope Improvement - Current Scope Advisors</td>
          <td>Core</td>
          <td>The currently active Scope Advisors are: BA LabsETH Address:
            0xDfe08A40054685E205Ed527014899d1EDe49B892</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - A1 - Core Stability Parameters - Role Of Stability Facilitators</dfn>
          </td>
          <td>Core Stability Parameters - Role Of Stability Facilitators</td>
          <td>Section</td>
          <td>This Section defines the role of the Stability Facilitators in managing the Core Stability
            Parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Role Of Stability Facilitators - Broad Authority</dfn>
          </td>
          <td>Core Stability Parameters - Role Of Stability Facilitators - Broad Authority</td>
          <td>Core</td>
          <td>Prior to the launch of Star Vaults and the implementation of a new Rate System, all Stability
            Parameters related to Sky Core and Spark Star will be managed by the Stability Facilitators, in
            consultation with the Stability Scope Advisors. This process will be conducted through the
            Operational Weekly Governance Cycle or, if necessary, through out-of-schedule Executive Votes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Role Of Stability Facilitators - Spark Protocol Debt Ceiling</dfn>
          </td>
          <td>Core Stability Parameters - Role Of Stability Facilitators - Spark Protocol Debt Ceiling</td>
          <td>Core</td>
          <td>As long as Spark Protocol remains near its maximum borrow limit, the Stability Facilitators can use
            the Operational Weekly Governance Cycle to propose to increase its Debt Ceiling to attract more
            users.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - A2 - Core Stability Parameters - Parameters</dfn>
          </td>
          <td>Core Stability Parameters - Parameters</td>
          <td>Section</td>
          <td>This Section defines the Core Stability Parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Base Rate</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Base Rate</td>
          <td>Core</td>
          <td>The Base Rate is the key interest rate in the system. It defines all other rates by various spreads.
            It is expressed as an annual percentage rate.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Long Term Base Rate Determination Process</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Long Term Base Rate Determination Process</td>
          <td>Core</td>
          <td>In the long term, the Base Rate must be automatically determined based on a model which ensures long
            term price stability of USDS and other Stablecoins produced by the Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Medium Term Base Rate Determination Process</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Medium Term Base Rate Determination Process</td>
          <td>Core</td>
          <td>In the medium term, the Base Rate is changed by Executive Votes proposed by the Stability
            Facilitators based on the recommendation of the Stability Scope Advisors.The Stability Facilitators
            must regularly update the Base Rate in order to ensure (1) a sufficient level of Cash Stablecoins
            and (2) price stability of USDS and other Stablecoins produced by the Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Base Rate Spread Determination Process</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Base Rate Spread Determination Process</td>
          <td>Core</td>
          <td>Spreads which are attached to the Base Rate can also be changed through the Operational Weekly
            Governance Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Dai Savings Rate</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Dai Savings Rate</td>
          <td>Core</td>
          <td>The Dai Savings Rate ("DSR") is the rate Dai holders can earn on their Dai in the Dai Savings Rate
            smart contracts.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Dai Savings Rate Formula</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Dai Savings Rate Formula</td>
          <td>Core</td>
          <td>The Dai Savings Rate is determined based on the Base Rate and DSR Spread parameter using the
            following formula:Dai Savings Rate = Base Rate + DSR Spread</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Dai Savings Rate Current Value</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Dai Savings Rate Current Value</td>
          <td>Core</td>
          <td>The current value of the Dai Savings Rate is 3.50%.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Sky Savings Rate</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Sky Savings Rate</td>
          <td>Core</td>
          <td>The Sky Savings Rate ("SSR") is the rate USDS holders can earn on their USDS in the Sky Savings Rate
            smart contracts.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Sky Savings Rate Formula</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Sky Savings Rate Formula</td>
          <td>Core</td>
          <td>The Sky Savings Rate is determined based on the Dai Savings Rate and the USDS Spread parameter using
            the following formula:Sky Savings Rate = Dai Savings Rate + USDS Spread</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - USDS Spread Current Value</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - USDS Spread Current Value</td>
          <td>Core</td>
          <td>The current value of the USDS Spread is 1.00%.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Stars Credit Line Borrow Rate</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Stars Credit Line Borrow Rate</td>
          <td>Core</td>
          <td>The Stars Credit Line Borrow Rate is the annual percentage rate that Stars must pay to Sky Core to
            receive USDS liquidity into their respective vaults.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.2
              - Core Stability Parameters - Parameters - Stars Credit Line Borrow Rate Risk Limits</dfn>
          </td>
          <td>Core Stability Parameters - Parameters - Stars Credit Line Borrow Rate Risk Limits</td>
          <td>Core</td>
          <td>USDS liquidity that Stars receive from Sky Core can be deployed across Conduits within risk limits
            defined by the Stability Facilitators.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - A1 - Real World Assets - Arranged Structures</dfn>
          </td>
          <td>Real World Assets - Arranged Structures</td>
          <td>Section</td>
          <td>Arranged Structures are special legal structures set up by Ecosystem Actors to secure Real World
            Assets to help stabilize the Sky Ecosystem. Each Arranged Structure has a Conduit system which is
            owned by a Star and automatically connected to all Stars; the Conduit allows them to send and
            receive USDS or other assets.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - A2 - Real World Assets - Star Owner For Arranged Structures</dfn>
          </td>
          <td>Real World Assets - Star Owner For Arranged Structures</td>
          <td>Section</td>
          <td>Arranged Structures must have a Star owner. The Star owner assigns instructions to the Arranged
            Structure on behalf of Sky, and determines if and how other Stars can access the Conduit of the
            Arranged Structure.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - A3 - Real World Assets - Arrangers</dfn>
          </td>
          <td>Real World Assets - Arrangers</td>
          <td>Section</td>
          <td>This Section defines procedures related to Arrangers, Ecosystem Actors that assist in the design and
            operation of Arranged Structures. Every Arranged Structure must have a designated Arranger
            responsible for conducting ongoing reporting. All aspects of this relationship, including the
            Arranger's duties, must be defined in this Section.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Arrangers - Introduction</dfn>
          </td>
          <td>Real World Assets - Arrangers - Introduction</td>
          <td>Core</td>
          <td>Arrangers are Ecosystem Actors who specialize in sourcing, negotiating, structuring, and reporting
            on Real World Assets, as well as maintaining and monitoring the underlying Arranged Structures used
            by the Sky Protocol. The Arrangers manage a restricted function on the Arranged Structure Conduit
            that allows them to send assets onwards to the predetermined blockchain account of the Arranged
            Structure.Arrangers are generally prohibited from occupying any position where they could cause
            damage or loss to the Sky Ecoystem, notwithstanding delays or inconveniences.After the Arranged
            Structures are established and assets are allocated, Arrangers must not have the capability to
            operate or influence the legal and operational structure's asset operations in any manner that could
            cause significant harm or losses to the stability of USDS. Arrangers are directly approved by SKY
            voters, and all LRA collateral exposure must be structured by an approved Arranger.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Arrangers - Onboarding And Offboarding of Arrangers</dfn>
          </td>
          <td>Real World Assets - Arrangers - Onboarding And Offboarding of Arrangers</td>
          <td>Core</td>
          <td>
            When they deem it necessary, the Stability Facilitators may initiate a Governance Poll to onboard or
            offboard Arrangers. The list of current active Arrangers is maintained in <dfn>A.3.3
              - Real World Assets - Arrangers - List Of Active Arrangers</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Arrangers - List Of Active Arrangers</dfn>
          </td>
          <td>Real World Assets - Arrangers - List Of Active Arrangers</td>
          <td>Core</td>
          <td>List of current active Arrangers:• BlocktowerFollowing the voluntary offboarding of Monetalis as an
            active Arranger, the Clydesdale RWA Arranged Structure must be wound down by the Stability
            Facilitator in collaboration with Monetalis or another suitable entity that can serve as an interim
            Arranger. This process must ensure a smooth and orderly wind-down of the assets within Clydesdale to
            minimize fees and maximize returns.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Arrangers - Reporting And Stress Test Requirements</dfn>
          </td>
          <td>Real World Assets - Arrangers - Reporting And Stress Test Requirements</td>
          <td>Core</td>
          <td>
            Arrangers must publish monthly reporting on each Arranged Structure they have arranged. Every six
            (6) months, Arrangers are also required to publish a stress test analysis that demonstrates how the
            structures would perform under historical financial crisis scenarios and other hypothetical
            scenarios.The Stability Facilitators must periodically fund independent Ecosystem Actors to review
            and verify the quality and the results of the stress tests. Should an independent review produce an
            unfavorable result, the Stability Facilitators must propose a Governance Poll for warning,
            temporarily deactivating, or permanently offboarding the Arranger and/or the Asset Managers
            connected to the discovered issue.To be considered compliant, Arrangers' monthly reports must
            satisfy the requirements of one of the following documents:•<dfn>A.3.3
              - Real World Assets - Arrangers - Monthly Arranger Report Requirements</dfn>• <dfn>A.3.3
              - Real World Assets - Arrangers - Access To Accounts</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Arrangers - Monthly Arranger Report Requirements</dfn>
          </td>
          <td>Real World Assets - Arrangers - Monthly Arranger Report Requirements</td>
          <td>Core</td>
          <td>The following information must be included in the monthly Arranger report. Each item must be
            reported for at least the start and end date of the reporting period. If these dates fall on days
            when markets are closed, the first business day after the start date and the last business day
            before the end date may be used instead.• Cash balance.• Cash income over the reporting period. Any
            income over $20,000 in value should be broken out as its own line item, and an explanation provided
            for any non-recurring or non-ordinary expenses.• Cash expenses over the reporting period. Any
            expense over $20,000 in value should be broken out as its own line item, and an explanation provided
            for any non-recurring or non-ordinary expenses.• Market value of publicly traded equities, ETFs, and
            mutual funds.• Market value (the closing price) of publicly traded debt securities. Debt securities
            that are investment grade and less than 12 months from maturity may alternatively be reported at
            cost basis + linearly recognizing scheduled interest income.• A valuation for illiquid or privately
            traded assets. This should utilize a valuation from a reputable third party with relevant expertise
            or follow a well-defined methodology that is explained in detail in the report.• CUSIPs, date of
            purchase, date of maturity, coupon, cost basis, and face value of all publicly traded debt
            securities in the portfolio for the last day of the reporting period.• USDS inflows from the Sky
            Protocol during the reporting period.• Total repayments on-chain to the Sky Protocol either to a
            vault or for surplus. If repayments are derived from multiple sources, they should be broken out
            into line items for each source.• Vault debt to the Sky Protocol.• Copies of original statements for
            all bank, brokerage, exchange, custodial, or other accounts. The Arranger may redact the names for
            non-Arranger service providers if and only if that is a requirement of confidentiality agreements
            with the non-Arranger service providers.The Stability Facilitator must publicly confirm on the Sky
            Forum that they have reviewed the original account documentation and verified that it supports the
            Arranger's summary.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Arrangers - Access To Accounts</dfn>
          </td>
          <td>Real World Assets - Arrangers - Access To Accounts</td>
          <td>Core</td>
          <td>
            As an alternative to the requirements set out in <dfn>A.3.3
              - Real World Assets - Arrangers - Monthly Arranger Report Requirements</dfn>, the Arranger can
            provide the following information through public read-only access to all accounts:• All asset
            balances• All transaction amounts (non-Arranger service provider names may be redacted)•
            Hold-to-maturity yields (for assets with maturity) or current yield (for assets with no maturity)In
            addition, Makerburn.com (<a href="https://makerburn.com/#/">https://makerburn.com/#/</a>),
            Daistats.com (<a href="https://daistats.com/#/">https://daistats.com/#/</a>), or another dashboard
            must be publicly available to summarize USDS inflows and outflows from the Sky vault.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - A4 - Real World Assets - Star Owner Can Change Arrangers</dfn>
          </td>
          <td>Real World Assets - Star Owner Can Change Arrangers</td>
          <td>Section</td>
          <td>The Star owner of the Arranged Structure can change the blockchain account of the Arranged Structure
            and change the Arranger.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - A5 - Real World Assets - Perpetual Yield Strategies</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies</td>
          <td>Section</td>
          <td>The subdocuments herein define perpetual yield strategies and exposure targets that can be
            implemented by the Stability Facilitators.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Implemented By Stability Facilitator</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Implemented By Stability Facilitator</td>
          <td>Core</td>
          <td>The Stability Facilitators can implement various perpetual yield strategies, including on-chain and
            off-chain mechanisms, that enable the Sky Protocol to take advantage of high risk-adjusted return on
            perpetual yield strategies in the crypto markets. Exposure targets specified in this document
            override requirements defined by other Articles of the Stability Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Perpetual Exposure</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Perpetual Exposure</td>
          <td>Core</td>
          <td>The subdocuments herein define Perpetual Exposure parameters and the associated governance
            processes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Perpetual Exposure Direct Accumulation</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Perpetual Exposure Direct Accumulation</td>
          <td>Core</td>
          <td>The Stability Facilitators can trigger Executive Votes that instruct Arranged Structures to set up
            mechanisms that allow them to take direct exposure to Ethena sUSDe, or use legal rails to get direct
            exposure through custodians.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Adjustment Of Perpetual Exposure Direct
              Accumulation</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Adjustment Of Perpetual Exposure Direct
            Accumulation</td>
          <td>Active Data Controller</td>
          <td>
            The level of exposure that can be adjusted is defined as Active Data in: <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Andromeda Direct Exposure</dfn> <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Clydesdale Legal Rails Exposure</dfn> <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Andromeda Legal Rails Exposure</dfn>The Active
            Data is updated as follows:• The Responsible Party is the Stability Facilitators.• The Update
            Process must follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Requirements For Adjustment Of Perpetual
              Exposure Direct Accumulation</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Requirements For Adjustment Of Perpetual Exposure
            Direct Accumulation</td>
          <td>Core</td>
          <td>
            When updating the Active Data controlled by <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Adjustment Of Perpetual Exposure Direct
              Accumulation</dfn>, the Stability Facilitators shall consult with the Stability Scope Advisors and
            other recognized Ecosystem Actors.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Morpho Vaults</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Morpho Vaults</td>
          <td>Core</td>
          <td>The subdocuments herein define the exposure for the Morpho Vaults and the associated governance
            processes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Morpho Overcollateralized SUSDe Or USDe
              DDM</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Morpho Overcollateralized SUSDe Or USDe DDM</td>
          <td>Core</td>
          <td>The Stability Facilitators can trigger Executive Votes that set up DDMs to Morpho Vaults that have
            overcollateralized exposure to sUSDe or USDe.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Adjustment Of Exposure Morpho Vault</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Adjustment Of Exposure Morpho Vault</td>
          <td>Active Data Controller</td>
          <td>
            The level of exposure is defined as Active Data in <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Current Exposure Of Morpho SUSDe Or USDe DDM
              Vault</dfn>. The Active Data is updated as follows:• The Responsible Party is the Stability
            Facilitators.• The Update Process must follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Requirements For Adjustment Morpho Vault</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Requirements For Adjustment Morpho Vault</td>
          <td>Core</td>
          <td>
            When updating the level of exposure in <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Current Exposure Of Morpho SUSDe Or USDe DDM
              Vault</dfn>, the Stability Facilitators shall consult with the Stability Scope Advisors and other
            recognized Ecosystem Actors.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Morpho Vault Multisig</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Morpho Vault Multisig</td>
          <td>Core</td>
          <td>
            A multisig, controlled by Governance Facilitator JanSky, has been established to adjust the DDM
            parameters in real time. To prevent abuse, the management of the DDM parameters, and Governance
            Facilitator JanSky's use of the multisig, must wholly adhere to the Stability Facilitator's
            instructions, as required by <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Management Of Morpho Vault</dfn>. The members
            of the multisig can be expanded beyond the single JanSky account. The multisig and other relevant
            control mechanisms can be established through an Executive Vote initiated by the Stability
            Facilitators at will.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Management Of Morpho Vault</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Management Of Morpho Vault</td>
          <td>Core</td>
          <td>The parameters of the Metamorpho vault are managed through the multisig controlled by Governance
            Facilitator JanSky. The Governance Facilitator's use of the multisig must wholly adhere to
            instructions provided by the Stability Facilitator, which instructions are based on expert advice
            from the Stability Scope Advisor and other Ecosystem Actors.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - A1 - Collateral Portfolio</dfn>
          </td>
          <td>Collateral Portfolio</td>
          <td>Section</td>
          <td>This Section governs the management of Sky's Collateral Portfolio.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Stablecoin Collateral Reserve</dfn>
          </td>
          <td>Collateral Portfolio - Stablecoin Collateral Reserve</td>
          <td>Core</td>
          <td>Sky must maintain a reserve of at least 20% of the total Dai and USDS Supply held as Cash
            Stablecoins, or assets and exposure that can rapidly be converted to Cash Stablecoins.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Cash Stablecoin Definition And List</dfn>
          </td>
          <td>Collateral Portfolio - Cash Stablecoin Definition And List</td>
          <td>Core</td>
          <td>
            A Cash Stablecoin is defined as either a Stablecoin listed in <dfn>A.3.4
              - Collateral Portfolio - List Of Cash Stablecoin</dfn>; a technically secure DeFi token that can
            be instantly converted to a listed Stablecoin; or a custody solution that can be converted into a
            listed Stablecoin within 30 minutes. The Stability Facilitators can modify the above cited document
            through the Operational Weekly Governance Cycle to react to changing market conditions,
            opportunities or risks. The modification of the list can include adding or removing Cash
            Stablecoins, or changing the terms of existing Cash Stablecoins on the list.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - List Of Cash Stablecoin</dfn>
          </td>
          <td>Collateral Portfolio - List Of Cash Stablecoin</td>
          <td>Core</td>
          <td>List of Cash Stablecoins:• USDC and USDC in Coinbase Custody</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Stablecoin Collateral Reserve - Cash Stablecoin Peg Stability Module
              Upgrades</dfn>
          </td>
          <td>Collateral Portfolio - Stablecoin Collateral Reserve - Cash Stablecoin Peg Stability Module Upgrades
          </td>
          <td>Core</td>
          <td>The mechanism for holding and making Cash Stablecoins available to support the liquidity of Dai and
            USDS can be upgraded to a superior technical, financial or legal solution by a proposal from the
            Stability Facilitators through the Operational Weekly Governance Cycle.The Stability Facilitators
            may specify requirements for how Star Advisory teams deploy USDS generated from their Star Vault.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management</dfn>
          </td>
          <td>Collateral Portfolio - Asset Liability Management</td>
          <td>Core</td>
          <td>To ensure adequate liquidity, Cash Stablecoins are managed through a simple Asset Liability
            Management framework. This framework allocates excess Cash Stablecoins into low-risk RWA assets, and
            draws on these assets to replenish the Cash Stablecoins when they fall too low.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management - Excess Cash Stablecoins</dfn>
          </td>
          <td>Collateral Portfolio - Asset Liability Management - Excess Cash Stablecoins</td>
          <td>Core</td>
          <td>
            If the Dai and USDS Collateral portfolio contains more than 30% of Cash Stablecoins as defined
            above, then any Cash Stablecoins above the 30% mark must be allocated towards the collateral defined
            in <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management - Low Risk RWA</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management - Lack Of Cash Stablecoins</dfn>
          </td>
          <td>Collateral Portfolio - Asset Liability Management - Lack Of Cash Stablecoins</td>
          <td>Core</td>
          <td>
            If the Dai and USDS Collateral portfolio contains less than 20% Cash Stablecoins, the assets defined
            in <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management - Low Risk RWA</dfn> must be sold off to
            return the Cash Stablecoin exposure to 25%.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management - Low Risk RWA</dfn>
          </td>
          <td>Collateral Portfolio - Asset Liability Management - Low Risk RWA</td>
          <td>Core</td>
          <td>Andromeda is the RWA Arranged Structure that can allocate capital into Low-Risk RWA (LRR). LRR is
            safe, short-term treasury strategies of less than one (1) year duration. Whenever excess Cash
            Stablecoins must be allocated into LRR, or whenever LRR must be sold to replenish Cash Stablecoins,
            the amounts allocated or sold are applied to the Andromeda RWA Arranged Structure.Control of the
            Andromeda RWA Arranged Structure must be prepared to transition to the Spark Star.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management - Optimizations</dfn>
          </td>
          <td>Collateral Portfolio - Asset Liability Management - Optimizations</td>
          <td>Core</td>
          <td>
            The Stability Facilitators can use the Operational Weekly Governance Cycle to modify the Asset
            Liability Management framework in order to make it more efficient, or more resilient. This
            modification can involve changing any of the logic defined in <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management</dfn> or its subdocuments.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Legacy RWA Offboarding</dfn>
          </td>
          <td>Collateral Portfolio - Legacy RWA Offboarding</td>
          <td>Core</td>
          <td>Old RWA exposure that was added before Endgame must stay for as long as necessary, and optimized for
            yield if possible. When it is possible, the Stability Facilitators should take action to wind down
            and offboard all Legacy RWA. Governance actions related to optimizations, wind down and offboardings
            can be done directly in Executive Votes with no prior Governance Poll needed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process</td>
          <td>Core</td>
          <td>The subdocuments herein define the process by which Sky vault users should be notified about
            collateral offboarding.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Legacy Context</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Legacy Context</td>
          <td>Core</td>
          <td>
            Periodically, collateral and vault types (ilks) are re-evaluated, which sometimes results in an
            offboarding of that collateral or vault type. There have been several instances where users entered
            official Sky forums/chats to understand why they had been suddenly liquidated, despite historically
            comfortable collateralization ratios (<a
              href="https://forum.makerdao.com/t/an-assessment-first-hand-experience-and-recommendations-from-the-aave-offboarding/11836">https://forum.makerdao.com/t/an-assessment-first-hand-experience-and-recommendations-from-the-aave-offboarding/11836</a>).
            This is, understandably, a poor user experience. Even with liquidation penalties set to 0%, the
            forced unwinding of levered positions conceivably can result in user losses, as well as potentially
            taxable events. This Section defines procedures concerning the dissemination of information about
            upcoming collateral offboarding on a best-effort basis. The objective is to minimize the number of
            users who are unaware of the offboarding prior to getting their positions liquidated.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Legacy Context Specific Goals</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Legacy Context Specific Goals</td>
          <td>Core</td>
          <td>Specific Goals:1. Codify a series of good-faith communication efforts.2. Provide an easy-to-follow
            process for Sky contributors to follow without significant burden.3. Minimize the number of users
            unaware of a collateral offboarding.4. Provide a method to bypass these requirements in the event a
            collateral is being offboarded due to serious security or solvency concerns.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Technical Process</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Technical Process</td>
          <td>Core</td>
          <td>The subdocuments herein specify actions to be taken by specific actors within Sky when offboarding a
            vault type.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Immediate Actions</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Immediate Actions</td>
          <td>Core</td>
          <td>
            Upon approval by Sky Governance to offboard a permissionless collateral type or vault type, the
            following actions are taken as soon as is practicable:• Set debt ceiling to zero (0) Dai or USDS.•
            Make an initial public announcement on all communication channels listed in <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Communication Channels And Media Assets
              Listing</dfn>.• Make a second public announcement on all communication channels in the above cited
            document no later than 14 calendar days after the initial public announcement.• Once the second
            public announcements have been made, set the liquidation penalty to 0%.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Following Actions</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Following Actions</td>
          <td>Core</td>
          <td>Parameter changes designed to offboard users, such as changes to the liquidation ratio or stability
            fee, can only be implemented once 14 calendar days have passed following a second public
            announcement.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Communication Channels And Media Assets</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Communication Channels And Media Assets</td>
          <td>Active Data Controller</td>
          <td>
            The process for adding, removing, and modifying communication channels and media assets, and the
            order of announcement publication, are defined as Active Data in <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Communication Channels And Media Assets
              Listing</dfn>.The Active Data is updated as follows:• The Responsible Party is the Communication
            Coordinator.• The Update Process must follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Communication Coordinator</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Communication Coordinator</td>
          <td>Core</td>
          <td>The subdocuments herein define the Communication Coordinator role.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Designated Responsible Party</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Designated Responsible Party</td>
          <td>Core</td>
          <td>
            The Communication Coordinator is designated the Responsible Party who is authorized to modify the
            Active Data document at <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Communication Channels And Media Assets
              Listing</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - The Current Communication Coordinator</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - The Current Communication Coordinator</td>
          <td>Active Data Controller</td>
          <td>
            The current Communication Coordinator is defined as Active Data in <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Current Communication Coordinator</dfn>. The Active
            Data is updated as follows:• The Responsible Party is the Governance Facilitators. • The Update
            Process must follow the protocol for 'Direct Edit' and must adhere to the additional requirements
            defined in <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Requirements For Modification Of Current
              Communication Coordinator</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Requirements For Modification Of Current
              Communication Coordinator</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Requirements For Modification Of Current Communication
            Coordinator</td>
          <td>Core</td>
          <td>
            If the current Communication Coordinator is no longer willing or able to fulfill this role, then the
            Governance Facilitator may appoint a new Communication Coordinator.• The Governance Facilitator is
            permitted to modify <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Current Communication Coordinator</dfn> by
            replacing the existing Communication Coordinator.• The new Communication Coordinator must have
            publicly communicated their willingness to fulfill the Communication Coordinator role.• The
            Governance Facilitator must publicly communicate that the modification has taken place.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Expedited Offboarding</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Expedited Offboarding</td>
          <td>Core</td>
          <td>The subdocuments herein define an expedited offboarding process in the event a collateral type needs
            to be removed quickly due to security or solvency concerns.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Requirements</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Requirements</td>
          <td>Core</td>
          <td>
            When a collateral type threatens the security or solvency of the Sky Protocol, an expedited 
            offboarding is in order. Expedited offboardings override the timeline specified in <dfn>A.3.4 
              - Collateral Portfolio - Offboarding Process - Technical Process</dfn> and allow the 
            immediate modification of all relevant parameters. Expedited offboardings must proceed 
            pursuant to the following requirements:<br>
            • The Offboarding Proposal must state that the offboarding should be expedited due to an 
            emergency or urgent concern, as defined in <dfn>A.1.8 - Emergency Voting System - Definition
               Of Emergency Situations</dfn>.• The Offboarding Proposal must explicitly reference this
                Atlas document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Announcements</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Announcements</td>
          <td>Core</td>
          <td>
            The public announcements defined in <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Technical Process</dfn> must still be carried out.
            However, the timing of these announcements no longer constrains the modification of parameters.
            These announcements must also state that the offboarding is being expedited and explain the reasons
            for this accelerated process.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module</td>
          <td>Core</td>
          <td>A Peg Stability Module ("PSM") allows users to swap a given collateral type directly for Dai or USDS
            at a fixed rate, rather than borrowing Dai or USDS. The PSM contract was designed with Stablecoin
            collateral in mind, allowing users to swap other Stablecoins for Dai or USDS at a fixed rate to aid
            with keeping Dai or USDS pegged to one (1) USD.A PSM operates similarly to a regular vault type with
            a zero Stability Fee and a liquidation ratio of 100% that can only be accessed through a user-facing
            smart contract containing the relevant swap functions. Unlike regular vaults, users of the PSM do
            not retain ownership of the asset and borrow Dai or USDS. Instead, PSM users swap the asset directly
            for Dai or USDS.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module</td>
          <td>Core</td>
          <td>The subdocuments herein manage the Lite Peg Stability Module.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module Parameter
              Definitions</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module Parameter Definitions</td>
          <td>Core</td>
          <td>The subdocuments herein define the parameters of the Lite Peg Stability Module.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Toll / Fee In Definition</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Toll / Fee In Definition</td>
          <td>Core</td>
          <td>tin is a percentage fee applied when trading the collateral asset into the PSM in exchange for Dai.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Toll / Fee Out Definition</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Toll / Fee Out Definition</td>
          <td>Core</td>
          <td>tout is the percentage fee applied when trading Dai into the PSM in exchange for the collateral
            asset.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Maximum Debt Ceiling Definition</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Maximum Debt Ceiling Definition</td>
          <td>Core</td>
          <td>DC-IAM line is the maximum amount of debt the LitePSM can accrue.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Target Available Debt Definition</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Target Available Debt Definition</td>
          <td>Core</td>
          <td>DC-IAM gap is the target gap between the debt usage and the Debt Ceiling.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Ceiling Increase Cooldown Definition</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Ceiling Increase Cooldown Definition</td>
          <td>Core</td>
          <td>DC-IAM ttl is the minimum time requirement before it is possible to increase the debt ceiling,
            expressed in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Buffer Definition</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Buffer Definition</td>
          <td>Core</td>
          <td>buf is a fixed-sized amount of pre-minted Dai which LitePSM is designed to maintain in most
            instances. Note, however, that when a user calls buyGem, the amount of Dai available can be
            temporarily larger than buf.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Authorized Parties Definition</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Authorized Parties Definition</td>
          <td>Core</td>
          <td>Authorized Parties are actors who are authorized by Sky Governance to use the Lite Peg Stability
            Module without paying swap fees.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module Parameter
              Modification</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module Parameter Modification</td>
          <td>Core</td>
          <td>
            The Stability Facilitators, in consultation with the Stability Scope Advisors, may recommend changes
            to any of the parameters specified in the subdocuments of <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module Parameter
              Definitions</dfn>. These changes will be subject to an Executive Vote through the Operational
            Weekly Governance Cycle.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module Parameter Values</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Lite Peg Stability Module Parameter Values</td>
          <td>Core</td>
          <td>The current values of the Lite Peg Stability Module parameters are:• tin: 0%• tout: 0%• DC-IAM line:
            10,000,000,000• DC-IAM gap: 400,000,000• DC-IAM ttl: 43,200 seconds• buf: 400,000,000• Authorized
            Parties: None</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - Legacy Peg Stability Modules</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - Legacy Peg Stability Modules</td>
          <td>Core</td>
          <td>All other Peg Stability Modules must be offboarded when the migration to the Lite PSM is complete.
            This will be coordinated by the Stability Facilitators in consultation with the Stability Scope
            Advisors. The subdocuments herein specify the terms of legacy Peg Stability Modules. These documents
            become obsolete when the respective Peg Stability Modules have been offboarded.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Peg Stability Module - USDC PSM And Coinbase Custody</dfn>
          </td>
          <td>Collateral Portfolio - Peg Stability Module - USDC PSM And Coinbase Custody</td>
          <td>Core</td>
          <td>Whenever the total amount of USDC in the Peg Stability Module ("PSM") plus the total amount of USDC
            in GUNI pools falls below 400 million, USDC must be transferred from Coinbase Custody to the PSM to
            bring the total amount of USDC in the PSM, plus the total amount of USDC in the GUNI pools, to 550m
            USDC. Whenever the total amount of USDC in the PSM, plus the total amount of USDC in GUNI pools
            exceeds 700 million, USDC must be transferred from the PSM to Coinbase Custody to bring the total
            amount of USDC in the PSM, plus the total amount of USDC in the GUNI pools, to 550m USDC. This
            mechanism can be fully replaced with an upgraded PSM that makes the Coinbase Custody solution
            obsolete. The Stability Facilitators can directly trigger an Executive Vote to implement an upgraded
            PSM.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.5 - A1 - Surplus Buffer And Smart Burn Engine - Surplus Buffer</dfn>
          </td>
          <td>Surplus Buffer And Smart Burn Engine - Surplus Buffer</td>
          <td>Section</td>
          <td>The Surplus Buffer is the difference between Sky’s assets and liabilities. Protocol revenue increases the Surplus Buffer and 
              expenses decrease the Surplus Buffer.
          </td>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.5 - Surplus Buffer And Smart Burn Engine - Surplus Buffer - Current Implementation</dfn>
          </td>
          <td>Surplus Buffer And Smart Burn Engine - Surplus Buffer - Current Implementation</td>
          <td>Core</td>
          <td>The current implementation of the Surplus Buffer is the Vow contract deployed on the Ethereum Mainnet at 
              0xa950524441892a31ebddf91d3ceefa04bf454466.
          </td>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.5 - Surplus Buffer And Smart Burn Engine - Surplus Buffer - Current Value</dfn>
          </td>
          <td>Surplus Buffer And Smart Burn Engine - Surplus Buffer - Current Value</td>
          <td>Core</td>
          <td>The current value of the Surplus Buffer can be calculated using the Vat contract, Sky’s central accounting contract, located 
              on the Ethereum Mainnet at 0x35d1b3f3d7966a1dfe207aa4514c12a259a0492b. The current value of the Surplus Buffer is the 
              difference between:
                1. The assets of the Vow contract obtained by calling the dai function on the Vat contract with the address of the Vow 
                contract, and
                2. The liabilities of the Vow contract obtained by calling the sin function on the Vat contract with the address of the 
                Vow contract.
            
          </td>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.5
              - A2 - Surplus Buffer And Smart Burn Engine - Surplus Buffer Splitter Parameters</dfn>
          </td>
          <td>Surplus Buffer And Smart Burn Engine - Surplus Buffer Splitter Parameters</td>
          <td>Section</td>
          <td>The current Surplus Buffer Splitter parameters are:• vow.hump: 70m (Threshold of Surplus buffer for Splitter to activate)•
              Estimated Net protocol Income: 100,765,523• 50% of estimated net protocol income is sent to Splitter: 50,382,762 (for SBE and 
              Seal Module, remaining 50% is accumulated in Surplus Buffer). This value must be regularly updated through an executive vote to 
              continue to target 50% of the estimated net protocol income.• vow.bump: 10,000 DAI• splitter.hop: 1,728 seconds• 100% of 
              Splitter allocation is set to accumulate SKY• 0% of Splitter allocation is set to reward Seal users• burn (the percentage of 
              the vow.bump to be moved to the underlying flapper): 100% (1 * WAD). Flapper must maintain its legacy values.</td>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.7
              - SKY Backstop - Emission Rate</dfn>
          </td>
          <td>SKY Backstop - Emission Rate</td>
          <td>Section</td>
          <td>An emissions rate for the SKY backstop function that prevents risk of sudden failure must be
            defined. This must be continuously assessed and improved to maximize stability of the system in
            worst case scenarios.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.7
              - SKY Backstop - Emission Rate - Limitless</dfn>
          </td>
          <td>SKY Backstop - Emission Rate - Limitless</td>
          <td>Core</td>
          <td>The SKY Backstop is temporarily limitless.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.7
              - SKY Backstop - Maximum Level Of Emission</dfn>
          </td>
          <td>SKY Backstop - Maximum Level Of Emission</td>
          <td>Section</td>
          <td>A maximum level of SKY emission per undercollateralization event must be defined. This must be
            continuously assessed and improved to maximize stability of the system in worst-case scenarios.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.7
              - SKY Backstop - Override Mechanism</dfn>
          </td>
          <td>SKY Backstop - Override Mechanism</td>
          <td>Section</td>
          <td>The Protocol must include an override mechanism that allows Sky Governance to continue emitting SKY
            beyond the maximum level. This Section must specify research processes and principles to guide when
            and how the override mechanism can be safely used.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.7
              - SKY Backstop - Halt Mechanism</dfn>
          </td>
          <td>SKY Backstop - Halt Mechanism</td>
          <td>Section</td>
          <td>The Protocol must contain a SKY backstop halt mechanism that immediately halts the backstop event in
            case of severe risk of total failure.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.7
              - SKY Backstop - Mitigate Worst Case Scenario</dfn>
          </td>
          <td>SKY Backstop - Mitigate Worst Case Scenario</td>
          <td>Section</td>
          <td>In case the backstop limit is reached and not overridden, or in case the backstop is halted during
            the event, the USDS target price receives a haircut to settle the remaining bad debt of the system.
            This Section must define elements and infrastructure to address this worst-case scenario, including
            research concerning ways to mitigate damage.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - A1 - Measures For Endgame Transition</dfn>
          </td>
          <td>Measures For Endgame Transition</td>
          <td>Section</td>
          <td>This Section defines temporary measures to give effect to the Stability Scope during the Endgame
            transition.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine</td>
          <td>Core</td>
          <td>The Native Vault Engine will be upgraded to support Star ownership and transferred to the first Star
            incubated from the Incubator. It is temporarily controlled by Sky Core.While it is under the control
            of Sky Core, it will have a limited set of collateral types and risk parameters that the Stability
            Facilitators must implement according to the following subdocuments.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Vault Types</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Vault Types</td>
          <td>Core</td>
          <td>The collateral types of the Native Vault Engine and their parameters are defined in the subdocuments
            herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - ETH-A</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - ETH-A</td>
          <td>Core</td>
          <td>Current ETH-A parameters are:• Stability Fee: 6.00%• Liquidation Ratio: 145%• DC-IAM line:
            15,000,000,000 Dai• DC-IAM gap: 150,000,000 Dai• DC-IAM ttl: 21,600 seconds• cut: 99.00%• step: 90
            seconds• buf: 110.00%• cusp: 45.00%• tail: 7,200 seconds• chip: 0.10%• tip: 250• chop: 13%• hole:
            40,000,000 Dai• dust: 7,500 Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - ETH-B</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - ETH-B</td>
          <td>Core</td>
          <td>Current ETH-B parameters are:• Stability Fee: 6.50%• Liquidation Ratio: 130%• DC-IAM line:
            250,000,000 Dai• DC-IAM gap: 20,000,000 Dai• DC-IAM ttl: 21,600 seconds• cut: 99.00%• step: 60
            seconds• buf: 110.00%• cusp: 45.00%• tail: 4,800 seconds• chip: 0.10%• tip: 250• chop: 13%• hole:
            15,000,000 Dai• dust: 25,000 Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - ETH-C</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - ETH-C</td>
          <td>Core</td>
          <td>Current ETH-C parameters are:• Stability Fee: 5.75%• Liquidation Ratio: 170%• DC-IAM line:
            2,000,000,000 Dai• DC-IAM gap: 100,000,000 Dai• DC-IAM ttl: 28,800 seconds• cut: 99.00%• step: 90
            seconds• buf: 110.00%• cusp: 45.00%• tail: 7,200 seconds• chip: 0.10%• tip: 250• chop: 13%• hole:
            35,000,000 Dai• dust: 3,500 Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - WSTETH-A</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - WSTETH-A</td>
          <td>Core</td>
          <td>Current WSTETH-A parameters are:• Stability Fee: 7.00%• Liquidation Ratio: 150%• DC-IAM line:
            750,000,000 Dai• DC-IAM gap: 30,000,000 Dai• DC-IAM ttl: 43,200 seconds• cut: 99.00%• step: 90
            seconds• buf: 110.00%• cusp: 45.00%• tail: 7,200 seconds• chip: 0.10%• tip: 250• chop: 13%• hole:
            30,000,000 Dai• dust: 7,500 Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - WSTETH-B</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - WSTETH-B</td>
          <td>Core</td>
          <td>Current WSTETH-B parameters are:• Stability Fee: 6.75%• Liquidation Ratio: 175%• DC-IAM line:
            1,000,000,000 Dai• DC-IAM gap: 45,000,000 Dai• DC-IAM ttl: 43,200 seconds• cut: 99.00%• step: 90
            seconds• buf: 110.00%• cusp: 45.00%• tail: 7,200 seconds• chip: 0.10%• tip: 250• chop: 13%• hole:
            20,000,000 Dai• dust: 3,500 Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - WBTC-A</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - WBTC-A</td>
          <td>Core</td>
          <td>Current WBTC-A parameters are:• Stability Fee: 11.00%• Liquidation Ratio: 150%• DC-IAM line: 0 Dai•
            DC-IAM gap: 4,000,000 Dai• DC-IAM ttl: 86,400 seconds• cut: 99.00%• step: 90 seconds• buf: 110.00%•
            cusp: 45.00%• tail: 7,200 seconds• chip: 0.10%• tip: 250• chop: 0%• hole: 10,000,000 Dai• dust:
            7,500 Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - WBTC-B</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - WBTC-B</td>
          <td>Core</td>
          <td>Current WBTC-B parameters are:• Stability Fee: 11.50%• Liquidation Ratio: 150%• DC-IAM line: 0 Dai•
            DC-IAM gap: 2,000,000 Dai• DC-IAM ttl: 86,400 seconds• cut: 99.00%• step: 60 seconds• buf: 110.00%•
            cusp: 45.00%• tail: 4,800 sec• chip: 0.10%• tip: 250• chop: 0%• hole: 5,000,000 Dai• dust: 25,000
            Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - WBTC-C</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - WBTC-C</td>
          <td>Core</td>
          <td>Current WBTC-C parameters are:• Stability Fee: 10.75%• Liquidation Ratio: 175%• DC-IAM line: 0 Dai•
            DC-IAM gap: 8,000,000 Dai• DC-IAM ttl: 86,400 seconds• cut: 99.00%• step: 90 seconds• buf: 110.00%•
            cusp: 45.00%• tail: 7,200 seconds• chip: 0.10%• tip: 250• chop: 0%• hole: 10,000,000 Dai• dust:
            3,500 Dai</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Risk Parameter Definitions</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Risk Parameter Definitions</td>
          <td>Core</td>
          <td>The Native Vault Engine risk parameters are defined in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Liquidation Ratio</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Liquidation Ratio</td>
          <td>Core</td>
          <td>The Liquidation Ratio parameter limits the maximum amount of Dai debt that a vault user can 
            draw from their vault given the value of their collateral locked in that vault. In practice, it 
            expresses the minimum collateral in percentage terms that can support a given Dai debt. If the ratio 
            of a Vault user’s collateral to their debt drops below this value, their vault can be liquidated. Each 
            vault type has its own Liquidation Ratio. The Liquidation Ratio for each vault type is expressed as a 
            percentage value of the collateral that must be present in the vault to support its debt.<br>Changes to 
            the Liquidation Ratio are subject to the Operational Weekly Cycle, requiring a Governance Poll followed by an Executive Vote.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Debt Ceiling Limit</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Debt Ceiling Limit</td>
          <td>Core</td>
          <td>
            The Debt Ceiling Limit is numerically provided and acts as an upper limit. The Stability
            Facilitators can propose changes within this limit. Debt Ceiling Limit = Unlimited is defined as
            large enough to avoid being reached in the near future. The DC-IAM methodology contained in <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Debt Ceiling Instant Access Module
              (DC-IAM)</dfn> acts as a risk mitigation tool. It limits the rate at which exposure can increase
            in a short period of time in the event of an unexpected emergency.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Stability Fee</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Stability Fee</td>
          <td>Core</td>
          <td>
            The Stability Fee parameter is an annual percentage fee charged on the Dai generated on Vaults. It
            is expressed as an annual percentage yield but it is charged on a per-block basis in Dai. The Dai
            from this fee is minted, added to the Dai debt for the vault, and then transferred into the Surplus
            Buffer which is under the control of Sky Governance. Each vault type has its own Stability Fee that
            can be adjusted by the Stability Facilitators. The Stability Facilitators must regularly update
            Vault Types' Stability Fee according to requirements defined in the subdocuments below.The Stability
            Scope Advisors must develop a Rate System which can be used to set various interest rates, including
            the rates for Core Crypto vaults and the minimum lending rate for future Stars. The Rate System must
            be based on external benchmarks including the risk-free rate and the highest current sustainable
            rate in crypto financial markets. These rates should act as the lowest and highest base rates to
            which additional spreads can be added to better reflect the risks involved in specific lending
            activities.The Rate System must be dynamic, based on the state of Cash Stablecoins in the system,
            and naturally move the state towards the target Cash Stablecoins defined in <dfn>A.3.4
              - Collateral Portfolio - Asset Liability Management</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Rates SF</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Rates SF</td>
          <td>Core</td>
          <td>ETH:• SR = 0.00%• K = 27.43%• Ka = 0.00%• Kb = 40.00%• KFa = 5.50%• KFb = 40.50%WSTETH:• SR = 0.00%•
            K = 12.46%• Ka = 0.00%• Kb = 20.00%• KFa = 3.50%• KFb = 7.50%WBTC:• SR = 1.00%• K = 2.65%• Ka =
            3.00%• Kb = 10.00%• KFa = 3.50%• KFb = 35.50%</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Stability Fee Formulas</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Stability Fee Formulas</td>
          <td>Core</td>
          <td>List of Stability Fee Formulas according to the current conditions and chosen meta-parameters:•
            ETH-A: Dai Savings Rate (EDSR while active) + Normal LR Spread + Exposure Spread• ETH-B: Dai Savings
            Rate (EDSR while active) + Low LR Spread + Exposure Spread• ETH-C: Dai Savings Rate (EDSR while
            active) + High LR Spread + Exposure Spread• WSTETH-A: Dai Savings Rate (EDSR while active) + Normal
            LR Spread + Exposure Spread + Asset Spread• WSTETH-B: Dai Savings Rate (EDSR while active) + High LR
            Spread + Exposure Spread + Asset Spread• WBTC-A: Yield Collateral Yield Benchmark + Normal LR Spread
            + Exposure Spread• WBTC-B: Yield Collateral Yield Benchmark + Low LR Spread + Exposure Spread•
            WBTC-C: Yield Collateral Yield Benchmark + High LR Spread + Exposure Spread</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Spread Rates SF</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Spread Rates SF</td>
          <td>Core</td>
          <td>ETH-A Spread:• LR Spread is 0.25%• Exposure Spread is 1.49%• Asset Spread is 0.00%ETH-B Spread:• LR
            Spread is 0.75%• Exposure Spread is 1.49%• Asset Spread is 0.00%ETH-C Spread:• LR Spread is 0.00%•
            Exposure Spread is 1.49%• Asset Spread is 0.00%WSTETH-A Spread:• LR Spread is 0.25%• Exposure Spread
            is 1.49%• Asset Spread is 0.42%WSTETH-B Spread:• LR Spread is 0.00%• Exposure Spread is 1.49%• Asset
            Spread is 0.42%WBTC-A Spread:• LR Spread is 0.25%• Exposure Spread is 1.00%• Asset Spread is
            0.00%WBTC-B Spread:• LR Spread is 0.75%• Exposure Spread is 1.00%• Asset Spread is 0.00%WBTC-C
            Spread:• LR Spread is 0.00%• Exposure Spread is 1.00%• Asset Spread is 0.00%</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Debt Ceiling Instant Access Module
              (DC-IAM)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Debt Ceiling Instant Access Module (DC-IAM)
          </td>
          <td>Core</td>
          <td>The DC-IAM allows any user to adjust the Debt Ceiling of a supported vault type according to the
            rules defined in the DC-IAM smart contract logic and parameters set by the Stability Facilitators.
            The DC-IAM holds three parameters that can be set by Sky Governance for each vault type, (i) Maximum
            Debt Ceiling (line), (ii) Target Available Debt (gap), and (iii) Ceiling Increase Cooldown (ttl).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Maximum Debt Ceiling (line)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Maximum Debt Ceiling (line)</td>
          <td>Core</td>
          <td>
            The line parameter refers to the maximum value for the Debt Ceiling that the DC-IAM will allow in
            the given vault type. When using the DC-IAM to manage the Debt Ceiling of a vault type, the line
            parameter essentially replaces the Debt Ceiling parameter for that vault type. Rather than Sky
            Governance setting the Debt Ceiling directly, they will need to set the Maximum Debt Ceiling (line)
            in the DC-IAM. The line parameter is defined in Dai.The Maximum Debt Ceiling is defined in <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Debt Ceiling Limit</dfn> and is
            currently unlimited.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Target Available Debt (gap)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Target Available Debt (gap)</td>
          <td>Core</td>
          <td>The gap parameter controls how much of a gap the DC-IAM aims to maintain between the current debt
            usage and the Debt Ceiling of the vault type. The higher this value, the more risk there is from
            large collateral drops in very short amounts of time. The smaller this value, the more vault use is
            negatively affected. The gap parameter is defined in Dai.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Ceiling Increase Cooldown (ttl)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Ceiling Increase Cooldown (ttl)</td>
          <td>Core</td>
          <td>The Ceiling Increase Cooldown (ttl) parameter controls how frequently the Debt Ceiling can be
            increased by the DC-IAM. If a user attempts to use the DC-IAM to increase the Debt Ceiling of a
            vault type before this time expires, the transaction will fail to execute and the Debt Ceiling will
            remain unchanged. The ttl parameter in combination with the gap parameter enforces a maximum rate at
            which debt usage can increase over time using a given vault type. These parameters should be set
            such that the maximum increase over time can accommodate all reasonable usage of the vault type in
            question. The ttl parameter is defined in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Auction Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Auction Parameters</td>
          <td>Core</td>
          <td>A clear justification and analysis must be provided to validate any proposed changes to the
            parameters specified in this document. Before these changes are added to an Executive Vote, the
            Stability Facilitators must first propose a Governance Poll. However, in an emergency, the Stability
            Facilitators have the authority to bypass the Governance Poll and add the proposed parameters
            directly to an Executive Vote. The parameters contained herein must be regularly monitored and
            updated if needed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Auction Price Function (calc)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Auction Price Function (calc)</td>
          <td>Core</td>
          <td>
            The Auction Price Function is the mathematical function that determines how the collateral price
            changes over time during a collateral auction. Collateral auctions use a falling price auction,
            where the price starts high and decreases according to the function defined in this parameter. The
            Exponential Stair Step function contains two key parameters, cut and step, defined in <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Auction Price Function (cut)</dfn> and
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Auction Price Function (step)</dfn>,
            respectively.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Auction Price Function (cut)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Auction Price Function (cut)</td>
          <td>Core</td>
          <td>The cut parameter controls the 'depth' of each step in the function. A smaller cut means a smoother
            line; a large one means more pronounced steps. The cut parameter is defined as a multiplicative
            factor. For example, 0.99 equated to a 1% price drop.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Auction Price Function (step)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Auction Price Function (step)</td>
          <td>Core</td>
          <td>The step parameter controls the length of time between price drops. A smaller step means a smoother
            line; a large one means more pronounced steps. The step parameter is defined in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Auction Price Multiplier (buf)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Auction Price Multiplier (buf)</td>
          <td>Core</td>
          <td>The buf parameter is a multiplier that is applied to the starting price of a collateral auction.
            Each vault type has its own Auction Price Multiplier that can be adjusted by Sky Governance
            separately. This multiplier is intended to be greater than 1.0x because Liquidations 2.0 uses
            falling price auctions. This means that it is generally preferable for the auction price to begin
            above the market price and then fall to the correct value over some amount of time. The buf
            parameter is defined as a multiplicative factor.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Max Auction Drawdown (cusp)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Max Auction Drawdown (cusp)</td>
          <td>Core</td>
          <td>The Max Auction Drawdown is the maximum percentage drop in collateral price during a collateral
            auction before the auction is reset. 'Collateral price' in this context refers to the collateral
            auction price rather than the collateral market price.The Max Auction Drawdown parameter overlaps
            with the Max Auction Duration parameter in that an auction will need to be reset once either maximum
            is exceeded.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Max Auction Duration (tail)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Max Auction Duration (tail)</td>
          <td>Core</td>
          <td>The Max Auction Duration parameter sets the maximum time that can elapse before an auction needs to
            reset for a particular vault type. Expressed in seconds, this parameter determines when an auction
            can no longer settle and must be reset.The Max Auction Duration parameter overlaps with the Max
            Auction Drawdown parameter in that an auction will need to be reset once either maximum is exceeded.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Proportional Kick Incentive (chip)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Proportional Kick Incentive (chip)</td>
          <td>Core</td>
          <td>The Proportional Kick Incentive parameter represents a reward in Dai paid to the keepers that
            trigger collateral liquidation auctions in the Sky Protocol. The Proportional Kick Incentive is set
            as a percentage and represents a portion of Dai based on the debt of the vault that is being
            liquidated. The Dai is rewarded for each liquidation auction at the point the auction is triggered.
            Each vault type has its own Proportional Kick Incentive that may be adjusted separately by Sky
            Governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Flat Kick Incentive (tip)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Flat Kick Incentive (tip)</td>
          <td>Core</td>
          <td>The Flat Kick Incentive parameter represents a reward in Dai paid to the keepers that trigger
            collateral liquidation auctions in the Sky Protocol. The Flat Kick Incentive is a fixed amount of
            Dai that is rewarded for each liquidation auction at the point the auction is triggered. Each vault
            type has its own Flat Kick Incentive that may be adjusted separately by Sky Governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Liquidation Penalty (chop)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Liquidation Penalty (chop)</td>
          <td>Core</td>
          <td>The Liquidation Penalty parameter controls the fee vault owners must pay when their position is
            liquidated due to insufficient collateral. For a vault holder to receive any collateral back from
            the liquidations process, the debt and Liquidation Penalty must be covered by the collateral
            auction. Each vault type has its own Liquidation Penalty that can be adjusted by Sky Governance.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Local Liquidation Limit (hole)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Local Liquidation Limit (hole)</td>
          <td>Core</td>
          <td>The Local Liquidation Limit sets the maximum amount of Dai debt for which collateral auctions can be
            active at any one time within a particular vault type. When the total Dai value of auctions exceeds
            this maximum for a particular vault type, no more collateral can be auctioned using that vault type
            until others are completed. Each vault type has a separate Local Liquidation Limit.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Debt Floor (dust)</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Debt Floor (dust)</td>
          <td>Core</td>
          <td>The Debt Floor parameter controls the minimum amount of Dai that can be minted using a specific
            vault type for an individual vault. If a user tries to mint Dai and the amount of Dai minted would
            not put the vault's amount of Dai minted above its Debt Floor, the transaction will fail and no DAi
            will be minted. Likewise, if a user attempts to pay back debt such that their debt will equal less
            than the Debt Floor and greater than zero, the transaction will fail and no Dai will be paid back.
            Each vault type has its own Debt Floor that can be adjusted by Sky Governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Collateral Offboarding</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Collateral Offboarding</td>
          <td>Core</td>
          <td>The processes for offboarding Native Vault Engine collateral are defined in the subdocuments herein.
          </td>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Collateral Offboarding Process</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Collateral Offboarding Process</td>
          <td>Core</td>
          <td>The Stability Facilitators, in consultation with the Stability Scope Advisors, must use the Operational Weekly Cycle to 
            offboard Native Vault Engine collateral pursuant to A.3.9 - Measures For Endgame Transition - Native Vault Engine - 
            Collateral Offboarding and its subdocuments.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Offboarding Low Usage Collateral</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Offboarding Low Usage Collateral</td>
          <td>Core</td>
          <td>
            To protect the Protocol from unnecessary complexity, the Stability Facilitators must offboard
            collateral types specified in <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Vault Types</dfn> if they fall below a
            total debt of 20 million.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Offboarding WBTC Collateral</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Offboarding WBTC Collateral</td>
          <td>Core</td>
          <td>
            WBTC-A, WBTC-B and WBTC-C are defined in <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Vault Types</dfn> only for the purpose
            of Stability Fee consistency. These are otherwise not considered Native Vault Engine collateral and
            should be offboarded according to <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Offboarding Other Collateral</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Offboarding Other Collateral</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Offboarding Other Collateral</td>
          <td>Core</td>
          <td>All other collateral types should be offboarded when the Stability Facilitators deem it appropriate
            and when new mechanisms are in place to take over the roles previously covered by the offboarded
            collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Oracles</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Oracles</td>
          <td>Core</td>
          <td>The Native Vault Engine collateral types of ETH, STETH, WBTC will specifically use the Chronicle v3
            oracle solution, until at least January 1st 2026. The Native Vault Engine collateral types must be
            migrated to the new version of the Chronicle v3 oracle when it is feasible to do so.Other oracle
            solutions, including diversified oracles, will only be considered until January 1st, 2026, and only
            if there are unresolvable security concerns with the Chronicle v3 oracles.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Updates</dfn>
          </td>
          <td>Measures For Endgame Transition - Native Vault Engine - Updates</td>
          <td>Core</td>
          <td>
             If not otherwise specified, the Stability Facilitators have the ability to modify any of the parameters defined in <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Risk Parameter Definitions</dfn> for any
            of the Vault Types in <dfn>A.3.9
              - Measures For Endgame Transition - Native Vault Engine - Vault Types</dfn>. As a general rule, the modification of said parameters 
            is pursuant to the Operational Weekly Cycle and can be effected directly via an Executive Vote, without requiring a Governance Poll. 
            Exceptions to this general rule must be clearly stated in the relevant Atlas document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Keepers</dfn>
          </td>
          <td>Measures For Endgame Transition - Keepers</td>
          <td>Core</td>
          <td>Keeper networks provide critical services for the back-end systems of Sky, enhancing protocol
            security and efficiency. There are multiple providers of keeper networks in the Sky Ecosystem,
            decentralizing the keepers and ensuring redundancy. The subdocuments herein specify ongoing payment
            streams to compensate the different providers of keeper networks.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Keepers - Gelato Network</dfn>
          </td>
          <td>Measures For Endgame Transition - Keepers - Gelato Network</td>
          <td>Core</td>
          <td>Gelato NetworkBudget: 1,500 USDS per dayStream Duration: 3 years (start date 29 May 2023).</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Keepers - Keep3r Network</dfn>
          </td>
          <td>Measures For Endgame Transition - Keepers - Keep3r Network</td>
          <td>Core</td>
          <td>Keep3r NetworkBudget: 1,500 USDS per dayStream Duration: 3 years (start date 29 May 2023).</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Keepers - Chainlink Automation</dfn>
          </td>
          <td>Measures For Endgame Transition - Keepers - Chainlink Automation</td>
          <td>Core</td>
          <td>Chainlink AutomationBudget: 1,500 USDS per dayStream Duration: 3 years (start date 29 May 2023).
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module</td>
          <td>Core</td>
          <td>
            Spark is able to temporarily borrow Dai from Sky Core through the Spark Dai Direct Deposit Module
            (D3M).This will be replaced by borrowing at the Stars Credit Line Borrow Rate specified in <dfn>A.3.2
              - Core Stability Parameters - Parameters - Stars Credit Line Borrow Rate</dfn> after the launch of
            Star Vaults and the development of a new Rate System.The Spark Dai Direct Deposit Module is managed
            by the Stability Facilitators, in consultation with the Stability Scope Advisors, pursuant to the
            subdocuments herein.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module - Parameter Definitions</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module - Parameter Definitions</td>
          <td>Core</td>
          <td>The subdocuments herein define the Spark Dai Direct Deposit Module parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module - Target Available Debt
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module - Target Available Debt Definition
          </td>
          <td>Core</td>
          <td>The gap parameter is the target gap between the debt usage and the debt ceiling.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module - Debt Ceiling Increase
              Cooldown Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module - Debt Ceiling Increase Cooldown
            Definition</td>
          <td>Core</td>
          <td>The ttl parameter is the minimum time requirement before it is possible to increase the debt
            ceiling, expressed in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module - Maximum Debt Ceiling
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module - Maximum Debt Ceiling Definition
          </td>
          <td>Core</td>
          <td>The line is the maximum amount of debt that can be borrowed under the Spark Dai Direct Deposit
            Module.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module - Buffer Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module - Buffer Definition</td>
          <td>Core</td>
          <td>buffer is a fixed-sized amount of pre-minted Dai which the Spark Dai Direct Deposit Module is designed
            to maintain in most instances.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module - Debt Write Off Timelock Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module - Debt Write Off Timelock Definition</td>
          <td>Core</td>
          <td>tau is the timelock required before bad debt can be written off after the Spark Dai Direct Deposit Module has been shut 
              down, expressed in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Dai Direct Deposit Module - Current Configuration</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Dai Direct Deposit Module - Current Configuration</td>
          <td>Core</td>
          <td>The current parameters of the Spark Dai Direct Deposit Module are:• gap: 40 million Dai• ttl: 24
            hours• line: 2.5 billion Dai• buffer: 100 million Dai• tau: 7 days</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - Spark Deployment Of New Direct Deposit Modules</dfn>
          </td>
          <td>Measures For Endgame Transition - Spark Deployment Of New Direct Deposit Modules</td>
          <td>Core</td>
          <td>The Stability Facilitators can directly include the deployment of new Direct Deposit Modules in
            Executive Votes, with risk parameters defined by the Stability Facilitators. These parameters should
            be based on input from the Stability Scope Advisors and should best serve the needs of the Sky
            Ecosystem and its collaboration with other protocols.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Collateral Onboarding/Offboarding</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Collateral Onboarding/Offboarding </td>
          <td>Core</td>
          <td>The onboarding/offboarding of SparkLend collateral is temporarily controlled by Sky Core. It is 
            implemented by the Stability Facilitators, in consultation with the Stability Scope Advisors, 
            through the Operational Weekly Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters</td>
          <td>Core</td>
          <td>The SparkLend risk parameters are temporarily controlled by Sky Core.While the risk parameters are
            under the control of Sky Core, they are implemented by the Stability Facilitators in consultation
            with the Stability Scope Advisors, as specified in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Definitions</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Definitions</td>
          <td>Core</td>
          <td>The subdocuments herein define the SparkLend risk parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Borrow Rate Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Borrow Rate Definition</td>
          <td>Core</td>
          <td>The borrow rate is the annualized percentage yield for borrowing the asset, which is determined
            based on the market's Interest Rate Model and actual utilization in the market.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Supply Rate Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Supply Rate Definition</td>
          <td>Core</td>
          <td>The supply rate is the annualized percentage yield for supplying the asset, which is determined
            based on borrow rate as:supply rate = market utilization * borrow rate * (1-reserve factor)</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Interest Rate Model
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Interest Rate Model Definition</td>
          <td>Core</td>
          <td>
            The Interest Rate Model ("IRM") is defined by four main parameters:1. Base Rate - the starting rate
            at 0% utilization2. Variable Slope 1 - the rate at optimal utilization3. Variable Slope 2 - the rate
            at 100% utilization4. Utilization - the utilization itselfThe Base Rate, Slope 1, and Slope 2
            parameters are further defined in:<dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Base Rate Definition</dfn>; <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Slope 1 Definition</dfn>; and <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Slope 2 Definition</dfn>.All
            markets except Dai use this IRM. The IRM for Dai is independent of utilization and is defined as a
            spread over the Core Stability Parameters Base Rate set forth in <dfn>A.3.2
              - Core Stability Parameters - Parameters - Base Rate</dfn>. The spread is determined by the
            Stability Facilitators, in consultation with the Stability Scope Advisors.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - LTV Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - LTV Definition</td>
          <td>Core</td>
          <td>The LTV is the maximum percentage of the value of collateral that borrowers can borrow against their
            collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Liquidation Threshold
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Liquidation Threshold Definition</td>
          <td>Core</td>
          <td>The liquidation threshold is the maximum debt a borrower can owe as a percentage of their collateral
            before their position is considered under-collateralized and thus at risk of being liquidated.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - High Efficiency Mode Category
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - High Efficiency Mode Category
            Definition</td>
          <td>Core</td>
          <td>The High Efficiency Mode Category groups assets that are highly correlated with each other into
            buckets, for example Stablecoins or various forms of ETH. Borrowing against an asset to acquire
            another asset in the same category can support higher LTVs and liquidation thresholds as determined
            by the protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Liquidation Bonus Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Liquidation Bonus Definition</td>
          <td>Core</td>
          <td>The liquidation bonus is the bonus for liquidating an unhealthy loan, or equivalently the penalty
            for having an unhealthy loan liquidated. The party paying off the unhealthy loan is entitled to
            collateral with an equivalent value as the debt paid off plus the liquidation bonus.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Reserve Factor Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Reserve Factor Definition</td>
          <td>Core</td>
          <td>The reserve factor is the percentage of interest payments paid to the protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Supply Cap Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Supply Cap Definition</td>
          <td>Core</td>
          <td>The supply cap is the maximum amount of the asset that can be supplied.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Borrow Cap Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Borrow Cap Definition</td>
          <td>Core</td>
          <td>The borrow cap is the maximum amount of the asset that can be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Optimal Utilization
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Optimal Utilization Definition</td>
          <td>Core</td>
          <td>The optimal utilization represents the desired target utilization of the borrowing capacity for the
            asset. It is an input used to determine the interest rate of borrowing. When the actual utilization
            is above the optimal utilization, borrowing rates will be higher; and when the actual utilization is
            below the optimal utilization, borrowing rates will be lower.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Isolated Debt Ceiling
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Isolated Debt Ceiling Definition</td>
          <td>Core</td>
          <td>The isolated debt ceiling represents the maximum amount that can be borrowed against designated
            isolated assets, as determined by the Stability Facilitators in consultation with the Stability
            Scope Advisors. Only Stablecoins may be borrowed against isolated assets.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Base Rate Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Base Rate Definition</td>
          <td>Core</td>
          <td>The base rate is an input used to determine the interest rate of borrowing. The base rate is
            adjusted based on actual borrowing utilization relative to optimal borrowing utilization to arrive
            at the actual borrowing rate.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Reserve State Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Reserve State Definition</td>
          <td>Core</td>
          <td>The reserve state represents the state of the market for a particular collateral type. The reserve
            state may be:• Active - all activities may occur• Frozen - all activities may occur except for
            supplying and borrowing• Paused - no activities may occur</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Slope 1 Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Slope 1 Definition</td>
          <td>Core</td>
          <td>Slope 1 is the interest rate at optimal utilization in the Interest Rate Model.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Slope 1 Spread Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Slope 1 Spread Definition</td>
          <td>Core</td>
          <td>The Slope 1 Spread is the difference between the WETH interest rate at optimal utilization in the
            Interest Rate Model and the staking yield on stETH. The Slope 1 Spread Parameter is only defined for
            WETH.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Slope 2 Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Slope 2 Definition</td>
          <td>Core</td>
          <td>Slope 2 is the interest rate at 100% utilization in the Interest Rate Model.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Collateral-Enabled
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Collateral-Enabled Definition</td>
          <td>Core</td>
          <td>If Collateral is Enabled, then the asset may be used as collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Borrowing-Enabled Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Borrowing-Enabled Definition</td>
          <td>Core</td>
          <td>If Borrowing is Enabled, then the asset may be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Isolated Collateral-Enabled
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Isolated Collateral-Enabled Definition
          </td>
          <td>Core</td>
          <td>If Isolated Collateral is Enabled, only Stablecoins can be borrowed when using the asset as
            collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Isolation Mode Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Isolation Mode Definition</td>
          <td>Core</td>
          <td>When a user is in Isolation Mode, only assets with Isolated Borrow enabled can be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Siloed Borrowing-Enabled
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Siloed Borrowing-Enabled Definition
          </td>
          <td>Core</td>
          <td>If Siloed Borrowing is Enabled, then when borrowing the asset, no other asset may be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Flash Loan Enabled Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Flash Loan Enabled Definition
          </td>
          <td>Core</td>
          <td>If the Flash Loan Enabled parameter is activated, then the asset may be borrowed using a flash loan.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Total Flash Loan Fee Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Total Flash Loan Fee Definition
          </td>
          <td>Core</td>
          <td>The Total Flash Loan Fee incorporates a fee paid to the protocol and a fee paid to liquidity providers. This total fee is 
              calculated as a percentage of the flash loan amount. Of the Total Flash Loan Fee, the Protocol Flash Loan Fee is paid to the 
              protocol, with the remainder paid to liquidity providers.
              The Total Flash Loan Fee is set on a protocol level, regardless of what assets are being borrowed.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Protocol Flash Loan Fee Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Protocol Flash Loan Fee Definition
          </td>
          <td>Core</td>
          <td>The Protocol Flash Loan Fee is the fee for a flash loan paid to the protocol as a percentage of the flash loan amount.
              The Protocol Flash Loan Fee is set on a protocol level, regardless of what assets are being borrowed.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Modification</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Modification</td>
          <td>Core</td>
          <td>
            The Stability Facilitators, in consultation with the Stability Scope Advisors, may recommend changes to 
            any of the parameters specified in the subdocuments of<dfn> A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Definitions</dfn> or <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Parameter
              Definitions</dfn>.<br>As a general rule, the modification of said parameters is pursuant to the Operational 
            Weekly Cycle and can be effected directly via an Executive Vote, without requiring a Governance Poll.<br>Changes 
            to the parameters defined in the following documents are exceptions to the general rule and require a Governance 
            Poll followed by an Executive Vote:• <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters -  Liquidation Threshold Definition</dfn>• <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters -  Liquidation Bonus Definition</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Current Configuration</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Current Configuration</td>
          <td>Core</td>
          <td>The subdocuments herein define the current configuration of the SparkLend risk parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - GNO Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - GNO Risk Parameters</td>
          <td>Core</td>
          <td>The current GNO risk parameters are:• LTV: 0%• Liquidation Threshold: 25%• E-mode Category: N/A•
            Liquidation Bonus: 10%• Reserve Factor: 0%• Supply Cap: N/A• Borrow Cap: N/A• Optimal Utilization:
            100%• Isolated Debt Ceiling: $5,000,000• Base Rate: 1%• Slope 1: 0%• Slope 2: 0%• Reserve State:
            Frozen• Collateral: Yes• Borrowing: No• Isolated Collateral: Yes• Isolated Borrowing: No• Siloed
            Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Dai Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Dai Risk Parameters</td>
          <td>Core</td>
          <td>The current Dai risk parameters are:• LTV: 0%• Liquidation Threshold: 0.01%• E-mode Category: N/A•
            Liquidation Bonus: 4.5%• Reserve Factor: 0%• Supply Cap: N/A• Borrow Cap: N/A• Optimal Utilization:
            N/A• Isolated Debt Ceiling: N/A• Base Rate: N/A• Slope 1: N/A• Slope 2: N/A• Reserve State: Active•
            Collateral: Yes• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: Yes• Siloed Borrowing:
            No• Flash Loan Enabled: Yes
            The Dai Borrow Rate is set directly by the Stability Facilitators in consultation with the Stability Scope Advisors, and is 
            currently equal to ~9.5%, which is the Dai Savings Rate plus 1%.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - WETH Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - WETH Risk Parameters</td>
          <td>Core</td>
          <td>The current WETH risk parameters are:• LTV: 82%• Liquidation Threshold: 83%• E-mode Category: ETH•
            Liquidation Bonus: 5%• Reserve Factor: 5%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap
            automater• Optimal Utilization: 90%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: N/A•
            Slope 1 Spread: -0.50%• Slope 2: 120%• Reserve State: Active• Collateral: Yes• Borrowing: Yes•
            Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes
            The Slope 1 parameter for WETH is calculated based on the following formula:<br>
            slope 1 = stETH yield + slope 1 spread - base rate</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - USDT Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - USDT Risk Parameters</td>
          <td>Core</td>
          <td>The current USDT risk parameters are:• LTV: 0%• Liquidation Threshold: 0%• E-mode Category: USD•
            Liquidation Bonus: 0%• Reserve Factor: 5%• Supply Cap: 30,000,000 USDT• Borrow Cap: Set by cap
            automater• Optimal Utilization: 95%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 6.83%•
            Slope 2: 15%• Reserve State: Active• Collateral: No• Borrowing: Yes• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - WBTC Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - WBTC Risk Parameters</td>
          <td>Core</td>
          <td>The current WBTC risk parameters are:• LTV: 0%• Liquidation Threshold: 55%• E-mode Category: N/A•
            Liquidation Bonus: 7%• Reserve Factor: 20%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap
            automater• Optimal Utilization: 60%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 2%• Slope
            2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated
            Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - sDai Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - sDai Risk Parameters</td>
          <td>Core</td>
          <td>The current sDai risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: USD•
            Liquidation Bonus: 5%• Reserve Factor: 10%• Supply Cap: Set by cap automater• Borrow Cap: N/A•
            Optimal Utilization: 100%• Isolated Debt Ceiling: N/A• Base Rate: 1%• Slope 1: 0%• Slope 2: 0%•
            Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated Borrowing:
            No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - wstETH Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - wstETH Risk Parameters</td>
          <td>Core</td>
          <td>The current wstETH risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: ETH•
            Liquidation Bonus: 7%• Reserve Factor: 30%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap
            automater• Optimal Utilization: 70%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 2%•
            Slope 2: 200%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - USDC Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - USDC Risk Parameters</td>
          <td>Core</td>
          <td>The current USDC risk parameters are:• LTV: 0%• Liquidation Threshold: 0%• E-mode Category: USD•
            Liquidation Bonus: 0%• Reserve Factor: 5%• Supply Cap: 60,000,000 USDC• Borrow Cap: Set by cap
            automater• Optimal Utilization: 95%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 6.83%•
            Slope 2: 15%• Reserve State: Active• Collateral: No• Borrowing: Yes• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - weETH Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - weETH Risk Parameters</td>
          <td>Core</td>
          <td>The current weETH risk parameters are:• LTV: 72%• Liquidation Threshold: 73%• E-mode Category: N/A•
            Liquidation Bonus: 10%• Reserve Factor: 15%• Supply Cap: Set by cap automator• Borrow Cap: N/A• Optimal
            Utilization: 45%• Isolated Debt Ceiling: $200,000,000• Base Rate: 5%• Slope 1: 15%• Slope 2: 300%•
            Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: Yes• Isolated Borrowing:
            No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - rETH Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - rETH Risk Parameters</td>
          <td>Core</td>
          <td>The current rETH risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: ETH•
            Liquidation Bonus: 7%• Reserve Factor: 15%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap
            automater• Optimal Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 0.25%• Slope 1: 7%•
            Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - LBTC Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - LBTC Risk Parameters</td>
          <td>Core</td>
          <td>The current LBTC risk parameters are:• LTV: 65%• Liquidation Threshold: 70%• E-mode Category: 3•
            Liquidation Bonus: 8%• Reserve Factor: 15%• Supply Cap: 250 LBTC• Borrow Cap: 0• Optimal 
            Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 5%• Slope 1: 15%• Slope 2: 300%• 
            Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - tBTC Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - tBTC Risk Parameters</td>
          <td>Core</td>
          <td>The current tBTC risk parameters are:• LTV: 65%• Liquidation Threshold: 70%• E-mode Category: 0•
            Liquidation Bonus: 8%• Reserve Factor: 20%• Supply Cap: 125 tBTC• Borrow Cap: 25 tBTC• Optimal 
            Utilization: 60%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 4%•Slope 2: 300%• 
            Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - ezETH Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - ezETH Risk Parameters</td>
          <td>Core</td>
          <td>The current ezETH risk parameters are:• LTV: 72%• Liquidation Threshold: 73%• E-mode Category: 0•
            Liquidation Bonus: 10%• Reserve Factor: 15%• Supply Cap: 2,000 ezETH• Borrow Cap: 0• Optimal 
            Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 5%• Slope 1: 15%•Slope 2: 300%• 
            Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - rsETH Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - rsETH Risk Parameters</td>
          <td>Core</td>
          <td>The current rsETH risk parameters are:• LTV: 72%• Liquidation Threshold: 73%• E-mode Category: 0•
            Liquidation Bonus: 10%• Reserve Factor: 15%• Supply Cap: 2,000 rsETH• Borrow Cap: 0• Optimal 
            Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 5%• Slope 1: 15%•Slope 2: 300%• 
            Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Total Flash Loan Fee Current Value</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Total Flash Loan Fee Current Value</td>
          <td>Core</td>
          <td>The Total Flash Loan Fee is 0.00%.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Protocol Flash Loan Fee Current Value</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Protocol Flash Loan Fee Current Value</td>
          <td>Core</td>
          <td>The Protocol Flash Loan Fee is 0.00%.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - cbBTC Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - cbBTC Risk Parameters</td>
          <td>Core</td>
          <td>The current cbBTC risk parameters are:• LTV: 74%• Liquidation Threshold: 75%• E-mode Category: N/A
            • Liquidation Bonus: 8%• Reserve Factor: 20%• Supply Cap: 500 cbBTC• Borrow Cap: 50 cbBTC
            • Optimal Utilization: 60%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 4%
            • Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - sUSDS Risk Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - sUSDS Risk Parameters</td>
          <td>Core</td>
          <td>The current sUSDS risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: N/A
            • Liquidation Bonus: 5%• Reserve Factor: 10%• Supply Cap: 50,000,000 sUSDS• Borrow Cap: 0 sUSDS
            • Optimal Utilization: 80%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 2%
            • Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No•
            Isolated Borrowing: No• Siloed Borrowing: No</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automators</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automators</td>
          <td>Core</td>
          <td>
            Cap Automaters allow the Supply Cap defined in <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Supply Cap Definition</dfn> and
            the Borrow Cap defined in <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Borrow Cap Definition</dfn> to be
            dynamically adjusted.The Cap Automater is defined in terms of three parameters:1. gap - the target
            available exposure2. ttl - the cooldown period for cap increases3. max - the absolute maximum
            exposureAny user can permissionlessly update a covered Supply Cap or Borrow Cap so the available
            exposure is equal to the target, as long as the resulting exposure does not exceed the specified
            maximum limit and the cooldown period has elapsed in the case of increases to the Supply Cap or
            Borrow Cap.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Parameter
              Definitions</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Parameter Definitions
          </td>
          <td>Core</td>
          <td>The subdocuments herein define the parameters of the Cap Automators.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Target Available
              Exposure Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Target Available
            Exposure Definition</td>
          <td>Core</td>
          <td>The gap parameter is the target gap between the supply usage and the Supply Cap, in the case of the
            Supply Cap, or between the borrow usage and the Borrow Cap, in the case of the Borrow Cap.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Cooldown Period
              Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Cooldown Period
            Definition</td>
          <td>Core</td>
          <td>The ttl parameters is the minimum time requirement before it is possible to increase the Supply Cap
            or Borrow Cap, expressed in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Absolute Maximum
              Exposure Definition</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Absolute Maximum
            Exposure Definition</td>
          <td>Core</td>
          <td>The max parameter is the maximum the Supply Cap or Borrow Cap can be increased to.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Current
              Configuration</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator Current Configuration
          </td>
          <td>Core</td>
          <td>The subdocuments herein define the current configuration of the cap automators for each covered
            market.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator WETH
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator WETH Parameters</td>
          <td>Core</td>
          <td>The current WETH cap automator parameters are:• Supply cap ◦ gap: 150,000 WETH ◦ ttl: 12 hours ◦
            max: 2 million WETH• Borrow cap ◦ gap: 10,000 WETH ◦ ttl: 12 hours ◦ max: 1 million WETH</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator wstETH
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator wstETH Parameters</td>
          <td>Core</td>
          <td>The current wstETH cap automator parameters are:• Supply cap ◦ gap: 50,000 wstETH ◦ ttl: 12 hours ◦
            max: 1.2 million wstETH ◦ Borrow cap ◦ gap: 10,000 wstETH ◦ ttl: 12 hours ◦ max: 1,000,000 wstETH</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator rETH
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator rETH Parameters</td>
          <td>Core</td>
          <td>The current rETH cap automator parameters are:• Supply cap ◦ gap: 10,000 rETH ◦ ttl: 12 hours ◦ max:
            80,000 rETH• Borrow cap ◦ gap: 100 rETH ◦ ttl: 12 hours ◦ max: 2,400 rETH</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator WBTC
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator WBTC Parameters</td>
          <td>Core</td>
          <td>The current WBTC cap automator parameters are:• Supply cap ◦ gap: 200 WBTC ◦ ttl: 12 hours ◦ max:
            5,000 WBTC• Borrow cap ◦ gap: 1 WBTC ◦ ttl: 12 hours ◦ max: 1 WBTC</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator sDai
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator sDai Parameters</td>
          <td>Core</td>
          <td>The current sDai cap automator parameters are:• Supply cap ◦ gap: 50 million sDai ◦ ttl: 12 hours ◦
            max: 1 billion sDai• Borrow cap: n/a - not a borrowable asset ◦ gap: n/a ◦ ttl: n/a ◦ max: 0 sDAI
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator USDC
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator USDC Parameters</td>
          <td>Core</td>
          <td>The current USDC cap automator parameters are:• Supply cap ◦ gap: n/a ◦ ttl: n/a ◦ max: 60 million
            USDC• Borrow cap ◦ gap: 6 million USDC ◦ ttl: 12 hours ◦ max: 57 million USDC</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator USDT
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator USDT Parameters</td>
          <td>Core</td>
          <td>The current USDT cap automator parameters are:• Supply cap ◦ gap: n/a ◦ ttl: n/a ◦ max: 30 million
            USDT• Borrow cap ◦ gap: 3 million USDT ◦ ttl: 12 hours ◦ max: 28.5 million USDT</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator cbBTC
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator cbBTC Parameters</td>
          <td>Core</td>
          <td>The current cbBTC cap automator parameters are:• Supply cap ◦ gap: 500 cbBTC ◦ ttl: 12 hours ◦ max: 10,000 cbBTC
          • Borrow cap ◦ gap: 50 cbBTC ◦ ttl: 12 hours ◦ max: 500 cbBTC</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator sUSDS
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator sUSDS Parameters</td>
          <td>Core</td>
          <td>The current sUSDS cap automator parameters are:• Supply cap ◦ gap: 50 million sUSDS ◦ ttl: 12 hours ◦ max: 500 million sUSDS
            • Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator weETH
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator weETH Parameters</td>
          <td>Core</td>
          <td>The current weETH cap automator parameters are:• Supply cap ◦ gap: 10,000 weETH ◦ ttl: 12 hours ◦ max: 500,000 weETH
            • Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator LBTC
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator LBTC Parameters</td>
          <td>Core</td>
          <td>The current LBTC cap automator parameters are:• Supply cap ◦ gap: 250 LBTC ◦ ttl: 12 hours ◦ max: 2,500 LBTC
            • Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator tBTC
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator tBTC Parameters</td>
          <td>Core</td>
          <td>The current tBTC cap automator parameters are:• Supply cap ◦ gap: 125 tBTC ◦ ttl: 12 hours ◦ max: 500 tBTC
          • Borrow cap ◦ gap: 25 tBTC ◦ ttl: 12 hours ◦ max: 250 tBTC</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator ezETH
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator ezETH Parameters</td>
          <td>Core</td>
          <td>The current ezETH cap automator parameters are:• Supply cap ◦ gap: 2,000 ezETH ◦ ttl: 12 hours ◦ max: 20,000 ezETH
            • Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator rsETH
              Parameters</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Cap Automator rsETH Parameters</td>
          <td>Core</td>
          <td>The current rsETH cap automator parameters are:• Supply cap ◦ gap: 2,000 rsETH ◦ ttl: 12 hours ◦ max: 20,000 rsETH
            • Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Kill Switch</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Kill Switch</td>
          <td>Core</td>
          <td>
            The kill switch disables all borrowing across SparkLend markets in the event of a depeg on key
            collateral assets.The kill switch is defined in terms of a threshold for specified pegged assets. If
            the ratio of the price of a specified asset to its peg is equal to or less than the threshold, then
            any user can trigger the kill switch to disable borrowing across all SparkLend markets.After the
            kill switch is triggered, markets can be reactivated by Sky Governance after resetting the kill
            switch. Resetting the kill switch is subject to the Governance Security Delay specified in <dfn>A.1.9
              - A2 - Sky Core Governance Security - Governance Security Delay Requirements</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.9
              - Measures For Endgame Transition - SparkLend Risk Parameters - Kill Switch Current
              Configuration</dfn>
          </td>
          <td>Measures For Endgame Transition - SparkLend Risk Parameters - Kill Switch Current Configuration</td>
          <td>Core</td>
          <td>The kill switch currently covers the following assets with the specified thresholds:• STETH/ETH - 0.95</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.1
              - A1 - Core Tokens - USDS</dfn>
          </td>
          <td>Core Tokens - USDS</td>
          <td>Section</td>
          <td>USDS is the Stablecoin product of the Sky Protocol. It is designed to remain stable against USD, and its supply is regulated through the Peg Stability Module and the Allocation System, as governed by the Stability Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.1
              - Core Tokens - USDS - USDS Launch</dfn>
          </td>
          <td>Core Tokens - USDS - USDS Launch</td>
          <td>Core</td>
          <td>In the Endgame Token Launch Phase, USDS is launched as an upgrade to Dai, offering new features,
            including Token Rewards. Dai can be exchanged to and from USDS at a rate of 1:1.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.1
              - A2 - Core Tokens - SKY</dfn>
          </td>
          <td>Core Tokens - SKY</td>
          <td>Section</td>
          <td>SKY is the governance token of the Sky Protocol. It grants voting rights in the Sky Governance
            system. Its liquidity is boosted by the Smart Burn Engine, as governed by the Stability Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.1
              - Core Tokens - SKY - SKY Launch</dfn>
          </td>
          <td>Core Tokens - SKY - SKY Launch</td>
          <td>Core</td>
          <td>In the Endgame Token Launch Phase, SKY is launched as an upgrade to MKR. MKR can be exchanged to and
            from SKY at a rate of 1:24,000.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.2
              - A1 - SkyLink - Multichain Support Native Mechanisms</dfn>
          </td>
          <td>SkyLink - Multichain Support Native Mechanisms</td>
          <td>Section</td>
          <td>SkyLink deployments support features including the Savings Rate Mechanism (including sUSDS), the
            Token Rewards Mechanism and the Activation Mechanism.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.3
              - A1 - Savings Rate And Token Reward Mechanism - Savings Rates</dfn>
          </td>
          <td>Savings Rate And Token Reward Mechanism - Savings Rates</td>
          <td>Section</td>
          <td>The Savings Rate Mechanism includes both the legacy Dai Savings Rate Mechanism and the Sky Savings
            Rate. The Sky Savings Rate includes a built-in sUSDS mechanism. The Savings Rate is governed by the
            Stability Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.3
              - A2 - Savings Rate And Token Reward Mechanism - Token Reward Mechanism</dfn>
          </td>
          <td>Savings Rate And Token Reward Mechanism - Token Reward Mechanism</td>
          <td>Section</td>
          <td>The Token Rewards Mechanism provides SKY rewards to USDS users. Star tokens are also distributed
            through a Token Rewards Mechanism.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - A1 - Activation And Sealing Mechanisms - SKY Activation</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - SKY Activation</td>
          <td>Section</td>
          <td>SKY Activation can be done by any SKY holder through the SKY Activation Mechanism available on
            Ethereum Mainnet and SkyLink Deployments. SKY Activation provides USDS Rewards or Star Token
            Rewards.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - Activation And Sealing Mechanisms - SKY Activation - Availability</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - SKY Activation - Availability</td>
          <td>Core</td>
          <td>SKY Activation will be available at the launch of the Spark Star.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - A2 - Activation And Sealing Mechanisms - Star Token Activation</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - Star Token Activation</td>
          <td>Section</td>
          <td>Star Token Activation can be done by any Star Token holder. It is available on Ethereum Mainnet and
            SkyLink Destination Chains. Star Token Activation provides SKY Rewards.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - Activation And Sealing Mechanisms - Star Token Activation - Availability</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - Star Token Activation - Availability</td>
          <td>Core</td>
          <td>Star Token Activation will be available at the launch of the Spark Star.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - A3 - Activation And Sealing Mechanisms - Sealing</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - Sealing</td>
          <td>Section</td>
          <td>Sealing is available both for SKY and MKR holders, with 1 MKR counting as 24,000 SKY. Sealing seals
            the principal tokens behind an Exit Fee. Sealing provides USDS Rewards or Star Token Rewards.
            Sealing users can also generate USDS using the USDS content of the Smart Burn Engine as collateral.
            Users' ability to generate USDS is based on the equivalent quantity they hold of sealed SKY. The
            Sealing mechanism is governed by the Stability Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - Activation And Sealing Mechanisms - Sealing - Availability</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - Sealing - Availability</td>
          <td>Core</td>
          <td>Sealing will be available shortly after the launch of USDS and SKY.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - Activation And Sealing Mechanisms - Sealing - Exit Fee</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - Sealing - Exit Fee</td>
          <td>Core</td>
          <td>The Sealing Exit Fee starts at 5%, and increases by 1% every six (6) months from launch, until it
            reaches its permanent long-term value at 15%.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.4.4
              - Activation And Sealing Mechanisms - Sealing - USDS generation Risk Parameters</dfn>
          </td>
          <td>Activation And Sealing Mechanisms - Sealing - USDS generation Risk Parameters</td>
          <td>Core</td>
          <td>The current LSE-MKR-A & Liquidation parameters are:• Cut: 0.99• Step: 60 seconds• Buf: 1.20•
           Cusp: 0.40• Tail: 6,000 seconds• Chip: 0.1%• Tip: 300 DAI• Calc: StairstepExponentialDecrease• 
            Ilk.chop: 8%• Tolerance: 0.5• Dust: 30,000 DAI• Ilk.hole: 3M DAI• Stability Fee: 20%•
            spotter[ilk].mat (Liquidation Ratio): 125%• DC-IAM line: 45M.• DC-IAM gap: 45M•
            DC-IAM ttl: 30 minutes• Add Seal Module to LineMom GSM Exception<br>Other Seal Module Params:• farms (Whitelisted set 
            of farms to choose from): LsMkrUsdsFarm• fee - (Exit Fee): 0%<br>StakingRewards:• rewardsDistribution: Set to the Splitter•
            rewardsDuration: 15,649 seconds</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.2
              - A1 - Brand Identity</dfn>
          </td>
          <td>Brand Identity</td>
          <td>Section</td>
          <td>This Section defines the management and use of Sky's brand identity.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.2
              - Brand Identity - Website And Domain</dfn>
          </td>
          <td>Brand Identity - Website And Domain</td>
          <td>Core</td>
          <td>The IP rights of the Sky website must be transferred to an entity similar to the Dai Foundation.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.2
              - Brand Identity - Dai And MKR</dfn>
          </td>
          <td>Brand Identity - Dai And MKR</td>
          <td>Core</td>
          <td>Dai and MKR must remain as valid tokens and products, with no actively maintained brand presence
            beyond community assets, educational material and their token names.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.2
              - Brand Identity - Recentering Maker Brand Polls</dfn>
          </td>
          <td>Brand Identity - Recentering Maker Brand Polls</td>
          <td>Core</td>
          <td>The Accessibility Facilitator must run a one-off special governance poll to determine the long-term 
            brand of the backend protocol, with 3 poll options. The poll must run from November 4 to November 7. 
            The winning option will modify the state of the Atlas as described below. The modifications and provisions 
            of this Atlas Document overrides and supersedes all other Documents in the Atlas, despite conflict in names, 
            tokenomics or anything else.<br> The 3 poll options are as follows:<br> Option 1:<br> Keep the Sky brand as 
            the backend protocol brand. If this option is chosen, no further changes happen and everything remains as today 
            with the brand. The effort to transition MKR to SKY continues, and the Sky brand remains the core brand that 
            both denotes the frontend Sky.money, and the backend Sky Ecosystem and Sky Protocol.<br> Option 2:<br> Recenter 
            the Maker brand. If this option is chosen, Sky is kept as the brand for the Sky.money frontend, USDS is also kept 
            as the brand for the new stablecoin - but the underlying backend protocol has its name changed to Maker, and MKR 
            becomes the core asset of the protocol. SkyLink becomes MakerLink, SkyChain becomes MakerChain, Sky Token Rewards 
            becomes Star Token Rewards, and Sky Savings Rate becomes USDS Savings Rate. The Maker brand is returned with its 
            old assets, as currently seen on makerdao.com, with minimal change. SKY tokens initially continue to function 
            exactly the same, and SKY Token Rewards would continue at the same rate. Once SPK launches, SKY Token Rewards would 
            be turned off, and the ability to migrate from MKR to SKY would be turned off. However, SKY to MKR migration would 
            remain permanently, with a technical modification to ensure that SKY is backed by a finite amount of MKR, rather 
            than the ability to emit new MKR. The ratio of SKY to MKR will permanently remain 1:24,000. The governance forum 
            would revert to forum.makerdao.com and other similar assets would also revert to Maker branding - with the 
            exception of the main @skyecosystem X handle. What happens to the X handle would be decided in a later process when 
            it is determined what’s going to happen with Sky.<br> Option 3:<br> Recenter the Maker brand, with a limited brand 
            refresh. If this option is chosen, Sky is kept as the brand for the Sky.money frontend, USDS is also kept as the brand 
            for the new stablecoin - but the underlying backend protocol has its name changed to Maker, and MKR becomes the core 
            asset of the protocol. SkyLink becomes MakerLink, SkyChain becomes MakerChain, Sky Token Rewards becomes Star Token 
            Rewards, and Sky Savings Rate becomes USDS Savings Rate. The Maker brand is slightly modified to better align with the 
            USDS brand identity, and to align with its role as the maker of the StarDAOs. The logo font can be slightly refreshed 
            and polished, and the colour scheme and general aesthetic should be inspired by the dark blue / navy “star theme” that 
            can be seen on Sky.money in sections that describe Stars and governance. SKY tokens initially continue to function 
            exactly the same, and SKY Token Rewards would continue at the same rate. Once SPK launches, SKY Token Rewards would be 
            turned off, and the ability to migrate from MKR to SKY would be turned off. However, SKY to MKR migration would remain 
            permanently, with a technical modification to ensure that SKY is backed by a finite amount of MKR, rather than the 
            ability to emit new MKR. The ratio of SKY to MKR will permanently remain 1:24,000. The governance forum would revert 
            to forum.makerdao.com and other similar assets would also revert to Maker branding - with the exception of the main 
            @skyecosystem X handle. What happens to the X handle would be decided in a later process when it is determined what’s 
            going to happen with Sky.<br> The Accessibility Facilitator may gather feedback and input to these 3 options during 
            the week of voting on this Atlas Edit, and use that to modify the exact language of the 3 poll options before they are 
            put out in their final state. Any edits made in this way to a poll option will become binding on the Atlas, if the poll 
            ends up winning.<br> The option that gets a plurality becomes the final outcome effective immediately from the moment 
            the poll ends.<br> If Option 1 has a plurality when counting individually, but Option 2 + Option 3 combined has a 
            plurality, then the outcome is Option 2.<br> The Accessibility Facilitator must prepare for all 3 options being chosen, 
            including preparing brand assets in advance. If recentering the Maker Brand is chosen, in either form, then this must 
            be implemented at events and other accessibility campaigns from the moment the poll ends, to the extent this is reasonably 
            possible.<br> Long term implications for SKY<br> If recentering the Maker brand is chosen (Option 2 or Option 3), then, 
            depending on what outcome is chosen for the Sky brand, the current SKY token may be renamed (e.g. to OLD_SKY), and a new 
            SKY token can be created and used for a different purpose, such as a StarDAO. In any case, holders of the current SKY 
            token would be guaranteed the ability to migrate back to MKR for an unlimited amount of time, and holders would be able 
            to hold their original SKY tokens forever if they desire.<br> USDS core Stablecoin and DAI ERC20 Wrapper<br> The core 
            stablecoin and product of the protocol is called USDS. It has multiple ERC20 wrappers, including the ERC20 USDS wrapper, 
            and the ERC20 DAI Wrapper and ERC20 sDAI Wrapper. The total supply of USDS is the total supply of internal stablecoins 
            in the protocol that backs all wrappers. The total supply of Dai can also be calculated by summing the supply of all 
            wrappers branded as Dai, including Dai, sDai and Chai.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - A1 - Integrator Program</dfn>
          </td>
          <td>Integrator Program</td>
          <td>Section</td>
          <td>This Section manages the Integrator Program, which includes the Accessibility Reward System and Integration Boost. 
              Integrators are actors that offer access to the Sky Protocol via their frontends or infrastructure.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Accessibility Reward System</dfn>
          </td>
          <td>Integrator Program - Accessibility Reward System</td>
          <td>Core</td>
          <td>The subdocuments of this document define the terms and conditions of the Reward System.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Accessibility Reward System - Accessibility Reward Codes</dfn>
          </td>
          <td>Integrator Program - Accessibility Reward System - Accessibility Reward Codes</td>
          <td>Core</td>
          <td>Eligible Integrators may receive an Accessibility Reward Code. With the Accessibility Reward Code, the Integrator can mark 
              all USDS balances that access the Protocol through their frontends or infrastructure, and earn the Accessibility Reward on 
              these balances.
              The distribution of Accessibility Reward Codes is managed by Ecosystem Actors on behalf of Sky.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Accessibility Reward System - Accessibility Reward Marketing Fee</dfn>
          </td>
          <td>Integrator Program - Accessibility Reward System - Accessibility Reward Marketing Fee</td>
          <td>Core</td>
          <td>The Accessibility Reward applies to USDS earning the Savings Rate and Token Rewards, and also to Unrewarded USDS (USDS not 
              earning the Savings Rate or Token Rewards), as long as the USDS balance is marked with the Accessibility Reward Code of an 
              Integrator. The Marketing Fees paid through the Accessibility Reward are calculated and paid out monthly.
              For Savings Rate or Token Reward balances, the Integrator earns a Marketing Fee of 0.4% of the balance per year.
              For Unrewarded USDS balances, the Integrator earns a Marketing Fee of [Savings Rate - 0.2%] of the balance per year.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Accessibility Reward System - Onchain and Offchain Accessibility Reward Code Marking</dfn>
          </td>
          <td>Integrator Program - Accessibility Reward System - Onchain and Offchain Accessibility Reward Code Marking</td>
          <td>Core</td>
          <td>The Accessibility Reward Codes can be marked to a balance both through onchain and offchain processes.
              • Onchain means they are directly included in the users’ transactions so they can be read on-chain, through a special 
                signature on the token transfer method.
              • Offchain means that various, continuously updated offchain monitoring mechanisms can be used to prove that an Integrator’s 
                Accessibility Reward Code is connected to particular accounts and balances, such as their user balances or customer funds.
            </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Accessibility Reward System - Accessibility Reward Code Management</dfn>
          </td>
          <td>Integrator Program - Accessibility Reward System - Accessibility Reward Code Management</td>
          <td>Core</td>
          <td>On an interim basis, two Ecosystem Actors have the ability to generate Accessibility Reward Codes for Integrators. Their 
              Accessibility Reward Codes will work in two different ways, as specified below.
              Phoenix Labs:
                • Accessibility Reward Codes from Phoenix Labs provide the 0.4% or [Savings Rate - 0.2%] Marketing Fee as normal.
                • Additionally, the Spark Star also earns a 0.1% Management Fee on balances marked by Phoenix Labs’ Accessibility Reward Codes.
                • Phoenix Labs Forum account: PhoenixLabs
              Viridian Advisors:
                • Accessibility Reward Codes from Viridian Advisors provide the 0.4% or [Savings Rate - 0.2%] Marketing Fee as normal.
                • Viridian Advisory Forum account: Viridian</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Accessibility Reward System - Interim Accessibility Reward Code Assignment Process</dfn>
          </td>
          <td>Integrator Program - Accessibility Reward System - Interim Accessibility Reward Code Assignment Process</td>
          <td>Core</td>
          <td>On an interim basis, Phoenix Labs and Viridian Advisors must each maintain a dedicated thread in the Governance Forum (under 
              the Maker Core or Sky Core category). In these threads, they must maintain a list of the Integrators who have received 
              Accessibility Reward Codes, including the specific code itself, and the Integrators’ Ethereum addresses to which the 
              Accessibility Rewards are to be paid.
              Phoenix Labs and Viridian Advisors can maintain a separate Forum thread, or use other means, to enable prospective 
              Integrators to sign up for their Accessibility Reward Codes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Accessibility Reward System - Accessibility Reward Payment</dfn>
          </td>
          <td>Integrator Program - Accessibility Reward System - Accessibility Reward Payment</td>
          <td>Core</td>
          <td>Where feasible, Phoenix Labs and Viridian Advisors must calculate on a monthly basis the onchain and offchain Accessibility 
            Rewards earned for the Codes they are responsible for. If there are calculations that cannot reasonably be done, they can be 
            delayed and later calculated.
            Every month, the Accessibility Facilitators must ensure that the calculated Accessibility Rewards are paid out to the 
            corresponding addresses.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Integration Boost</dfn>
          </td>
          <td>Integrator Program - Integration Boost</td>
          <td>Core</td>
          <td>The Accessibility Facilitator can work with Ecosystem Actors to set up mechanisms that provide
            additional rewards to DeFi lending protocols that integrate USDS. The rewards must be calculated
            offchain to be equivalent to the USDS Savings Rate on their unutilized USDS, and must be delivered
            through the native liquidity mining mechanisms of the lending protocols, or similar systems.<br> The
            Integration Boost can also be delivered to other forms of DeFi protocols than Lending Protocols, as
            long as there is a reasonable equivalence in how the integration boost helps grow USDS adoption.<br>
            The Integration Boost is delivered through a multisig that the Accessibility Facilitator can request
            to have topped up to 3 million USDS through Executive Votes whenever necessary to ensure the
            Integration Boost is delivered successfully.<br> Since the Integration Boost is delivered with a lag,
            for strategic integrations, the Accessibility Facilitator may choose to provide an extra high
            Integration Boost, to encourage rapid adoption and prevent the Integration Boost value from getting
            low during the early growth phase.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Compliance With Local Laws And Regulations As A Condition Precedent To Integrators Receiving 
              Accessibility Rewards</dfn>
          </td>
          <td>Integrator Program - Compliance With Local Laws And Regulations As A Condition Precedent To Integrators Receiving 
              Accessibility Rewards</td>
          <td>Core</td>
          <td>This document and its subdocuments define the jurisdictional compliance rules applicable to Integrators that operate 
              user-facing frontends that integrate with, and thus offer access to, the Sky Protocol and receive Accessibility Rewards.
              Integrators are solely responsible for complying with all relevant legal and regulatory requirements related to their 
              participation in the Accessibility Reward Program. Integrators represent and warrant that their participation and activities 
              under the Integrator Program are and will remain in full compliance with all applicable laws and regulations.
              In connection with integrating with, and thereby providing access to, the Sky Protocol, Integrators must operate their 
              frontends and infrastructure in compliance with all relevant legal and regulatory requirements in the jurisdictions 
              applicable to their services. This requires compliance with all relevant legal and regulatory requirements in relation to 
              frontend operations, marketing, and promotions in the jurisdictions where the Integrator provides access to the Sky Protocol 
              through the integration.
              An Integrator’s right to participate in the Integrator Program is contingent upon its ongoing compliance with all applicable 
              laws and regulations.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.3
              - Integrator Program - Compliance With Local Laws And Regulations As A Condition Precedent To Integrators Receiving 
              Accessibility Rewards - Consequence For Integrator Non-Compliance</dfn>
          </td>
          <td>Integrator Program - Compliance With Local Laws And Regulations As A Condition Precedent To Integrators Receiving 
              Accessibility Rewards - Consequence For Integrator Non-Compliance</td>
          <td>Core</td>
          <td>Sky Ecosystem Governance, in its absolute and unilateral discretion, retains the right to withhold, revoke, or demand 
              immediate repayment of any and all Accessibility Rewards from any Integrator that is determined, suspected, or alleged to be 
              in violation of the Atlas or any legal, regulatory, or other obligations associated with its integration with, and provision 
              of access to, the Sky Protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.4
              - A1 - Accessibility Communication Channels</dfn>
          </td>
          <td>Accessibility Communication Channels</td>
          <td>Section</td>
          <td>This Section defines rules for managing accessible communication channels to enhance public access
            to, and interaction with, the Sky Ecosystem. These communication channels are distinct from Sky's
            governance-focused communication channels.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.4
              - Accessibility Communication Channels - External Platforms</dfn>
          </td>
          <td>Accessibility Communication Channels - External Platforms</td>
          <td>Core</td>
          <td>Sky must support the accessibility of the Sky Ecosystem by paying Ecosystem Actors to maintain
            accounts and channels on external platforms, such as Twitter and Telegram. These accounts may
            develop and share Accessibility content that follows the brand guidelines.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.4
              - Accessibility Communication Channels - Budget</dfn>
          </td>
          <td>Accessibility Communication Channels - Budget</td>
          <td>Core</td>
          <td>
            The Accessibility communication channel budget is available to maintain the tasks described in <dfn>A.5.4
              - A1 - Accessibility Communication Channels</dfn> and its subdocuments.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.4
              - Accessibility Communication Channels - Budget - Amount</dfn>
          </td>
          <td>Accessibility Communication Channels - Budget - Amount</td>
          <td>Core</td>
          <td>The Accessibility communication channel budget is:• 0 USDS per month, implemented with DssVest. It
            is a monthly recurring budget.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.4
              - Accessibility Communication Channels - Budget - Modification</dfn>
          </td>
          <td>Accessibility Communication Channels - Budget - Modification</td>
          <td>Core</td>
          <td>The Accessibility Facilitator can propose to modify the budget by posting a message in the Sky Core
            Forum specifying the proposed new value. This triggers a Governance Poll in the Weekly Governance
            Cycle that edits the value if it is accepted.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.5
              - A1 - Accessibility Campaigns</dfn>
          </td>
          <td>Accessibility Campaigns</td>
          <td>Section</td>
          <td>This Section defines infrastructure and processes pertaining to accessibility campaigns.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.5
              - Accessibility Campaigns - Accessibility Facilitators Responsibility</dfn>
          </td>
          <td>Accessibility Campaigns - Accessibility Facilitators Responsibility</td>
          <td>Core</td>
          <td>The Accessibility Facilitators must research and develop a framework for long-term Accessibility
            Campaigns.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.5
              - Accessibility Campaigns - Early Bird Reward</dfn>
          </td>
          <td>Accessibility Campaigns - Early Bird Reward</td>
          <td>Core</td>
          <td>As a part of the brand reveal phase, the Accessibility Facilitators set up an Early Bird Reward System. The Early Bird 
              Reward System rewarded all users signing up before the launch date of USDS and SKY with double the SKY rewards for the first 
              month following launch.
              The accumulated SKY rewards were paid out as an airdrop as specified in <dfn>A.5.5 - Accessibility Campaigns - Early Bird 
              Reward - Token Distribution</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.5
              - Accessibility Campaigns - Early Bird Reward - Token Distribution</dfn>
          </td>
          <td>Accessibility Campaigns - Early Bird Reward - Token Distribution</td>
          <td>Core</td>
          <td>To distribute the Early Bird Reward the following actions have been or will be taken:
                • 27,222,832.8 newly minted SKY, equal to 120% of the total estimated Early Bird Reward distributions, was transferred to 
                the multisig wallet operated by the Accessibility Facilitators at the address 0x14D98650d46BF7679BBD05D4f615A1547C87Bf68 
                on the Ethereum Mainnet.
                • The remaining SKY in the 0x14D98650d46BF7679BBD05D4f615A1547C87Bf68 multisig that is not used to fund the 
                MerkleDistributor will be burned by calling the burn function on the multisig. The estimated amount of SKY needed to fund 
                the MerkleDistributor is 22,685,694.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - A1 - Location Resilience</dfn>
          </td>
          <td>Location Resilience</td>
          <td>Section</td>
          <td>This Section defines requirements for Ecosystem Actors and Stars to implement limited filtering and
            full blocking of IPs.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - Location Resilience - Reduce Exposure To Locations</dfn>
          </td>
          <td>Location Resilience - Reduce Exposure To Locations</td>
          <td>Core</td>
          <td>Ecosystem Actors in the Sky Ecosystem must actively explore and implement reasonably available
            options to reduce their infrastructure's exposure to locations identified in the following
            subdocuments as subject to either IP filtering ("limited filtering") or IP blocking ("full block").
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - Location Resilience - Consequence For Non-Compliance</dfn>
          </td>
          <td>Location Resilience - Consequence For Non-Compliance</td>
          <td>Core</td>
          <td>
            All frontends operated by Ecosystem Actors on behalf of Stars are required to follow the location-filtering
            rules defined in <dfn>A.5.8
              - A1 - Location Resilience</dfn> and its subdocuments. The failure to adhere to these rules will
            result in penalties.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - Location Resilience - Limited Filtering Of Features & IPs</dfn>
          </td>
          <td>Location Resilience - Limited Filtering Of Features & IPs</td>
          <td>Core</td>
          <td>Limited filtering requires frontends operated by Ecosystem Actors to avoid displaying or describing
            features to users with IPs flagged for limited filtering.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - Location Resilience - Limited Filtering Of Features & IPs - Restricted Features</dfn>
          </td>
          <td>Location Resilience - Limited Filtering Of Features & IPs - Restricted Features</td>
          <td>Core</td>
          <td>The features that must be restricted from being displayed or described to users flagged for Limited
            Filtering are:• Activation Rewards• Sky Savings Rate• Seal Rewards• Any other feature related to
            yield or rewards.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - Location Resilience - Limited Filtering Of Features & IPs - Flagged IPs</dfn>
          </td>
          <td>Location Resilience - Limited Filtering Of Features & IPs - Flagged IPs</td>
          <td>Core</td>
          <td>Frontends must develop internal processes to determine their strategy for limited filtering, to ensure optimal balance of resilience and accessibility.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - Location Resilience - Full Block</dfn>
          </td>
          <td>Location Resilience - Full Block</td>
          <td>Core</td>
          <td>Full block requires frontends operated by Ecosystem Actors to deny service of any kind to users with
            IPs flagged for Full Block.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.8
              - Location Resilience - Full Block - Flagged IPs</dfn>
          </td>
          <td>Location Resilience - Full Block - Flagged IPs</td>
          <td>Core</td>
          <td>User IPs flagged for Full Block are:• Cuba• Iran• Syria• North Korea• Crimea and Sevastopol• Donetsk
            People's Republic• Luhansk People's Republic of Ukraine• Kherson Oblast• Zaporizhzhia Oblast</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - A1 - Launch Project</dfn>
          </td>
          <td>Launch Project</td>
          <td>Section</td>
          <td>This Section defines high-level objectives and requirements for the Launch Project. The Launch
            Project budget and the provisions for payout are defined in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Beta Launch</dfn>
          </td>
          <td>Launch Project - Beta Launch</td>
          <td>Core</td>
          <td>The Beta Launch is a crucial milestone in the Launch Project, marking the time at which three key
            elements will be unveiled: the new brand, USDS and SKY.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives</dfn>
          </td>
          <td>Launch Project - Objectives</td>
          <td>Core</td>
          <td>The subdocuments herein specify the Launch Project's objectives.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives - Coordinate Development</dfn>
          </td>
          <td>Launch Project - Objectives - Coordinate Development</td>
          <td>Core</td>
          <td>The Launch Project must coordinate the development of the new brand with website, marketing and
            communications strategy. The Launch Project must also effectively integrate the ecosystem's smart
            contract development into the launch.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives - Develop Technology</dfn>
          </td>
          <td>Launch Project - Objectives - Develop Technology</td>
          <td>Core</td>
          <td>The Launch Project must develop key AI and governance technology, and secure partnerships with
            high-value companies in relevant fields to rapidly anchor Sky's ability to leverage AI and
            governance technology.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives - Attract High-Value Actors</dfn>
          </td>
          <td>Launch Project - Objectives - Attract High-Value Actors</td>
          <td>Core</td>
          <td>The Launch Project must work to attract high-value actors who are less traditionally prone to
            interact with the world of crypto.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives - Regulatory Outreach</dfn>
          </td>
          <td>Launch Project - Objectives - Regulatory Outreach</td>
          <td>Core</td>
          <td>The Launch Project may also deal with various initiatives related to regulatory outreach or legal
            resilience efforts in the Sky Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives - Fund Infrastructure</dfn>
          </td>
          <td>Launch Project - Objectives - Fund Infrastructure</td>
          <td>Core</td>
          <td>The Launch Project must fund security and other critical infrastructure needs for the Ecosystem as
            required during the bootstrapping phase.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives - Purpose System</dfn>
          </td>
          <td>Launch Project - Objectives - Purpose System</td>
          <td>Core</td>
          <td>The Launch Project must explore options to help bootstrap the Purpose System and may request
            governance votes to allocate SKY from the Pause Proxy as grants or donations to relevant causes.
            Such payments must be approved through a SKY vote. Any approved payments will be funded separately;
            that is, they will not count against the Launch Project's budget.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Objectives - Launch Season Work</dfn>
          </td>
          <td>Launch Project - Objectives - Launch Season Work</td>
          <td>Core</td>
          <td>The Launch Project must prepare for its dissolution and replacement, following Beta Launch. Once the
            new brand has been revealed, significant transparency improvements for the Launch Project must also
            be implemented.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Long Term Focus</dfn>
          </td>
          <td>Launch Project - Long Term Focus</td>
          <td>Core</td>
          <td>The Launch Project's long-term focus must be on coordinating effective marketing and launch
            processes around the next launch phases; using communications and marketing to prepare the community
            for the potential of increased governance participation; and driving growth to the Ecosystem, the
            Stars, and Sky Governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Transparency Exception</dfn>
          </td>
          <td>Launch Project - Transparency Exception</td>
          <td>Core</td>
          <td>The Launch Project is a one-time exception to the requirements for maximum end-to-end transparency
            for all governance processes, Facilitator decisions, and budget spending defined by the Atlas. Due
            to the unique opportunity presented by the new brand and its well-coordinated release alongside the
            Beta Launch, the Launch Project must optimize for creating the best possible first impression, given
            its potential to have an outsized impact on the long-term success of the entire Ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Transparency Exception - After Beta Launch</dfn>
          </td>
          <td>Launch Project - Transparency Exception - After Beta Launch</td>
          <td>Core</td>
          <td>The Launch Project must follow a higher standard of transparency after the Beta Launch, when the
            first impression of the new brand and the overall launch process has already been set.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Include Non-Crypto Key Partners</dfn>
          </td>
          <td>Launch Project - Include Non-Crypto Key Partners</td>
          <td>Core</td>
          <td>The Launch Project must engage key non-crypto partners and, during the earliest phases, shield them
            from the unfamiliar challenges unique to decentralized governance and politics. This approach will
            enable them to participate successfully in the Beta Launch and gain a clear understanding of the
            system without unnecessary distractions.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Budget</dfn>
          </td>
          <td>Launch Project - Budget</td>
          <td>Core</td>
          <td>
            The budget available for the Launch Project is specified in <dfn>A.5.9
              - Launch Project - Budget - Amount</dfn>. This is a one-time budget with no renewal. Payouts from
            the budget can be triggered by the Accessibility Facilitator through a message in the Sky Core
            Forum, specifying the amount for lump-sum payments or the DssVest parameters for DssVest payments,
            along with the recipient address. The payment is bundled directly into the next Executive Vote
            without requiring a Governance Poll. Each time a payout is made, the remaining budget in <dfn>A.5.9
              - Launch Project - Budget - Current Remaining Amount</dfn> must be reduced to reflect the
            expenditure. Spending cannot exceed the total one-time budget.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Budget - Amount</dfn>
          </td>
          <td>Launch Project - Budget - Amount</td>
          <td>Core</td>
          <td>Initial one-time budget for the Launch Project:• 80,000,000 USDS• 360,000,000 SKY - The SKY can at
            most be spent at the rate of 48,000,000 SKY per month.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Budget Remaining Amount</dfn>
          </td>
          <td>Launch Project - Budget Remaining Amount</td>
          <td>Active Data Controller</td>
          <td>
            The remaining budget for the Launch Project is defined as Active Data in <dfn>A.5.9
              - Launch Project - Budget - Current Remaining Amount</dfn>. The Active Data is updated as
            follows:• The Responsible Party is the Accessibility Facilitators.• The Update Process must follow
            the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Sky on Solana Short Term Crosschain Strategy</dfn>
          </td>
          <td>Launch Project - Sky on Solana Short Term Crosschain Strategy</td>
          <td>Core</td>
          <td>The Accessibility Facilitators must work with Advisors and Ecosystem Actors to research and
            implement a decentralized crosschain solution using Wormhole that enables the bridging of USDS to
            Solana.<br> Once the crosschain solution is implemented, the Accessibility Facilitators must use the
            USDS integration boost system to encourage integration and adoption of USDS on Solana.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>
              A.5.9
            - Launch Project - Sky Ecosystem Liquidity Bootstrapping</dfn>
          </td>
          <td>Launch Project - Sky Ecosystem Liquidity Bootstrapping</td>
          <td>Core</td>
          <td>The Accessibility Facilitators must work with advisors and Ecosystem Actors to implement a liquidity bootstrapping program using up to 20 million USDS and 320 million SKY. These assets can be used for liquidity programs, or for liquidity infrastructure integration costs. Anything leftover from usage in liquidity programs must be returned to Sky control at the end of the bootstrapping program.<br>The funds can be paid into multisig accounts for future use via executive votes at will by the Accessibility Facilitators.
          </td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="type-specifications">
    <h1>Type Specifications</h1>
    <table>
      <tr>
        <th>Doc No (or Temp Name)</th>
        <th>Name</th>
        <th>Type</th>
        <th>Type Overview</th>
        <th>Components</th>
        <th>Type Category</th>
        <th>Doc Identifier Rules</th>
        <th>Additional Logic</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Type Specification
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Type Specification Type
          </td>
          <td>Type Specification</td>
          <td>The Type Specification Type is used for Type Specification Documents that specify the
            characteristics of each of the different Document Types. It ensures that all Type Specifications
            contain all necessary information to make it easy to reason about whether a document follows the
            requirements for its type.</td>
          <td>"Type Name": The Type Name Component must contain the name of the Document Type"Type Overview": The
            Type Overview Component must contain high level information as human-readable text about the type,
            such as what it is used for and why it is necessary."Type Components": If the Type has Components,
            they must be specified in this Component as a nested object."Type Category": This Component must
            specify whether the Type is an Immutable Document, a Primary Document, a Supporting Document, or a
            Translation Document."Document Identifier Rules": This Component must specify as human-readable text
            rules related to the Document Identifier for Atlas Documents of this Type, and their locations in
            the Document Trees."Additional Logic": This Component can contain additional logic that applies to
            all Documents of the Type.</td>
          <td>Primary Document</td>
          <td>Type Specification Documents must follow the Document Identifier rules for Primary Documents.</td>
          <td>The rules specified in Type Specification Documents must be followed for all Atlas Documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Atlas Preamble
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Atlas Preamble Type</td>
          <td>Type Specification</td>
          <td>The Atlas Preamble Type is used for the Atlas Preamble Document Tree which starts at the 0th
            position of the first layer of the Atlas. The Atlas Preamble details the Spirit of the Atlas in
            human-readable language, and specifies important definitions for understanding the Spirit of the
            Atlas, that must be used as context when interpreting all other parts of the Atlas.</td>
          <td>"Content": The content Component is very flexible and defines in broad human-readable language the
            Spirit of the Atlas.</td>
          <td>Immutable Document</td>
          <td>Atlas Preamble Documents are located at A.0 or as nested Documents one layer below A.0.</td>
          <td>Atlas Preamble Documents are immutable, foundational parts of the Atlas and their content must be
            considered when interpreting all other Atlas Documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Scope Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Scope Type</td>
          <td>Type Specification</td>
          <td>The Scope Type is used for the 5 nonzero Immutable Documents of the first layer of the Atlas that
            directly describe focus areas, principles, rules and processes of Sky Governance. Scope Documents
            define the broad boundaries, requirements and objectives of each of the 5 Atlas Scopes, so that they
            together can fully cover all activities that are needed for Sky to function while maintaining its
            resilient equilibrium.</td>
          <td>"Content": The content Component is very flexible and defines in broad human-readable language core
            principles, rules and processes.</td>
          <td>Immutable Document</td>
          <td>Scope Documents have the Document Identifiers from A.1 to A.5.</td>
          <td>Scope Documents are immutable, foundational parts of the Atlas and their content must be considered
            when interpreting all principles, rules and processes of Atlas Documents nested below them</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Article Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Article Type</td>
          <td>Type Specification</td>
          <td>The Article Type is used for the second layer documents nested below the 5 Scope documents of the
            Atlas. They directly describe individual focus areas that together fully cover everything needed for
            the purpose of the Scope to be fulfilled.</td>
          <td>"Content": The content Component is very flexible and defines in broad human-readable language core
            principles, rules and processes of the specific focus area of the Scope that the Article covers, and
            provides the starting point, requirements, boundaries, and in some cases immutable specifications,
            needed to develop the Adaptive Documents that are nested at lower layers of the Document Trees to
            maximally fulfill their practical purpose without violating the Spirit of the Atlas.</td>
          <td>Immutable Document</td>
          <td>Article Documents have Document Identifiers one layer below the Scope Documents.</td>
          <td>Article Documents are immutable, foundational parts of the Atlas and their content must be
            considered when interpreting all principles, rules and processes of Atlas Documents nested below
            them.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Section Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Section Type</td>
          <td>Type Specification</td>
          <td>The Section Type is used for the third layer of Immutable Documents nested under the Articles of
            each Scope in the Atlas. Section Documents provide additional structure and specification to the
            principles, rules and processes within the focus area of the Article. The Section Type acts as a
            foundation and boundary against misalignment of the Adaptive Documents that are nested below it.
            Generally, Section Documents should be "atomized", or restricted to specifying only a single
            discrete unit of logic.</td>
          <td>"Content": The content Component is very flexible and provides in-depth human-readable language to
            elaborate on the specific principles, rules, and processes that operationalize the Section's parent
            Article.</td>
          <td>Immutable Document</td>
          <td>Section Documents have Document Identifiers one layer below the Article Documents.</td>
          <td>Section Documents are immutable parts of the Atlas and their content must be considered when
            interpreting all principles, rules and processes of Adaptive Documents nested below them.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Core Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Core Type</td>
          <td>Type Specification</td>
          <td>The Core Type is the basic building block of the Primary Documents. Core Documents flexibly specify
            the core principles, rules and processes required to fulfil the specifications made by the Immutable
            Documents with a focus on clarity, practicality and applicability.</td>
          <td>"Content": The content Component is very flexible and defines in human-readable language core
            principles, rules or processes, or subcomponents thereof.</td>
          <td>Primary Document</td>
          <td>Core Documents follow the Document Identifier Rules of Primary Documents. Core Documents have
            Document Identifiers that are 4 layers or deeper in the Document Tree, and cannot contain 0's
            [zeros]. Within these constraints, Core Documents can have whatever Document Identifier that is
            useful for their purpose.</td>
          <td></td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Supporting Root
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Supporting Root Type
          </td>
          <td>Type Specification</td>
          <td>The Supporting Root Type is used to mark the beginning of the Supporting Document subtree of an
            Immutable or Primary Document. All Immutable and Primary Documents must have a Supporting Root.</td>
          <td></td>
          <td>Supporting Document</td>
          <td>Supporting Root Documents must always be located at the .0 position of its Target Document.</td>
          <td>The Supporting Root Documents have no function other than structurally acting as a directory for
            nested Supporting Documents in a standardized format. All Immutable Documents and Primary Documents
            must have a Supporting Root Document attached.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Original Context
              Data Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Original Context Data
            Type</td>
          <td>Type Specification</td>
          <td>Original Context Data Documents explain the intention and reasoning behind the content of its Target
            Document, to make interpretation and extrapolation of its contents easier, and provide additional
            information to other forms of analysis. Original Context Data helps anchor the fundamental purpose
            and meaning of the target document to its original context, and should help mitigate cultural drift
            over time. Original Context Data can contain unstructured data used for genesis data integration of
            early Atlas Documents. Original Context Data Documents can form nested subtrees to organize their
            data if relevant.</td>
          <td>"Content": The Content Component should contain all relevant information to understand the intention
            and reasoning behind the wording and elements of the main Document.</td>
          <td>Supporting Document</td>
          <td>Original Context Data Documents must always be located at the .0.1 position of their Target
            Document, or nested in a subtree of Original Context Data Documents below the .0.1 position.</td>
          <td>The Original Context Data Document should be in a finished form alongside the creation or
            modification of its Target Document, as it aims to capture the original context and intention of the
            contents of the Target Document. However, it can and should be modified if new evidence and data
            comes to light that helps to better describe the original context and intention of the Target
            Document, or if new perspectives or new external events makes it possible and useful to modify the
            Original Context Data Document in a way that doesn't contradict its earlier language.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Element Annotation
              Directory Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Element Annotation
            Directory Type</td>
          <td>Type Specification</td>
          <td>The Element Annotation Directory Type is a directory used to list all of the Element Annotation
            Documents pertaining to a Target Document.</td>
          <td>"Directory index": This Component should contain a list of the Element Annotation Documents
            contained within, with keys being the document identifiers and values being their document names.
          </td>
          <td>Supporting Document</td>
          <td>Element Annotation Directory Documents must always be located at the .0.3 position of their Target
            Document.</td>
          <td></td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Element Annotation
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Element Annotation Type
          </td>
          <td>Type Specification</td>
          <td>Element Annotation Documents provide further specification of the semantic meaning of vague or
            ambiguous terms in the Target Document. Element Annotation Documents can also briefly define
            technical jargon that is unique to the Target Document. Element Annotation Documents can be thought
            of as serving a function similar to that of a footnote: they can provide useful context or
            commentary. Element Annotations should be as concise as possible.</td>
          <td>"Element": The Element Component should contain the unique word or phrase from the Target Document
            that is being annotated."Annotation": The Annotation Component should concisely disambiguate and
            bound the semantic meaning of problematic terms in the Target Document. Such terms can be vague,
            ambiguous or technical jargon specific to the Target Document.</td>
          <td>Supporting Document</td>
          <td>Element Annotation Documents must always be located as subdocuments to the Element Annotation
            Directory Document of their Target Document. Element Annotation documents are located at the .0.3.X
            position, with X being the incremented number.</td>
          <td>Element Annotation Documents should be updated as necessary to reflect changes in the understanding
            or interpretation of the Element and/or any related Atlas document, while maintaining consistency
            with the Target Document. The Element Annotation should not contradict its Target Document or other
            context data of the Target Document.The "Name" property of each Element Annotation Document instance
            must follow a standardized template: the annotated Element is listed first, followed by a hyphen,
            and the phrase "Element Annotation".</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action
              Tenet Directory Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action Tenet
            Directory Type</td>
          <td>Type Specification</td>
          <td>The Facilitator Action Tenet Directory Type is a directory Type used to list all of the Facilitator
            Action Tenet Documents that pertain to a Target Document. Facilitator Action Tenet Documents specify
            adjudication principles and guidelines that are directly derived from the Target Document. When a
            controversy concerns the Target Document, the Facilitators must consult and apply the pertinent
            Action Tenet(s) in their decisionmaking.</td>
          <td>"Directory index": This Component should contain a list of the Facilitator Action Tenets contained
            within, with keys being the document identifiers and values being their document names.</td>
          <td>Supporting Document</td>
          <td>Facilitator Action Tenet Directory Documents must always be located at the .0.4 position of their
            Target Document.</td>
          <td></td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action
              Tenet Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action Tenet
            Type</td>
          <td>Type Specification</td>
          <td>The Facilitator Action Tenet Type is used to provide concrete adjudication principles derived from
            its Target Document. It distills the governance logic of the Target Document into a concise
            principle to guide Facilitators in resolving disputes related to the Target Document. The practical
            application of the Tenet is demonstrated by its "Scenario" Subdocuments.</td>
          <td>"Content": The Tenet Component specifies the adjudication logic, principle or doctrine that is
            directly derived from the Target Document. This Component can include policy statements underpinning
            the adjudication principle. Such policy statements can highlight the values that are served by, or
            the benefits gained from, adhering to the Tenet. When facing edge cases, these policy statements can
            help Facilitators to extrapolate from the Tenet's logic to achieve the most suitable outcome.</td>
          <td>Supporting Document</td>
          <td>Facilitator Action Tenet Documents must always be located as subdocuments of the Facilitator Action
            Tenet Directory Document (which latter is located at position .0.4) of their Target Document. Action
            Tenet documents are located at the .0.4.X position, with X being the incremented number.</td>
          <td>Facilitator Action Tenet Documents are likely to be necessary supplements for interpreting the
            Immutable Document types, as these tend to have generalized, broad language. The Core Document type
            has the function of operationalizing the Immutable Documents, and thus its language will tend to be
            far more specific and concrete. For that reason, Action Tenet Supporting Documents may not be
            necessary for a particular Core Document. This is not a hard-coded rule, however. The determination
            of whether an Action Tenet Document is needed for any given Atlas document should always be
            tailor-made.Action Tenet Documents should be created and updated as necessary to reflect changes in
            governance practices, provide clarity on decision-making processes, and enhance understanding of
            governance principles and rules. The examples should not contradict their Target Document or other
            Supporting Documents of the Target Document.If the Action Tenet can be anchored to a specific term
            from the Target Document, that term is listed first; followed by a hyphen; and then, an abstract of
            the Action Tenet logic, e.g.: "Organizational Drift - ACs' Mandate When Instigating Action Can Be
            Traced Back to a Discrete Entity". If the Action Tenet cannot be anchored to a specific term from
            the Target Document, the "Name" property should simply summarize the Action Tenet logic, e.g.:
            "Evaluating AC breach of role-specific requirement vs. general requirement".</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action
              Precedent Directory Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action
            Precedent Directory Type</td>
          <td>Type Specification</td>
          <td>Facilitator Action Precedent Directory Documents list all of the Facilitator Action Precedent
            Documents that pertain to a Target Document. Facilitator Action Precedent Documents record data
            about Facilitator Actions, including ongoing actions, that are primarily based on interpretation of
            content of the Target Document.</td>
          <td>"Directory index": This Component should contain a list of the Facilitator Action Precedents
            contained within, with keys being the document identifiers and values being their document names.
          </td>
          <td>Supporting Document</td>
          <td>Facilitator Action Precedent Directory Documents must always be located at the .0.5 position below
            their Target Document.</td>
          <td>A Facilitator Action Precedent Directory Document must be updated whenever a new Facilitator Action
            Precedent Document is added that meaningfully changes what should be contained in the Directory
            overview Component.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action
              Precedent Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action
            Precedent Type</td>
          <td>Type Specification</td>
          <td>The Facilitator Action Precedent Type is used to record all the relevant data related to a
            Facilitator Action, to serve as precedent for future Facilitator Actions and decision-making
            processes. It is also used for ongoing Facilitator Actions, and the creation of a Facilitator Action
            Precedent is the formal method that Facilitators use to record Atlas Interpretations, take action
            against misalignment, or explicitly approve ecosystem activity.</td>
          <td>"Input": The Input Component must contain a description of the situation or context in which the
            Facilitator Action takes place. This could include any relevant information, such as the state of
            governance or the specific issue at hand."Output": The Output Component must contain a description
            of the Facilitator's action and the outcome or decision that resulted from it. This should provide a
            clear illustration of how the Facilitator responded to the situation."Label": The Label Component
            indicates whether the Facilitator's action is considered aligned or misaligned according to the
            principles and rules of governance. This judgment is intended to guide future actions and decisions.
            If the label is misaligned, it must also specify the penalty that is applied to the Facilitator for
            misalignment. The Label must always be marked as Aligned when it is created by the Facilitator, and
            further action by Sky Governance can directly modify this later according to the specifications
            of the Atlas Documents relevant to appealing Facilitator Actions.</td>
          <td>Supporting Document</td>
          <td>Facilitator Action Precedent Documents must always be located as subdocuments of the Facilitator
            Action Precedent Directory Document of their Target Document.</td>
          <td>Facilitator Action Precedent Documents should be created and updated as necessary to reflect changes
            in governance practices, provide clarity on decision-making processes, and enhance understanding of
            governance principles and rules. The Precedents should not contradict their Target Document or other
            Supporting Documents of the Target Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Active Data
              Controller Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Active Data Controller
            Type</td>
          <td>Type Specification</td>
          <td>Active Data Controller Documents are Primary Documents that can have Active Data Documents attached
            to them as Supporting Documents; these latter contain variable state that can be directly modified
            by Facilitators and other processes external to the standard Weekly Governance Cycle or Monthly
            Governance Cycle (i.e., the Atlas Edit Proposal process). Active Data can be lists of authorized
            actors, parameters, or externally collected data being prepared for data integration with the Atlas.
          </td>
          <td>"Content": The Content Component of Active Data Controller Documents is used to define: 1) the
            entities who are authorized to modify the child Active Data Documents and 2) the authorized process
            by which said Active Data Documents are modified. If applicable, the Custom Components format and
            requirements of the Active Data Documents must be defined as well.</td>
          <td>Primary Document</td>
          <td>Active Data Controller Documents follow the Document Identifier Rules of Primary Documents. Active
            Data Controller Documents have Document Identifiers that are 4 layers or deeper in the Document
            Tree, and cannot contain 0's [zeros]. Within these constraints, Active Data Controller Documents can
            have whatever Document Identifier that is useful for their purpose.</td>
          <td>Active Data Controller Documents must have an Active Data Directory Document located below it at the
            .0.6 position. The Active Data Controller Document can reference its Active Data subdocuments for
            its own logic. This allows Active Data Documents to be self-improving and adaptive at high speeds.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Active Data
              Directory Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Active Data Directory
            Type</td>
          <td>Type Specification</td>
          <td>The Active Data Directory Type is a directory Type used to list all of the Active Data Documents
            that pertain to an Active Data Controller Document. Active Data Documents contain variable state
            that can be directly modified by Facilitators and other processes external to the standard Atlas
            Edit Weekly Cycle or Atlas Edit Monthly Cycle (i.e., the Atlas Edit Proposal process).</td>
          <td>"Directory overview": This Component should contain a brief explanation of overall patterns and
            themes of the Active Data Documents contained within.</td>
          <td>Supporting Document</td>
          <td>Active Data Directory Documents must always be located at the .0.6 position of their Active Data
            Controller Document or Budget Controller Document.</td>
          <td>An Active Data Directory Document should be updated whenever a new Active Data Document is added
            that meaningfully changes what should be contained in the Directory overview Component.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Active Data
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Active Data Type</td>
          <td>Type Specification</td>
          <td>The Active Data Type is used for Supporting Documents that contain variable state that can be
            directly modified by Facilitators and other processes external to the standard Weekly Governance
            Cycle or the Monthly Governance Cycle (i.e., the Atlas Edit Proposal process). Active Data can be
            lists of authorized actors, parameters, or externally collected data being prepared for data
            integration with the Atlas.</td>
          <td>"Content": This component is very flexible and represents in human-readable language the mutable
            data that is modifiable pursuant to the logic of the parent Active Data Controller."Custom
            Components": If present, the Custom Components of Active Data Documents are defined by their parent
            Active Data Controller Document. They can contain the variable state that is directly modifiable by
            processes external to the standard Weekly Governance Cycle or the Monthly Governance Cycle.</td>
          <td>Supporting Document</td>
          <td>Active Data Documents must always be located as subdocuments of the Active Data Directory Document
            of their Active Data Controller Document.</td>
          <td>Active Data Documents can contain arbitrary types of data, including large amounts of data or code.
            The function and purpose of the contained data depends on the logic specified in the Active Data
            Controller Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Budget Controller
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Budget Controller Type
          </td>
          <td>Type Specification</td>
          <td>The Budget Controller Type is used to manage the budgets used by Sky to operationalize the Scopes
            to achieve the purpose and goals of the Spirit of the Atlas. It controls variable state that
            specifically authorizes executive votes to disburse payments from the Sky Surplus Buffer, or
            authorize smart contracts to disbuse such payments. The Budget Controller Document determines the
            rules and processes for modifying and using the budgets contained in the Budget Documents that are
            attached to it. Budget Controllers also have Active Data Documents attached that are used to report
            on the status and results of projects funded through the Budget Documents.</td>
          <td>"Content": The Content Component of Budget Controller Documents is used to describe flexible rules
            of how the Active Data Documents and Budget Documents must behave, and how they can be modified. The
            Custom Components format and requirements of the Active Data Documents and the Budget Documents must
            be defined as well.</td>
          <td>Primary Document</td>
          <td>Budget Controller Documents follow the Document Identifier Rules of Primary Documents.</td>
          <td>Budget Controller Documents must have an Active Data Directory Document located below it at the .0.6
            position, and a Budget Directory Document located below it at the .0.7 position.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Budget Directory
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Budget Directory Type
          </td>
          <td>Type Specification</td>
          <td>The Budget Directory Type is a directory Type used to list all of the Budget Documents that pertain
            to a Budget Controller Document.</td>
          <td>"Directory overview": This Component should contain a brief explanation of overall patterns and
            themes of the Budget Documents contained within.</td>
          <td>Supporting Document</td>
          <td>Budget Directory Documents must always be located at the .0.7 position of their Budget Controller
            Document.</td>
          <td>A Budget Directory Document should be updated whenever a new Budget Document is added that
            meaningfully changes what should be contained in the Directory overview Component.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Budget Document
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Budget Document Type
          </td>
          <td>Type Specification</td>
          <td>Budget Documents contain state that can authorize executive votes to disburse payments from the
            Sky Surplus Buffer, or authorize smart contracts to disburse such payments.</td>
          <td>"Custom Components": The Custom Components of Budget Documents are defined by the Budget Controller
            Document. They contain the variable state that can be directly modified.</td>
          <td>Supporting Document</td>
          <td>Budget Documents must always be located as subdocuments of the Budget Directory Document of their
            Budget Controller Document.</td>
          <td>Budget Documents specify a budget rate expressed as SKY or USDS per unit of time.
            Additionally, they can contain large amounts of data, or code, and their function and purpose
            depends on their Budget Controller Document. Budget Documents can be modified directly through
            processes external to the standard Atlas Edit Proposal process as specified by their Budget
            Controller Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Definition
              Directory Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Definition Directory
            Type</td>
          <td>Type Specification</td>
          <td>The Definition Directory Type is used for Target Documents with many complex subdocuments, and acts
            as a directory for definitions of unique terms that are only referenced in its subdocuments.</td>
          <td></td>
          <td>Supporting Document</td>
          <td>Definition Directory Documents must always be located at the .0.0 position of their Target Document.
          </td>
          <td>Definition Directory Documents only need to be present in Atlas Documents that require definitions
            for unique terms in their Subdocuments.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Definition
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Definition Type</td>
          <td>Type Specification</td>
          <td>The Definition Type is used for documents that define unique concepts contained in subdocuments to
            the Target Document of the Definition Document</td>
          <td>"Term": The Term Component contains the name of the term that is being defined."Definition": The
            Definition Component contains the detailed definition of the term.</td>
          <td>Supporting Document</td>
          <td>Definition Documents must always be located as subdocuments of the Definition Directory Document of
            their Target Document.</td>
          <td>To the extent possible it should be avoided to have the same term defined multiple times in the
            Atlas, and instead always put a single definition at a location in the Atlas that covers all of its
            use. The main exception to this principle should be when relatively niche terms are present in two
            different Scopes.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Translation
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Translation Type</td>
          <td>Type Specification</td>
          <td>The Translation Type is used for creating translated versions of Atlas Documents to make the Atlas
            accessible to non-English speakers. Translation Documents are Accessory Documents and they do not
            have any impact on the governance or operation of Sky, but they are important for accessibility
            and inclusivity.</td>
          <td>"Original Document Type": The Type of the original document that is being translated must be
            specified in this component."Language": The Language Component specifies the language in which the
            Atlas Document is translated."Translated Name": The Translated Name component contains the name of
            the translated Atlas Document in the new language. "Custom": Translation Documents contain Custom
            Components that mirror the components of the original Document with component name and component
            data translated to the new language.</td>
          <td>Accessory Document</td>
          <td>
            Translation Documents are located as subdocuments to the Atlas Document they are translating. Their
            Document Identifier is the same as the Atlas Document they are translating, with an additional
            suffix that represents the language of the translation. For example, a Spanish translation of <dfn>A.1</dfn>
            would have the
            Document Identifier A.1.es.
          </td>
          <td>Translation Documents should be updated whenever the Atlas Document they are translating is updated
            to ensure that the translation remains accurate. However, in case of any discrepancies or
            contradictions, the original English version of the Atlas Document always takes precedence.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Archive Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Archive Type</td>
          <td>Type Specification</td>
          <td>The Archive Type is used for storing historical versions of Atlas Documents. Archive Documents are
            Accessory Documents and they do not have any impact on the governance or operation of Sky, but
            they are important for maintaining a record of changes and evolution of the Atlas over time.</td>
          <td>"Original Document Type": The Type of the original document that is being archived must be specified
            in this component."Custom": Archive Documents contain Custom Components that mirror the components
            of the original Document at the time of the version being archived.</td>
          <td>Accessory Document</td>
          <td>
            Archive Documents are located as subdocuments to the Atlas Document they are archiving. Their
            Document Identifier is the same as the Atlas Document they are archiving, with an additional suffix
            'v' followed by the version number of the document being archived. For example, the third version of
            <dfn>A.1</dfn> would have the
            Document Identifier A.1.v3.
          </td>
          <td>Archive Documents should be created whenever an Atlas Document is updated to ensure that a record of
            all previous versions is maintained. They are not meant to be modified or deleted once created.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Navigation Hub
              Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Navigation Hub Type</td>
          <td>Type Specification</td>
          <td>The Navigation Hub Type is used for Navigation Hubs that provide summarized content and links to
            child documents or Focus Hubs that dive deeper or provide supporting data for a specific action. It
            acts as an entry point and guide for navigating the content of an Immutable or Primary Document.
          </td>
          <td>"Content": The Content Component must contain summarized information and links to the child
            documents of the associated Immutable or Primary Document. It must also link to the nearest
            navigation hubs below its position if its Child Documents do not have Navigation Hubs.</td>
          <td>Supporting Document</td>
          <td>Navigation Hub Documents must be located at the .0.0 position of an Immutable or Primary Document.
          </td>
          <td>Navigation Hubs serve as a guide for users to understand and navigate the main content of the
            associated Immutable or Primary Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Focus Hub Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Focus Hub Type</td>
          <td>Type Specification</td>
          <td>The Focus Hub Type is used for Focus Hubs that delve deeper into specific topics or sections from
            the Navigation Hub. It can be used to slice up a lot of child documents or a lot of hubs into
            independent groups, so only the relevant group needs to be read. It can also be used to provide
            relevant data for a specific type of action or workflow related to the Focus Hubs Immutable or
            Primary Document or its subtree.</td>
          <td>"Content": The Content Component must contain detailed information about the specific topic or
            section from the Navigation Hub."links_to": This Component can provide links to related documents or
            sections, with keys being the document names and values being their respective identifiers.</td>
          <td>Supporting Document</td>
          <td>Focus Hub Documents must be located at the nonzero numerical positions below Navigation Hubs, e.g.:
            x.0.0.1, x.0.0.2, etc.</td>
          <td>Focus Hubs serve as a detailed guide on specific topics, giving users an in-depth understanding of
            the subject matter.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator
              Scenario Directory Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Scenario
            Directory Type</td>
          <td>Type Specification</td>
          <td>The Facilitator Scenario Directory Type is a directory used to list all of the Scenarios that
            pertain to a Facilitator Action Tenet. Scenarios are hypothetical fact patterns that are designed to
            illustrate the practical application of a single Facilitator Action Tenet, i.e., its parent
            Facilitator Action Tenet Document. Scenarios are classified as either Aligned or Misaligned. Aligned
            Scenarios conform to the logic of the Target Document. Misaligned Scenarios have breached the Target
            Document logic and are thus in violation of the Atlas.</td>
          <td>"Directory index": This Component should contain a list of the Facilitator Scenarios contained
            within, with keys being the document identifiers and values being their document names.</td>
          <td>Supporting Document</td>
          <td>Facilitator Scenario Directory Documents must always be located at the .1 position below their
            parent Facilitator Action Tenet Document.</td>
          <td></td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator
              Scenario Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Scenario
            Type</td>
          <td>Type Specification</td>
          <td>Facilitator Scenario Documents contain hypothetical fact patterns that are designed to illustrate
            the practical application of a single Facilitator Action Tenet, i.e., its parent Facilitator Action
            Tenet Document. Scenarios are classified as either Aligned or Misaligned. Aligned Scenarios conform
            to the logic of the Target Document. Misaligned Scenarios have breached the Target Document logic
            and are thus in violation of the Atlas.</td>
          <td>"Name": This Component should be an abstract or very brief description of the Scenario, e.g.,
            "Crafter approves pull request authored by Star Team." A Scenario's Name should never be followed by
            a number unless there are multiple Scenarios with the same Name."Description": This Component
            contains the hypothetical fact pattern that illustrates the application of its parent Facilitator
            Action Tenet. The fact pattern should be as concrete in its details as possible, so as to be helpful
            to the Facilitators' decisionmaking."Finding": This Component indicates whether, in this Scenario,
            the Target Document logic was or was not breached. If the Target Document was not breached, the
            Finding is "Aligned". If the Target Document was breached, the Finding is "Misaligned"."Additional
            Guidance": This Component provides additional context on the specific aspects of the Scenario that
            were salient to the Aligned or Misaligned finding. It can also provide guidance in terms of how the
            Facilitators should respond to such a Scenario, i.e.: follow-up actions or means of investigation.
          </td>
          <td>Supporting Document</td>
          <td>Faciltator Scenario Documents must always be located as subdocuments of the Facilitator Scenario
            Directory Document, which in turn is nested under its parent Facilitator Action Tenet Document,
            e.g.: A.1.1-1.0.4.1.1.1.A Scenario's Name should never be followed by a number unless there are
            multiple Scenarios with the same Name.</td>
          <td></td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - List Of Document Types
              And Their Specifications - The Scenario Variation Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - List Of Document Types And
            Their Specifications - The Scenario Variation Type</td>
          <td>Type Specification</td>
          <td>Facilitator Scenario Variation Documents are variations on the hypothetical fact patterns presented
            in their parent Scenario document ("original Scenario"). Each Variation substitutes elements of its
            original Scenario to demonstrate whether and why the finding of Aligned/Misaligned would change.
            Like the Scenario Type, Scenario Variations are also designed to illustrate the practical
            application of a single Facilitator Action Tenet, i.e., the Scenario's parent Facilitator Action
            Tenet Document. Scenario Variations are classified as either Aligned or Misaligned. Aligned
            Scenarios conform to the logic of the Target Document. Misaligned Scenarios have breached the Target
            Document logic and are thus in violation of the Atlas.</td>
          <td>"Description": This Component contains the hypothetical fact pattern that illustrates the
            application of its parent Facilitator Action Tenet. The fact pattern should be as concrete in its
            details as possible, so as to be helpful to the Facilitators' decisionmaking."Finding": This
            Component indicates whether, in this Scenario Variation, the Target Document logic was or was not
            breached. If the Target Document was not breached, the Finding is "Aligned". If the Target Document
            was breached, the Finding is "Misaligned"."Additional Guidance": This Component provides additional
            context on the specific aspects of the Scenario Variation that were salient to the Aligned or
            Misaligned finding. It can also provide guidance in terms of how the Facilitators should respond to
            such a Scenario, i.e.: follow-up actions or means of investigation.</td>
          <td>Supporting Document</td>
          <td>Scenario Variation Documents are located as subdocuments to the Scenario Document of which they are
            a variation. Their Document Identifier is the same as their parent Scenario, with an additional
            suffix 'var' followed by the variation number of the original Scenario document. For example, the
            second Scenario Variation of the original Scenario document A.1.1.0.4.1.1.1. would have the
            following identifier: A.1.1.0.4.1.1.1.var2 .</td>
          <td></td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - List Of Document Types
              And Their Specifications - The Needed Research Type</dfn>
          </td>
          <td>Atlas Documents - Structure, Categories, And Types Of Atlas Documents - List Of Document Types And
            Their Specifications - The Needed Research Type</td>
          <td>Type Specification</td>
          <td>Needed Research Documents specify potential problems associated with their Target Document. Such
            problems can include potential gaps or conflicts in logic; questions regarding the operation of the
            Target Document to which there are currently no answers; etc.As such, Needed Research documents
            formalize continuing research into Universal Alignment and enable the adaptive intelligence of the
            ecosystem to drive the evolution of Sky. Scope Facilitators, Atlas workstream contributors or
            other ecosystem participants are able to submit Needed Research inputs, which are then progressively
            processed through the standardized Atlas data integration protocol.The gradual processing of Needed
            Research inputs can lead to modifications to the organization or content of Atlas documents, as well
            as concrete process improvements and new initiatives.</td>
          <td>"Research Prompt": This component contains descriptions of potential problems, unanswered questions
            or other concerns associated with the Target Document.</td>
          <td>Supporting Document</td>
          <td>Unlike other Supporting Documents, the document identifier of Needed Research documents is not
            derived from the Supporting Root of their Target Document. The "standalone" numbering scheme of
            Needed Research documents enables them to be linked to more than one Atlas Document, no matter the
            latter's location in the Atlas document tree. Needed Research Document Identifiers begin with the
            prefix "NR-", followed by an incremented number.</td>
          <td>Generally, Needed Research Documents are most effective when linked to Primary Documents or
            Supporting Documents. These Document types have the objective of extrapolating from the abstract
            logic of their Parent documents to formulate rules and processes that are more concrete and
            actionable. Therefore, inputs for Needed Research are more appropriately sourced at this deeper
            level in the Atlas Document tree.</td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="annotations">
    <h1>Annotations</h1>
    <table>
      <tr>
        <th>Doc No</th>
        <th>Name</th>
        <th>Type</th>
        <th>Content</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>Active
              Data Controller Document - Element Annotation</dfn>
          </td>
          <td>Active Data Controller Document - Element Annotation</td>
          <td>Annotation</td>
          <td>Active Data Controller Documents are Primary Documents that have Active Data Documents attached to
            them as Supporting Documents. Edits to Active Data Controller Documents are subject to a SKY vote
            pursuant to the standard governance processes. These processes include:• Atlas Edit Weekly Cycle•
            Atlas Edit Monthly Cycle• Facilitators' Bootstrapping Poll• Operational Weekly Cycle</td>
        </tr>
        <tr>
          <td>
            <dfn>Active
              Data Controller Document - Element Annotation</dfn>
          </td>
          <td>Active Data Controller Document - Element Annotation</td>
          <td>Annotation</td>
          <td>Active Data Controller Documents are Primary Documents that have Active Data Documents attached to
            them as Supporting Documents. Edits to Active Data Controller Documents are subject to a SKY vote
            pursuant to the standard governance processes. These processes include:• Atlas Edit Weekly Cycle•
            Atlas Edit Monthly Cycle• Facilitators' Bootstrapping Poll• Operational Weekly Cycle</td>
        </tr>
        <tr>
          <td>
            <dfn>Ambiguity
              - Element Annotation</dfn>
          </td>
          <td>Ambiguity - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "ambiguity" refers to instances where the language of an Atlas document allows for
            multiple possible interpretations.</td>
        </tr>
        <tr>
          <td>
            <dfn>Ambiguity
              - Element Annotation</dfn>
          </td>
          <td>Ambiguity - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "ambiguity" refers to instances where the language of an Atlas document allows for
            multiple possible interpretations.</td>
        </tr>
        <tr>
          <td>
            <dfn>Business
              Activities - Element Annotation</dfn>
          </td>
          <td>Business Activities - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "business activities" refers to the commercial activities, transactions, and
            interactions that Ecosystem Actors perform within the ecosystem. These may include, but are not
            limited to, service delivery, product development, collaboration, and information exchange.</td>
        </tr>
        <tr>
          <td>
            <dfn>BuyGem
              - Element Annotation</dfn>
          </td>
          <td>BuyGem - Element Annotation</td>
          <td>Annotation</td>
          <td>buyGem is a function that can be called on the LitePSM smart contract to buy a collateral asset in
            exchange for Dai. "Gem" here is Daiwanese for the collateral token.The Lite Peg Stability Module
            maintains a pool of pre-minted Dai and Stablecoins to minimize transaction costs in swapping. The
            buf parameter is the amount of pre-minted Dai the LitePSM is designed to maintain in most instances.
            However, when a user calls buyGem and buys the collateral asset in exchange for Dai, the amount of
            Dai can temporarily exceed the buf parameter.</td>
        </tr>
        <tr>
          <td>
            <dfn>Circumvent
              - Element Annotation</dfn>
          </td>
          <td>Circumvent - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "circumvent" means to find a way to evade or distort the Atlas' established rules,
            principles, or processes, with the intent to undermine Universal Alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Clear
              Breach of Good Faith - Element Annotation</dfn>
          </td>
          <td>Clear Breach of Good Faith - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to an action by the Star, or entities acting on its behalf, that undermines
            trust, integrity, or fair dealing, such as deception or unethical conduct.</td>
        </tr>
        <tr>
          <td>
            <dfn>Clearly
              Delineated Processes and Frameworks - Element Annotation</dfn>
          </td>
          <td>Clearly Delineated Processes and Frameworks - Element Annotation</td>
          <td>Annotation</td>
          <td>The element, "clearly delineated processes and frameworks," highlights a central issue in
            interpreting the Atlas. All language must be interpreted to be understood. In this sense,
            eliminating subjectivity is an unattainable goal. (Even an artificial intelligence system which
            eliminates many steps of research for the user will still serve up information that must be first
            interpreted by the user before it can be effective.) Inference or extrapolation is necessarily
            inherent in interpretation, and comes in degrees. In the context of the Target Document, the
            element, "clearly delineated processes and frameworks," affirms that an interpreter's extraction of
            rules/principles/processes should be maximally grounded in the explicit language of the Immutable
            Documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>Collateral
              - Element Annotation</dfn>
          </td>
          <td>Collateral - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "collateral" in this context refers to the funds within the AD Buffer that are set aside
            to guarantee the availability of a whistleblower bounty.</td>
        </tr>
        <tr>
          <td>
            <dfn>Colluding
              - Element Annotation</dfn>
          </td>
          <td>Colluding - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "colluding" refers to the act of conspiring or working together in secret to achieve an
            outcome that violates or undermines Universal Alignment or the Spirit of the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>Risk Of Misalignment Spreading Among ACs - Element Annotation</dfn>
          </td>
          <td>Risk Of Misalignment Spreading Among ACs - Element Annotation</td>
          <td>Annotation</td>
          <td>The element “risk of misalignment spreading among ACs” refers to the potential for misalignment by one 
            AC to influence or lead to misalignment among other ACs, creating a broader systemic risk. The element 
            emphasizes the need for quick action to contain any breach before it spreads and causes wider disruptions.</td>
        </tr>
        <tr>
          <td>
            <dfn>Contentious
              - Element Annotation</dfn>
          </td>
          <td>Contentious - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "contentious" describes a situation where there is disagreement or dispute regarding the
            interpretation, application, or validity of a document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Contradictions
              - Element Annotation</dfn>
          </td>
          <td>Contradictions - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "contradictions" refers to instances where different Atlas documents conflict with one
            another, leading to confusion or inconsistency in their application.</td>
        </tr>
        <tr>
          <td>
            <dfn>Counterparties
              - Element Annotation</dfn>
          </td>
          <td>Counterparties - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to external parties or entities with whom the Facilitators might interact in the
            context of governance operations, such as Ecosystem Actors (active or incubating).</td>
        </tr>
        <tr>
          <td>
            <dfn>Cryptographically
              Signed Messages - Element Annotation</dfn>
          </td>
          <td>Cryptographically Signed Messages - Element Annotation</td>
          <td>Annotation</td>
          <td>
            A simple way to provide the required cryptographically signed messages is to use the Verified
            Signature on-chain mechanism hosted by Etherscan (<a
              href="https://etherscan.io/verifiedSignatures">https://etherscan.io/verifiedSignatures</a>). The
            cryptographic verification comes from the prospective Aligned Delegate "signing" or validating the
            messages using their chosen Ethereum address. In addition, the cryptographically signed messages
            should contain the required elements (titles and timestamps) to be valid. The required elements are
            specified in the Target Document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Current
              Spell Team - Element Annotation</dfn>
          </td>
          <td>Current Spell Team - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "current spell team" refers to the group of people who are presently working on a given
            spell. Members of the spell team may perform a crafter role or a reviewer role. The "current spell
            team" does not include the "spell roster", which latter is defined as the group of people from which
            spell team members for a given spell are selected.</td>
        </tr>
        <tr>
          <td>
            <dfn>Current
              Spell Team - Element Annotation</dfn>
          </td>
          <td>Current Spell Team - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "current spell team" refers to the group of people who are presently working on a given
            spell. Members of the spell team may perform a crafter role or a reviewer role. The "current spell
            team" does not include the "spell roster", which latter is defined as the group of people from which
            spell team members for a given spell are selected.</td>
        </tr>
        <tr>
          <td>
            <dfn>Current
              Spell Team - Element Annotation</dfn>
          </td>
          <td>Current Spell Team - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "current spell team" refers to the group of people who are presently working on a given
            spell. Members of the spell team may perform a crafter role or a reviewer role. The "current spell
            team" does not include the "spell roster", which latter is defined as the group of people from which
            spell team members for a given spell are selected.</td>
        </tr>
        <tr>
          <td>
            <dfn>Debt
              Ceiling - Element Annotation</dfn>
          </td>
          <td>Debt Ceiling - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "Debt Ceiling" refers to the maximum amount that can be borrowed against assets in a
            vault. Although a PSM has a zero Stability Fee and a liquidation ratio of 100%, it is still a vault
            and swaps of a collateral asset for Dai represent issuance of Dai that is backed by that collateral
            asset. The Debt Ceiling serves to limit the exposure the PSM can incur to that collateral asset.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Debt
              Ceiling - Element Annotation</dfn>
          </td>
          <td>Debt Ceiling - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "Debt Ceiling" refers to the maximum amount that can be borrowed against assets in a
            vault. Although a PSM has a zero Stability Fee and a liquidation ratio of 100%, it is still a vault
            and swaps of a collateral asset for Dai represent issuance of Dai that is backed by that collateral
            asset. The Debt Ceiling serves to limit the exposure the PSM can incur to that collateral asset.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Delegate
              Contract - Element Annotation</dfn>
          </td>
          <td>Delegate Contract - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "Delegate Contract" refers to a bespoke Sky smart contract that allows SKY holders to
            delegate the voting strength associated with their SKY holdings to a particular Aligned Delegate.
            Every Aligned Delegate has at least one Delegate Contract, with which they can cast votes in Sky
            Governance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Delegated
              Voting Power - Element Annotation</dfn>
          </td>
          <td>Delegated Voting Power - Element Annotation</td>
          <td>Annotation</td>
          <td>The element “delegated voting power” refers to the ability of SKY holders and Sealing users to entrust their voting power to a Delegate Contract, allowing the Aligned Delegate controlling that contract to cast votes in the Sky Governance process on their behalf. The SKY holder or Sealing user always maintains full ownership of their tokens.</td>
        </tr>
        <tr>
          <td>
            <dfn>Deploying
              A Delegate Contract - Element Annotation</dfn>
          </td>
          <td>Deploying A Delegate Contract - Element Annotation</td>
          <td>Annotation</td>
          <td>
            A prospective Aligned Delegate must deploy a new Delegate Contract(s) through the associated smart
            contract, using their chosen Ethereum address. To create a new Delegate Contract, an applicant
            should visit this page and connect an Ethereum wallet: <a
              href="https://vote.makerdao.com/account">https://vote.makerdao.com/account</a>. An Aligned
            Delegate should deploy the new Delegate Contract(s) prior to posting a Submission Message on the Sky
            Forum pursuant to <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - AD Recognition Process -
              Submission Message</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Document
              Is Appealed - Element Annotation</dfn>
          </td>
          <td>Document Is Appealed - Element Annotation</td>
          <td>Annotation</td>
          <td>
            The element means that a formal request has been made to the Governance Facilitators to review an
            Atlas document for potential conflicts with other documents or misalignment. See <dfn>A.1.2
              - A3 - Atlas Documents - Conflict Resolution</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Ecosystem
              - Element Annotation</dfn>
          </td>
          <td>Ecosystem - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "Ecosystem" in the phrase "Ecosystem Agreements" should be understood as the
            collaborative network in which multiple stakeholders (referred to as "Ecosystem Actors") interact to
            conduct business operations benefiting Sky.</td>
        </tr>
        <tr>
          <td>
            <dfn>Executive
              Sheet - Element Annotation</dfn>
          </td>
          <td>Executive Sheet - Element Annotation</td>
          <td>Annotation</td>
          <td>
            The Executive Sheet refers to a Google Sheets document located at <a
              href="https://docs.google.com/spreadsheets/d/1w_z5WpqxzwreCcaveB2Ye1PP5B8QAHDglzyxKHG3CHw/edit?gid=1593813984#gid=1593813984">https://docs.google.com/spreadsheets/d/1w_z5WpqxzwreCcaveB2Ye1PP5B8QAHDglzyxKHG3CHw/edit?gid=1593813984#gid=1593813984</a>.
            The Executive Sheet contains a list of content which is planned to be included in a given spell. The
            Executive Sheet is prepared by the Governance Facilitators.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Expanded
              Definitions - Element Annotation</dfn>
          </td>
          <td>Expanded Definitions - Element Annotation</td>
          <td>Annotation</td>
          <td>
            The element "expanded definitions" describes the process of providing more detailed or comprehensive
            explanations of terms that are vague, overly broad, or otherwise unclear. Such expanded definitions
            can be codified in the Element Annotation Document Type. See <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Element Annotation
              Type</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Extrapolated
              - Element Annotation</dfn>
          </td>
          <td>Extrapolated - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "extrapolated" refers to the process by which a Facilitator has inferred or deduced from
            their understanding of the Spirit of the Atlas a necessary course of action when explicit guidance
            is not available. This inferred action is also based on the Facilitator's current state of Universal
            Alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Formalize
              Actions - Element Annotation</dfn>
          </td>
          <td>Formalize Actions - Element Annotation</td>
          <td>Annotation</td>
          <td>
            Facilitators have broad discretionary authority to interpret or supersede the Atlas pursuant to <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</dfn>. The
            element "formalize actions" pertains to the recommendation that Scope Facilitators, where feasible,
            conduct Governance Polls to officially ratify changes in the Atlas that correspond to the actions
            they have undertaken based on the aforementioned document.For example, if a Scope Facilitator
            decides to supersede a particular Atlas document due to its inadequacy in addressing a specific
            challenge, the Facilitator is encouraged to initiate a Governance Poll to allow SKY holders to vote
            on a revised version of the document that corrects the identified shortcomings.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Foundational
              Principles - Element Annotation</dfn>
          </td>
          <td>Foundational Principles - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "foundational principles" indicates the primary or essential rules, policies and
            objectives that serve as the groundwork for Sky Governance. To avoid ambiguity or slippery slope
            misalignment, these foundational principles must be specifically defined to the furthest extent
            possible in the Immutable Documents, as they are the base upon which the Adaptive Documents are
            built.</td>
        </tr>
        <tr>
          <td>
            <dfn>Governance
              Attacks - Element Annotation</dfn>
          </td>
          <td>Governance Attacks - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "governance attack" is a critical violation of the Sky ecosystem's governance protocols,
            far surpassing minor breaches in scope and impact. This term is reserved for misaligned acts with
            the near-term potential to severely compromise the Ecosystem's foundational structure and
            operational integrity. In contrast to mild breaches, which may involve actors with unintentional or
            benign motivations, a Governance Attack is distinguished by its deliberate and premeditated nature.
            Actors orchestrating such attacks are likely driven by strategic intent, aiming to destabilize or
            exploit the governance framework for their own gain.</td>
        </tr>
        <tr>
          <td>
            <dfn>Governance
              Dynamic - Element Annotation</dfn>
          </td>
          <td>Governance Dynamic - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "governance dynamic" refers generally to the balance of power and the integrity of
            operational processes that sustain Sky's Governance system. Disruption of this dynamic can lead to
            instability or misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Inaction
              - Element Annotation</dfn>
          </td>
          <td>Inaction - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "inaction" refers to the failure to act when action is necessary to prevent or address
            breaches of Universal Alignment or the Spirit of the Atlas. Inaction is considered as serious as
            active misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Internal
              Knowledge - Element Annotation</dfn>
          </td>
          <td>Internal Knowledge - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to information, insights, or data that are available exclusively to the
            Facilitators and are not shared or accessible to the Sky Ecosystem community. This could include
            messages in private chats, internal memos, emails, or proprietary data.</td>
        </tr>
        <tr>
          <td>
            <dfn>Isolated
              Borrow - Element Annotation</dfn>
          </td>
          <td>Isolated Borrow - Element Annotation</td>
          <td>Annotation</td>
          <td>"Isolated Borrow" specifies whether an asset can be borrowed when a user is in Isolation Mode on the
            SparkLend platform.</td>
        </tr>
        <tr>
          <td>
            <dfn>Methodologies
              - Element Annotation</dfn>
          </td>
          <td>Methodologies - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "methodologies" refers to the systematic approaches or frameworks used to achieve the
            specific objective of optimizing and aligning the Core Stability Parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>Monitoring
              And Ensuring - Element Annotation</dfn>
          </td>
          <td>Monitoring And Ensuring - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to the ongoing responsibility of Support Facilitators to monitor the progress of
            routine governance processes, check for compliance with the rules, and confirm that all necessary
            documentation and approvals are in place.</td>
        </tr>
        <tr>
          <td>
            <dfn>Multisig
            - Element Annotation</dfn>
          </td>
          <td>Multisig - Element Annotation</td>
          <td>Annotation</td>
          <td>The element “multisig” refers to a blockchain wallet implemented as a smart contract and requiring multiple signers 
            to approve transactions.<br> A blockchain wallet has an address associated with it and can hold cryptocurrency assets 
            as well as interact with smart contracts. The address of a blockchain wallet may be granted privileged access to 
            interact with other smart contracts, allowing the owner of the wallet to perform functions not available to other 
            users.<br> A multisig allows the control of a wallet to be shared among the signers based on specified parameters, 
            including the number of signers and how many signers are needed to approve each transaction. This allows a wallet to 
            be more safely managed: for instance, a multisig prevents the possibility that a single signer could take malicious 
            action and allows the signers to be updated if necessary.</td>
        </tr>
        <tr>
          <td>
            <dfn>Nested
              Document Trees - Element Annotation</dfn>
          </td>
          <td>Nested Document Trees - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "nested document trees" refers to the hierarchical organization of Atlas documents,
            where each document is part of a larger structure with parent and child relationships. Higher-level
            documents govern or influence the interpretation and application of lower-level documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>One
              Month's Budget Allocation - Element Annotation</dfn>
          </td>
          <td>One Month's Budget Allocation - Element Annotation</td>
          <td>Annotation</td>
          <td>
            See <dfn>One
              Month's Budget Allocation - Element Annotation</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>One
              Month's Budget Allocation - Element Annotation</dfn>
          </td>
          <td>One Month's Budget Allocation - Element Annotation</td>
          <td>Annotation</td>
          <td>
            See <dfn>One
              Month's Budget Allocation - Element Annotation</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>One
              Month's Budget Allocation - Element Annotation</dfn>
          </td>
          <td>One Month's Budget Allocation - Element Annotation</td>
          <td>Annotation</td>
          <td>
            To arrive at the value of this one-month budget threshold in USDS, see <dfn>A.1.5
              - Aligned Delegates - Budget And Participation Requirements - Budget Amount For Prime Delegate
              Slots</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Operational
              Security Or Privacy - Element Annotation</dfn>
          </td>
          <td>Operational Security Or Privacy - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "operational security or privacy" refers to disclosure or compromise of sensitive
            information related to the AD's identity, location and/or operations.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational
              Weekly Cycle - Element Annotation</dfn>
          </td>
          <td>Operational Weekly Cycle - Element Annotation</td>
          <td>Annotation</td>
          <td>Previously, the "Operational Weekly Cycle" was called simply the "Weekly Governance Cycle." With the
            introduction of the Atlas Edit Weekly Cycle, it became necessary to divide the Weekly Governance
            Cycle into two (2) subtypes: the Atlas Edit Weekly Cycle and the Operational Weekly Cycle. These two
            subtypes differ in terms of the permissioned parties authorized to trigger a proposal and the
            governance mechanisms involved. For instance, the Atlas Edit Weekly Cycle implements edits to the
            Atlas via the mechanism of a Governance Poll only. The Operational Weekly Cycle can action changes
            to the Protocol that require Atlas edits, and generally requires both a Governance Poll and an
            Executive Vote.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational
              Weekly Cycle - Element Annotation</dfn>
          </td>
          <td>Operational Weekly Cycle - Element Annotation</td>
          <td>Annotation</td>
          <td>Previously, the "Operational Weekly Cycle" was called simply the "Weekly Governance Cycle." With the
            introduction of the Atlas Edit Weekly Cycle, it became necessary to divide the Weekly Governance
            Cycle into two (2) subtypes: the Atlas Edit Weekly Cycle and the Operational Weekly Cycle. These two
            subtypes differ in terms of the permissioned parties authorized to trigger a proposal and the
            governance mechanisms involved. For instance, the Atlas Edit Weekly Cycle implements edits to the
            Atlas via the mechanism of a Governance Poll only. The Operational Weekly Cycle can action changes
            to the Protocol that require Atlas edits, and generally requires both a Governance Poll and an
            Executive Vote.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operationally
              Active - Element Annotation</dfn>
          </td>
          <td>Operationally Active - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "operationally active" refers to being formally engaged in a specific role that is
            defined in the Atlas as executing a mission or function within the Sky ecosystem.</td>
        </tr>
        <tr>
          <td>
            <dfn>Optimizing
              And Aligning - Element Annotation</dfn>
          </td>
          <td>Optimizing And Aligning - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "optimizing" refers to the process of making the Core Stability Parameters as effective
            as possible in achieving their goal of stabilizing the USDS Stablecoin. The element "aligning"
            refers to ensuring that these parameters are consistent and work in harmony with the objectives of
            Sky and with each other to prevent conflicts or discrepancies that could undermine stability.</td>
        </tr>
        <tr>
          <td>
            <dfn>Ordinary
              Operations - Element Annotation</dfn>
          </td>
          <td>Ordinary Operations - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to the routine activities, processes, and decisions that are part of the
            day-to-day functioning of Sky. It excludes decisions involving extraordinary circumstances and
            emergencies, as these situations may require certain security-sensitive matters to be kept
            confidential.</td>
        </tr>
        <tr>
          <td>
            <dfn>Otherwise
              Unable To Fulfill Their Duties - Element Annotation</dfn>
          </td>
          <td>Otherwise Unable To Fulfill Their Duties - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to situations where the Scope Facilitator is unable to perform their role due to
            reasons such as illness, conflict of interest, temporary suspension, or any other circumstance that
            significantly impairs their ability to execute their responsibilities.</td>
        </tr>
        <tr>
          <td>
            <dfn>Otherwise
              Unable To Fulfill Their Duties - Element Annotation</dfn>
          </td>
          <td>Otherwise Unable To Fulfill Their Duties - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to situations where the Scope Facilitator is unable to perform their role due to
            reasons such as illness, conflict of interest, temporary suspension, or any other circumstance that
            significantly impairs their ability to execute their responsibilities.</td>
        </tr>
        <tr>
          <td>
            <dfn>Partial
              Responsibility - Element Annotation</dfn>
          </td>
          <td>Partial Responsibility - Element Annotation</td>
          <td>Annotation</td>
          <td>This element clarifies that the Facilitator cannot choose to manage only certain parts of a Scope or
            limit their responsibility to specific tasks. They must accept the full responsibilities and manage
            the Scope as a whole.</td>
        </tr>
        <tr>
          <td>
            <dfn>Precedent
              - Element Annotation</dfn>
          </td>
          <td>Precedent - Element Annotation</td>
          <td>Annotation</td>
          <td>
            The element "precedent" refers to the established examples or standards set by documented Atlas
            Interpretations, which guide future decision-making and interpretations. Atlas Interpretations can
            be codified in the Facilitator Action Precedent Document Type. See <dfn>A.1.2
              - Atlas Documents - Structure, Categories, And Types Of Atlas Documents - The Facilitator Action
              Precedent Type</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Processes
              - Element Annotation</dfn>
          </td>
          <td>Processes - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "processes" refers to the step-by-step procedures or sequences of actions carried out to
            implement the methodologies referenced in the Target Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Properly
              Notified - Element Annotation</dfn>
          </td>
          <td>Properly Notified - Element Annotation</td>
          <td>Annotation</td>
          <td>This element means that the Support Facilitators have been informed in accordance with the
            prescribed procedures, including the timing, method, and content of the notification, as required by
            the relevant Scope.</td>
        </tr>
        <tr>
          <td>
            <dfn>Proportional
              Linear Scale - Element Annotation</dfn>
          </td>
          <td>Proportional Linear Scale - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "proportional linear scale" describes a method where the budget reduction is directly
            proportional to the decline in voting-communication activity between 95% and 75%. Here, the
            pertinent range of voting-communication activity spans from 95% to 75%, which is 20 percentage
            points. The budget decreases linearly across these 20 percentage points. In other words, the PD
            budget decreases by <strong>5%</strong> for every percentage point drop in voting-communication
            activity from 95% to 75% (since 100% divided by 20 percentage points = 5% per point).</td>
        </tr>
        <tr>
          <td>
            <dfn>Proportional
              Linear Scale - Element Annotation</dfn>
          </td>
          <td>Proportional Linear Scale - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "proportional linear scale" describes a method where the budget reduction is directly
            proportional to the decline in voting activity between 95% and 75%. Here, the pertinent range of
            voting activity spans from 95% to 75%, which is 20 percentage points. The budget decreases linearly
            across these 20 percentage points. In other words, the PD budget decreases by <strong>5%</strong>
            for every percentage point drop in voting activity from 95% to 75% (since 100% divided by 20
            percentage points = 5% per point).</td>
        </tr>
        <tr>
          <td>
            <dfn>Publicly
              Available Information - Element Annotation</dfn>
          </td>
          <td>Publicly Available Information - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to data, records, and documents that are accessible to the Sky Ecosystem
            community without any special access rights or permissions. This includes information published on
            websites, in public reports, or through other open and accessible channels.</td>
        </tr>
        <tr>
          <td>
            <dfn>Resilience
              Research And Preparedness - Element Annotation</dfn>
          </td>
          <td>Resilience Research And Preparedness - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to activities and studies aimed at strengthening Sky Ecosystem's ability to
            respond effectively to legal uncertainties or risks, including monitoring and analysis of legal
            trends and regulatory changes; scenario planning and risk modeling; and the development of
            strategies to mitigate potential threats.</td>
        </tr>
        <tr>
          <td>
            <dfn>Same 
              Codebase - Element Annotation</dfn>
          </td>
          <td>Same Codebase - Element Annotation</td>
          <td>Annotation</td>
          <td>The element “same codebase” refers to the fact that SparkLend is based on the Aave codebase. 
            Vulnerabilities or exploits discovered within Aave, or any other protocol utilizing the Aave 
            codebase, could potentially be replicated and affect SparkLend.</td>
        </tr>
        <tr>
          <td>
            <dfn>Secretly
              Organizing - Element Annotation</dfn>
          </td>
          <td>Secretly Organizing - Element Annotation</td>
          <td>Annotation</td>
          <td>
            The element "secretly organizing" is closely related to the term "colluding". See <dfn>Colluding
              - Element Annotation</dfn>. "Secretly organizing" means planning or coordinating actions behind
            closed doors, with the malign intent to bypass or undermine official processes or principles.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Sensitive
              Security Matters - Element Annotation</dfn>
          </td>
          <td>Sensitive Security Matters - Element Annotation</td>
          <td>Annotation</td>
          <td>This element refers to issues or decisions that, if publicly disclosed, could compromise the safety,
            integrity, or security of the Sky Ecosystem and its community members.</td>
        </tr>
        <tr>
          <td>
            <dfn>Separate
              Claim Protocol And Standard Operational Protocol - Element Annotation</dfn>
          </td>
          <td>Separate Claim Protocol And Standard Operational Protocol - Element Annotation</td>
          <td>Annotation</td>
          <td>
            The element refers to a separate set of procedures to be applied where Sky is the target of a legal
            or regulatory action. These separate procedures have not yet been defined. Once defined and
            ratified, they will be detailed in <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Legal Defense Standard Operational Protocols</dfn>.
            The Resilience Technical Committee must assist in elaborating this ruleset.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Slippery
              Slope Misalignment - Element Annotation</dfn>
          </td>
          <td>Slippery Slope Misalignment - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "slippery slope misalignment" refers to the potential for incremental deviations from
            Sky's core principles to gradually lead to significant and undesirable shifts, ultimately steering
            the Ecosystem away from its intended purpose and vision.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spirit
              of the Atlas - Element Annotation</dfn>
          </td>
          <td>Spirit of the Atlas - Element Annotation</td>
          <td>Annotation</td>
          <td>
            The element "Spirit of the Atlas" refers to the guiding principles that form the ethical,
            philosophical and operational foundation of the Sky ecosystem. This element should be understood as
            encompassing the core ideals and objectives influencing the governance, and thus the evolution, of
            Sky Ecosystem. The Spirit of the Atlas should be specified to the furthest extent possible in the
            Immutable Documents. The Spirit of the Atlas is continually evolving in response to internal and
            external stimuli; and thus reflects the adaptive intelligence of the Sky ecosystem as a whole. Once
            the Endgame State is reached and the Immutable Documents are forever locked down, the Spirit of the
            Atlas will continue to evolve through the vehicle of the Adaptive Documents. See also, <dfn>A.0.1
              - Atlas Preamble - Definitions - The Atlas</dfn> and <dfn>A.0.1
              - Atlas Preamble - Definitions - Letter Of The Rule Vs Spirit Of The Rule</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Spreads
              - Element Annotation</dfn>
          </td>
          <td>Spreads - Element Annotation</td>
          <td>Annotation</td>
          <td>The element refers to the differences added or subtracted from the Base Rate to determine other
            specific rates.</td>
        </tr>
        <tr>
          <td>
            <dfn>Stabilize
              - Element Annotation</dfn>
          </td>
          <td>Stabilize - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "stabilize" refers to the objective of maintaining USDS's value within a narrow range,
            preventing significant fluctuations that could lead to volatility. USDS should be worth $1 USD to
            fulfill its promise of being a Stablecoin.</td>
        </tr>
        <tr>
          <td>
            <dfn>Total Voting Power Delegated - Element Annotation</dfn>
          </td>
          <td>Total Voting Power Delegated - Element Annotation</td>
          <td>Annotation</td>
          <td>The element “total Voting Power delegated” refers to the cumulative SKY/MKR that has been delegated 
            to a Delegate Contract by SKY/MKR holders and Sealing users.</td>
        </tr>
        <tr>
          <td>
            <dfn>Trigger
              - Element Annotation</dfn>
          </td>
          <td>Trigger - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "trigger" refers to the Support Facilitators' act of adding a Resilience Research and
            Preparedness grant payment to an Executive Vote. The Support Facilitators are also responsible for
            providing provenance for such requests by confirming payment requests on the Executive Sheet. See
            <strong><dfn>Executive
                Sheet - Element Annotation</dfn></strong>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Trigger
              - Element Annotation</dfn>
          </td>
          <td>Trigger - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "trigger" refers to the Support Facilitators' act of adding a Resilience Research and
            Preparedness grant payment to an Executive Vote. The Support Facilitators are also responsible for
            providing provenance for such requests by confirming payment requests on the Executive Sheet. See
            <strong><dfn>Executive
                Sheet - Element Annotation</dfn></strong>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Unresponsive
              - Element Annotation</dfn>
          </td>
          <td>Unresponsive - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "unresponsive" means the failure to communicate, perform duties, or acknowledge
            requests, without providing a valid reason.</td>
        </tr>
        <tr>
          <td>
            <dfn>Unresponsive
              - Element Annotation</dfn>
          </td>
          <td>Unresponsive - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "unresponsive" means the failure to communicate, perform duties, or acknowledge
            requests, without providing a valid reason.</td>
        </tr>
        <tr>
          <td>
            <dfn>Upcoming
              Executive Vote - Element Annotation</dfn>
          </td>
          <td>Upcoming Executive Vote - Element Annotation</td>
          <td>Annotation</td>
          <td>Successfully polled changes to the Sky Protocol are included in an Executive Vote that is typically
            conducted within approximately 30 days of the poll passing. The exact timing is dependent on the
            decisions made by the Governance Facilitators and the spell teams.</td>
        </tr>
        <tr>
          <td>
            <dfn>Voting-Communication
              Metrics - Element Annotation</dfn>
          </td>
          <td>Voting-Communication Metrics - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "voting-communication metrics" refers to the percentage of votes for which an Aligned
            Delegate provides the required written explanations or justifications of their casted votes in
            Governance Polls and Executive Votes. These written explanations are posted in the AD's Forum
            thread. The Target Document's function is to ensure that SKY holders delegating to the AD have full
            transparency to understand the AD's decision-making process.</td>
        </tr>
        <tr>
          <td>
            <dfn>Where
              Feasible - Element Annotation</dfn>
          </td>
          <td>Where Feasible - Element Annotation</td>
          <td>Annotation</td>
          <td>This element "where feasible" introduces a degree of flexibility or discretion. It indicates that
            Scope Facilitators are encouraged to run Governance Polls in the context of the Target Document when
            it is possible, practical or appropriate to do so.</td>
        </tr>
        <tr>
          <td>
            <dfn>Whistleblower
              Bounty - Element Annotation</dfn>
          </td>
          <td>Whistleblower Bounty - Element Annotation</td>
          <td>Annotation</td>
          <td>The element "whistleblower bounty" is a financial reward allocated to individuals who responsibly
            provide credible evidence that is helpful to the Facilitators' investigation of an AD's misalignment
            or operational security breach.</td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="tenets">
    <h1>Tenets</h1>
    <table>
      <tr>
        <th>Doc No (or Temp Name)</th>
        <th>Name</th>
        <th>Type</th>
        <th>Content</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>ACs
              Must Go Beyond Mere Technical Compliance With Rules</dfn>
          </td>
          <td>ACs Must Go Beyond Mere Technical Compliance With Rules</td>
          <td>Action Tenet</td>
          <td>
            Alignment Conservers (ACs) must meet the most stringent standards for Universal Alignment,
            demonstrating not only compliance with the letter of the rules but also a deep and authentic
            commitment to the spirit of the rules, i.e., the underlying principles and goals of Sky. This
            demanding standard goes beyond mere technical compliance and requires proof of genuine intent and
            actions consistent with upholding the Spirit of the Atlas. See <dfn>A.0.1
              - Atlas Preamble - Definitions - Letter Of The Rule Vs Spirit Of The Rule</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Adjudication
              Guidelines to be applied to a second misaligned act or a first misaligned act that is not
              mild</dfn>
          </td>
          <td>Adjudication Guidelines to be applied to a second misaligned act or a first misaligned act that is
            not mild</td>
          <td>Action Tenet</td>
          <td>
            The Target Document fails to specify accountability measures for an AC who commits a misaligned act
            that is not mild. The Target Document is also silent on the subject of the proper remedial approach
            if an AC commits a subsequent misaligned act after an initial mild breach. The language does imply
            subsequent breaches should be treated with increasing severity.Despite the lack of explicit
            guidance, however, Facilitators have likely been given sufficient information in <dfn>A.1.4</dfn> to reach a
            reliable adjudication principle. Taken in its totality, the above cited Article requires
            Facilitators to take a highly aggressive stance when it comes to responding to AC misalignment risk.
            The absence of a substantial punitive measure for the first mild breach provides the AC with an
            opportunity for corrective action and learning. After the initial warning, any subsequent breach
            must immediately trigger derecognition, regardless of the degree of severity. Similarly, an initial
            breach that is not mild in scope or impact must trigger derecognition. This escalation is a
            necessary consequence of the Atlas's mandate that ACs are held to the highest standards of Universal
            Alignment.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>ADs
              & Facilitators required to adhere to comprehensive operational security practices</dfn>
          </td>
          <td>ADs & Facilitators required to adhere to comprehensive operational security practices</td>
          <td>Action Tenet</td>
          <td>The operational security of the Alignment Conserver roles is key to governance integrity overall.
            Aligned Delegates and Facilitators are mandated to maintain rigorous operational security practices
            to ensure that their identities and work activities are anonymized and all related information is
            safeguarded. Such practices must go beyond basic privacy-enhancing measures and must include the use
            of secure communication channels, stringent data encryption, anonymity tools like VPNs and TOR
            networks, regular security audits, and rigorous digital footprint management.</td>
        </tr>
        <tr>
          <td>
            <dfn>Amended
              - Blocked AEPs Cannot Be Re-Submitted In Original Form</dfn>
          </td>
          <td>Amended - Blocked AEPs Cannot Be Re-Submitted In Original Form</td>
          <td>Action Tenet</td>
          <td>An AEP that was blocked for misalignment cannot be resubmitted in its original form; it must be
            edited before it can be formally submitted again to the Monthly Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>Any
              Active Scope Facilitator - Only Active Scope Facilitators Can Take Over Expedited Onboarding of
              Reserve Facilitators</dfn>
          </td>
          <td>Any Active Scope Facilitator - Only Active Scope Facilitators Can Take Over Expedited Onboarding of
            Reserve Facilitators</td>
          <td>Action Tenet</td>
          <td>
            In the event that the Governance Facilitators are unable to fulfill their role, only currently
            active Scope Facilitators (not Reserve or Interim Facilitators) are authorized to take over the
            expedited process of onboarding Reserve Facilitators defined in <dfn>A.1.6
              - Facilitators - Expedited Onboarding Of Reserve Facilitators</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Any
              Active Scope Facilitator - Reserve And Interim Governance Facilitators Cannot Initiate Formal
              Adjudication</dfn>
          </td>
          <td>Any Active Scope Facilitator - Reserve And Interim Governance Facilitators Cannot Initiate Formal
            Adjudication</td>
          <td>Action Tenet</td>
          <td>
            Only currently active Scope Facilitators can initiate a formal adjudication pursuant to <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication Process</dfn>.
            This Action Tenet does not limit in any way a Reserve or Interim Facilitator from bringing
            allegations of potential Facilitator misalignment to the Governance Facilitators or another active
            Scope Facilitator. If warranted, the active Scope Facilitators can then decide to initiate a formal
            adjudication to investigate the allegations.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Clear Error</dfn>
          </td>
          <td>Clear Error</td>
          <td>Action Tenet</td>
          <td>The Target Document grants Facilitators the authority to directly edit an Active Data document if it
            contains a mistake or inaccuracy that is obvious, unambiguous, and indisputable. The term "clear
            error" means that the mistake is apparent and does not require extensive debate or investigation to
            be recognized as such.</td>
        </tr>
        <tr>
          <td>
            <dfn>Clearly
              Delineated Processes and Frameworks - AC actions must be grounded in explicit frameworks of
              Immutable Documents</dfn>
          </td>
          <td>Clearly Delineated Processes and Frameworks - AC actions must be grounded in explicit frameworks of
            Immutable Documents</td>
          <td>Action Tenet</td>
          <td>Generally, when an AC acts to impact governance in any way, they must do so according to
            rules/principles/processes that are based on the explicit language of the Immutable Documents.
            Because of the nature of language and the fact that the Atlas can never anticipate all possible
            scenarios, it will sometimes be necessary for the basis of ACs' actions to be sourced from
            extrapolations or inferences of logic, but these must be grounded.'Grounded inferences' means that
            derivations, deductions or extensions of governance logic maintain a strong, clear connection and
            alignment with the delineated processes and frameworks explicitly defined in the Immutable
            Documents.Because ungrounded inferences of logic lack such a robust and clearly documented
            foundation, they introduce severe misalignment risk given the potential for intentional
            misrepresentation or distortion. The interpreter may deviate from the genuine intent of the
            Immutable Documents, not driven by an earnest effort to understand but rather influenced by personal
            motives or ulterior agendas.</td>
        </tr>
        <tr>
          <td>
            <dfn>Clearly
              Detail Their Interactions - Facilitators' Documentation Mandate</dfn>
          </td>
          <td>Clearly Detail Their Interactions - Facilitators' Documentation Mandate</td>
          <td>Action Tenet</td>
          <td>Facilitators are required to thoroughly document all aspects of their communications and dealings
            with counterparties. This includes the content of discussions, the context of interactions (date and
            time), and any decisions made or actions taken as a result.</td>
        </tr>
        <tr>
          <td>
            <dfn>Determination
              Of Feasibility Is Itself At The Discretion of Facilitators</dfn>
          </td>
          <td>Determination Of Feasibility Is Itself At The Discretion of Facilitators</td>
          <td>Action Tenet</td>
          <td>The determination of feasibility may depend on factors such as time constraints, resource
            availability, or the urgency of the decision. The determination of feasibility Is itself at the
            discretion of the Facilitators.</td>
        </tr>
        <tr>
          <td>
            <dfn>Determine
              How They Are Modified - Immutable Documents Can Be Amended In The Transition To Endgame</dfn>
          </td>
          <td>Determine How They Are Modified - Immutable Documents Can Be Amended In The Transition To Endgame
          </td>
          <td>Action Tenet</td>
          <td>Currently, in the transition to Endgame, the Immutable Documents (Articles and Sections) can be
            amended pursuant to <strong><dfn>A.1.11</dfn></strong>
            and <strong><dfn>A.1.12</dfn></strong>.
            Once the Sky Ecosystem enters the Endgame State, the Immutable Documents of the Atlas will be
            forever locked down and cannot be changed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Doubt
              Regarding AC's Alignment Will Be Resolved Against Them</dfn>
          </td>
          <td>Doubt Regarding AC's Alignment Will Be Resolved Against Them</td>
          <td>Action Tenet</td>
          <td>In adjudicating potential misalignment of Alignment Conservers, Facilitators are not to assume
            innocence or give leeway in cases of ambiguity. Instead, the burden is on the Alignment Conserver to
            provide clear and convincing evidence of their alignment. Any uncertainty or doubt regarding the
            AC's alignment will be resolved against them, requiring them to definitively prove their adherence
            to the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>Evaluating
              AC breach of role-specific requirement vs. general requirement</dfn>
          </td>
          <td>Evaluating AC breach of role-specific requirement vs. general requirement</td>
          <td>Action Tenet</td>
          <td>When an Alignment Conserver breaches a role-specific requirement, this is misalignment on par with a
            breach of a general AC requirement, and vice versa. Facilitators must not default to assigning
            greater or lesser culpability on the sole basis of whether the breached rule is role-specific or
            general. Apart from this caveat, misaligned acts can have varying degrees of severity or harm, and
            should be individually evaluated by the Facilitator in any action.</td>
        </tr>
        <tr>
          <td>
            <dfn>Facilitators'
              Authority To Raise Formal Allegation</dfn>
          </td>
          <td>Facilitators' Authority To Raise Formal Allegation</td>
          <td>Action Tenet</td>
          <td>
            Any community member or Aligned Delegate with information pertinent to suspected Alignment Conserver
            misalignment may take their concerns directly to the Governance Facilitators. Upon receiving such
            information, the Governance Facilitators must promptly conduct an initial review to quickly assess
            the credibility of the concern. Based on this preliminary review, the Governance Facilitators must
            decide whether to initiate a formal adjudication process in accordance with <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Adjudication
              Process</dfn>.Where the allegation of misalignment concerns a Governance Facilitator, a community
            member can take their concerns to any other Scope Facilitator, who is then empowered to initiate the
            formal adjudication process.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Formalizing
              actions via Governance Poll is encouraged, but not mandatory</dfn>
          </td>
          <td>Formalizing actions via Governance Poll is encouraged, but not mandatory</td>
          <td>Action Tenet</td>
          <td>
            If a Scope Facilitator decides to supersede a particular Atlas document due to its inadequacy in
            addressing a specific challenge, the Facilitator is encouraged, though not required, to initiate a
            Governance Poll to allow SKY holders to vote on a revised version of the document that corrects the
            identified shortcomings. The Target Document does not require Facilitators to run a Governance Poll
            to formalize their actions.Similarly, if a Facilitator identifies a gap in the Atlas where a
            particular need is not explicitly addressed, they may extrapolate a course of action based on their
            interpretation of the Spirit of the Atlas. In this case, as well, the Target Document does not
            require Facilitators to run a Governance Poll to formalize their interpretation or extrapolated
            actions.This Action Tenet acknowledges the necessity for Facilitators to possess flexible and broad
            discretionary authority during the early stages of the Atlas' development. Such flexibility ensures
            that the ecosystem can swiftly adapt to emerging challenges. Consequently, it is important at this
            stage to avoid over-formalizing actions and decisions taken by Facilitators pursuant to <dfn>A.0.1
              - Atlas Preamble - General Provisions - Facilitators' Broad Discretionary Capacity</dfn>.
          </td>
          <tr>
          <td>
            <dfn>Governance 
              Facilitators Must Exercise Due Caution In Reviewing Use Of Multisig</dfn>
          </td>
          <td>Governance Facilitators Must Exercise Due Caution In Reviewing Use Of Multisig</td>
          <td>Action Tenet</td>
          <td>
           The list of instances justifying use of the Multisig in the Target Document is not intended to be 
            exhaustive. However, the Governance Facilitators must exercise due caution in reviewing and validating 
            use of the Multisig in edge cases, i.e., use of the Multisig that falls outside of the examples provided 
            in the Target Document. In such “edge cases,” the Governance Facilitators must ensure that a postmortem 
            is publicly published on the Sky Forum which justifies the use of the Multisig. The Governance Facilitators 
            should also consider proposing an edit to the Target Document so that the edge case is explicitly included 
            in the examples provided in the Target Document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Highest
              Standard - Facilitators must apply strictest possible requirements of Universal Alignment on
              ACs</dfn>
          </td>
          <td>Highest Standard - Facilitators must apply strictest possible requirements of Universal Alignment on
            ACs</td>
          <td>Action Tenet</td>
          <td>In any adjudication involving potential misalignment of Alignment Conservers (ACs), Facilitators are
            unequivocally directed to apply the strictest and highest standards of Universal Alignment.As ACs
            are held to the most rigorous standards of Universal Alignment, Facilitators should acknowledge
            evidence of misalignment if such evidence is deemed at least 51% more likely than not to be valid or
            to substantiate the presented claim. Additionally, should the overall weight of the evidence
            demonstrate a 51% or greater chance that the AC committed a misaligned act, the Facilitator is
            required to derecognize the AC.Given the exceptionally high stakes in cases of potential AC
            misalignment, Facilitators must prioritize an approach grounded in an abundance of caution, steering
            away from notions of 'fairness' or 'lenience.' Any lapse or misjudgment on the part of an AC cannot
            be excused based on ignorance of the rules, good intentions, honest mistake or similar factors.
            Maximal accountability for ACs is non-negotiable, a principle underpinned by the indispensable role
            of ACs as stewards of Universal Alignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>In
              Progress - Change To Minimum Positive Participation Value Cannot Affect Polls That Have Already
              Begun</dfn>
          </td>
          <td>In Progress - Change To Minimum Positive Participation Value Cannot Affect Polls That Have Already
            Begun</td>
          <td>Action Tenet</td>
          <td>"In progress" refers to the state of a Ratification Poll that has already started, where voting is
            currently taking place. The Target Document thus states that any changes to Minimum Positive
            Participation values cannot affect polls that have already begun.</td>
        </tr>
        <tr>
          <td>
            <dfn>In
              The Transition To Endgame - Immutable Documents Can Be Amended</dfn>
          </td>
          <td>In The Transition To Endgame - Immutable Documents Can Be Amended</td>
          <td>Action Tenet</td>
          <td>
            Currently, in the transition to Endgame, the Immutable Documents (Articles and Sections) can be
            amended pursuant to <dfn>A.1.11</dfn> and <dfn>A.1.12</dfn>. Once the
            Sky Ecosystem enters the Endgame State, the Immutable Documents of the Atlas will be forever locked
            down and cannot be changed.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Key
              Atlas Contributors</dfn>
          </td>
          <td>Key Atlas Contributors</td>
          <td>Action Tenet</td>
          <td>Key Atlas contributors are individuals or teams that play a crucial role in the development of the
            Atlas. Relevant workstreams can include community building, research, data collection, data
            processing, data review, drafting, peer review, etc. The Support Facilitators, in consultation with
            Atlas Axis or other relevant Ecosystem Actors, will distribute funding based on criteria such as the
            scope of the contribution, its impact on the Atlas, and the quality of the work produced.</td>
        </tr>
        <tr>
          <td>
            <dfn>Mild
              slippery slope breaches - Evaluating whether a misaligned act is 'very mild'</dfn>
          </td>
          <td>Mild slippery slope breaches - Evaluating whether a misaligned act is 'very mild'</td>
          <td>Action Tenet</td>
          <td>The element "mild slippery slope breach" characterizes a form of misalignment or rule breach that,
            when viewed in isolation, exhibits relatively insignificant scope or impact. Furthermore, a "very
            mild" act of misalignment often indicates a lack of ill intent (i.e., innocent mistake) or
            premeditation on the part of the rule violator. A "very mild slippery slope breach" will likely be
            the violator's first offense.</td>
        </tr>
        <tr>
          <td>
            <dfn>Mild
              slippery slope breaches - Facilitators required to be proactive against even mild
              misalignment</dfn>
          </td>
          <td>Mild slippery slope breaches - Facilitators required to be proactive against even mild misalignment
          </td>
          <td>Action Tenet</td>
          <td>Any Alignment Conserver misalignment, regardless of its seemingly trivial nature, carries inherent
            risks. ACs must be held to the highest standards of Universal Alignment. The Target Document
            indicates that leniency towards AC infractions could set a risky precedent, where, for instance,
            misaligned actors justify themselves based on prior instances of lenience.</td>
        </tr>
        <tr>
          <td>
            <dfn>Must
              Act Swiftly - Facilitators Must Take Immediate And Prompt Action</dfn>
          </td>
          <td>Must Act Swiftly - Facilitators Must Take Immediate And Prompt Action</td>
          <td>Action Tenet</td>
          <td>By "swiftly," the Target Document requires Facilitators to take immediate and prompt action without
            unnecessary delay. The urgency is intended to prevent further harm or disruption within the
            governance system. A highly time-sensitive response is mandated for any breaches or potential risks
            of AC misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operationally
              Active - Whether an entity is "operationally active" in a role is determined purely on a formal
              basis</dfn>
          </td>
          <td>Operationally Active - Whether an entity is "operationally active" in a role is determined purely on
            a formal basis</td>
          <td>Action Tenet</td>
          <td>
            Whether an entity is "operationally active" in a role is determined purely on a formal basis. As
            long as an entity occupies or assumes a role that is formally defined in the Atlas, that entity is
            "operationally active" in that role. This is notwithstanding the amount of time the entity devotes
            to a role; the nature of the work performed by the entity in a role; the fact that the entity is on
            a leave of absence from one role; the fact that the entity's role is uncompensated; or the fact that
            the entity alternates between two roles to avoid simultaneous performance of both roles.This Tenet
            is based on the rationale of protecting against misalignment risks that arise when a stakeholder
            occupies two or more ecosystem roles, each of which has different mandates and inner incentives.
            Such misalignment risks include conflict of interest and bias, collusion and conspiracy.See also, <dfn>Other
              Ecosystem Roles - Phrase must be read in its broadest sense by Facilitators</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Opportunity
              To Respond</dfn>
          </td>
          <td>Opportunity To Respond</td>
          <td>Action Tenet</td>
          <td>The opportunity to respond should include sufficient time to prepare a response, the ability to
            submit information or evidence, and reasonable access to any information pertinent to the
            allegation. Where an internal or external whistleblower has provided evidence of potential AC
            misalignment, the Governance Facilitators should keep the whistleblower's identity confidential.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Other
              Ecosystem Roles - Phrase must be read in its broadest sense by Facilitators</dfn>
          </td>
          <td>Other Ecosystem Roles - Phrase must be read in its broadest sense by Facilitators</td>
          <td>Action Tenet</td>
          <td>
            The Target Document is violated if an Alignment Conserver formally occupies two or more Sky
            ecosystem roles. The phrase "other ecosystem roles" is read in its broadest sense to mean the
            totality of roles that are formally defined in the Atlas with a function in the Sky ecosystem. Such
            "ecosystem roles" include, but are not limited to, Alignment Conserver, Governance Process Support
            Ecosystem Actor, Active or Incubating Ecosystem Actor, Star Advisor, Arranger, and the contributors
            supporting these aforementioned actors. The rationale of this rule is to protect against
            misalignment risks that arise when a stakeholder occupies two or more ecosystem roles, each of which
            has different mandates and inner incentives. Such misalignment risks include conflict of interest
            and bias, collusion and conspiracy.See also, <dfn>Operationally
              Active - Whether an entity is "operationally active" in a role is determined purely on a formal
              basis</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Other
              Ecosystem Roles - Ecosystem Role need not be compensated or full-time to be regulated under
              Target Document</dfn>
          </td>
          <td>Other Ecosystem Roles - Ecosystem Role need not be compensated or full-time to be regulated under
            Target Document</td>
          <td>Action Tenet</td>
          <td>An "ecosystem role" need not be compensated or full-time to be regulated by the Target Document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Promptly
              Derecognized - Mandated Timeline For AC Derecognition For Misalignment</dfn>
          </td>
          <td>Promptly Derecognized - Mandated Timeline For AC Derecognition For Misalignment</td>
          <td>Action Tenet</td>
          <td>The element 'promptly' in the Target Document means 'as soon as is reasonably possible.'To adhere to
            this commitment, the Governance Facilitators must derecognize the AC within a general timeframe of
            1-2 calendar days upon conclusion of an adjudication that finds against the AC for misalignment.
            Failure to meet this deadline requires a showing of good cause, demonstrating extenuating
            circumstances beyond the Facilitators' control.</td>
        </tr>
        <tr>
          <td>
            <dfn>Promptly
              Derecognized - Mandated Timeline For AD Derecognition For Operational Security Breach</dfn>
          </td>
          <td>Promptly Derecognized - Mandated Timeline For AD Derecognition For Operational Security Breach</td>
          <td>Action Tenet</td>
          <td>The element 'promptly' in the Target Document means 'as soon as is reasonably possible.'To adhere to
            this commitment, the Governance Facilitators must derecognize the AD within a general timeframe of
            1-2 calendar days upon conclusion of an investigation that finds against the AD for breach of
            operational security. Failure to meet this deadline requires a showing of good cause, demonstrating
            extenuating circumstances beyond the Facilitators' control.</td>
        </tr>
        <tr>
          <td>
            <dfn>Promptly
              Derecognized - Mandated Timeline For Facilitator Derecognition</dfn>
          </td>
          <td>Promptly Derecognized - Mandated Timeline For Facilitator Derecognition</td>
          <td>Action Tenet</td>
          <td>The element 'promptly' in the Target Document means 'as soon as is reasonably possible.'To adhere to
            this commitment, the Governance Facilitators must derecognize the Facilitator within a general
            timeframe of 1-2 calendar days upon conclusion of an investigation that finds against the
            Facilitator. Failure to meet this deadline requires a showing of good cause, demonstrating
            extenuating circumstances beyond the Facilitators' control.</td>
        </tr>
        <tr>
          <td>
            <dfn>Responsibly
              Provided - Whistleblower Evidence Of Misalignment Must Be Secured Ethically</dfn>
          </td>
          <td>Responsibly Provided - Whistleblower Evidence Of Misalignment Must Be Secured Ethically</td>
          <td>Action Tenet</td>
          <td>
            The phrase "responsibly provided" places limits on the sort of data, evidence and information that
            will enable a whistleblower to qualify for the bounty. Such data, evidence or information must have
            been secured ethically. A whistleblower who used publicly available data (e.g., public Discord or
            Forum posts) to demonstrate that an Aligned Delegate committed misaligned acts will qualify for the
            bounty. A whistleblower who hacked into the Aligned Delegate's devices or accounts to make this same
            demonstration will be disqualified from receiving the bounty. Where reasonable people would disagree
            about the ethical nature of the whistleblower's actions, the Governance Facilitators should err on
            the side of disqualifying the whistleblower. In such instances, disqualification prevents the
            setting of precedent that might incentivize future whistleblowers to engage in unethical or illegal
            activities.Both the Action Tenet and the above-stated presumption are supported by the Universal
            Alignment Assumption, which states that the "underlying intent of rules always aims to serve human
            values and promote public benefit within a given context." See <dfn>A.0.1
              - Atlas Preamble - Definitions - Universal Alignment Assumption</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Responsibly
              Provided - Whistleblower Evidence Of Operational Security Breach Must Be Secured Ethically</dfn>
          </td>
          <td>Responsibly Provided - Whistleblower Evidence Of Operational Security Breach Must Be Secured
            Ethically</td>
          <td>Action Tenet</td>
          <td>
            The phrase "responsibly provided" places limits on the sort of data, evidence and information that
            will enable a whistleblower to qualify for the bounty. Such data, evidence or information must have
            been secured ethically. A whistleblower who used publicly available blockchain data to demonstrate
            that an Aligned Delegate breached operational security best practices will qualify for the bounty. A
            whistleblower who hacked into the Aligned Delegate's devices or accounts to make this same
            demonstration will be disqualified from receiving the bounty. Where reasonable people would disagree
            about the ethical nature of the whistleblower's actions, the Governance Facilitators should err on
            the side of disqualifying the whistleblower. In such instances, disqualification prevents the
            setting of precedent that might incentivize future whistleblowers to engage in unethical or illegal
            activities.Both the Action Tenet and the above-stated presumption are supported by the Universal
            Alignment Assumption, which states that the "underlying intent of rules always aims to serve human
            values and promote public benefit within a given context." See <dfn>A.0.1
              - Atlas Preamble - Definitions - Universal Alignment Assumption</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Spell
              Teams - All Recognized Spell Teams Can Participate</dfn>
          </td>
          <td>Spell Teams - All Recognized Spell Teams Can Participate</td>
          <td>Action Tenet</td>
          <td>The element "spell teams" indicates that the entire spell roster can participate in the decision
            described in the Target Document. The spell roster is defined as all spell team members authorized
            to perform spell crafting and spell reviewing services for Sky Core.</td>
        </tr>
        <tr>
          <td>
            <dfn>Trigger
              - Support Facilitators Must Add Atlas Core Development Payments To Executive Vote</dfn>
          </td>
          <td>Trigger - Support Facilitators Must Add Atlas Core Development Payments To Executive Vote</td>
          <td>Action Tenet</td>
          <td>
            In this context, the element "trigger" means that the Support Facilitators are responsible for
            requesting the addition of Atlas Core Development payments to an Executive Vote. The Support
            Facilitators are also responsible for providing provenance for such requests by confirming payment
            requests on the Executive Sheet. See <dfn>Executive
              Sheet - Element Annotation</dfn>.
          </td>
        </tr>
            <tr>
          <td>
            <dfn>Prime Delegates Must Stake Their AD Buffer To Trigger Weekly Cycle Proposals</dfn>
          </td>
          <td>Prime Delegates Must Stake Their AD Buffer To Trigger Weekly Cycle Proposals</td>
          <td>Action Tenet</td>
          <td>
            To deter spurious or misaligned proposals, Prime Delegates must “stake” their AD Buffer to trigger a 
            Proposal. A Prime Delegate can trigger a Weekly Cycle Proposal only if their AD Buffer contains at least 
            one (1) month’s worth of budget at the time of triggering the Proposal. This “staking” requirement of one 
            month’s worth of budget remains in effect until the triggered Proposal is fully resolved - that is, until 
            either (1) the Proposal is rejected by the Governance Facilitators for misalignment, or (2) a Sky Governance 
            vote on the Proposal concludes in an approval or rejection. If the Proposal is voted down or rejected for 
            misalignment, the PD will lose their entire AD Buffer</dfn>.
          </td>
       </tr>
            <tr>
          <td>
            <dfn>Prime Delegate Loss Of Rank After Triggering Proposal Is Inconsequential </dfn>
          </td>
          <td>Prime Delegate Loss Of Rank After Triggering Proposal Is Inconsequential </td>
          <td>Action Tenet</td>
          <td>
            A Weekly Cycle Proposal is considered correctly triggered when the triggering Aligned Delegate is a Prime Delegate 
            with at least one (1) month’s worth of budget in their AD Buffer at the time of triggering the Proposal. It is 
            inconsequential if, after triggering the Proposal, the Prime Delegate loses Prime Delegate rank.</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Unanimity
              Is Not Required To Block Proposal For Misalignment</dfn>
          </td>
          <td>Unanimity Is Not Required To Block Proposal For Misalignment</td>
          <td>Action Tenet</td>
          <td>Unanimity is not required among Governance Facilitators to block an Atlas Edit Weekly Cycle Proposal
            for misalignment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Useful
              - Whistleblower Evidence Must Have Material Impact</dfn>
          </td>
          <td>Useful - Whistleblower Evidence Must Have Material Impact</td>
          <td>Action Tenet</td>
          <td>The element "useful" means that the evidence provided by the whistleblower must have had a material
            impact on the adjudication. The term "material impact" here does not imply that the adjudication
            process would have been impossible to resolve without the whistleblower's evidence. Instead, the
            evidence provided by the whistleblower can still be considered "useful" or of "material impact" if
            it serves a supportive role in the adjudication, even if it does not play a central or decisive
            part. The evidence simply needs to contribute meaningfully to the investigation, regardless of the
            extent of its influence. The Governance Facilitators ultimately have broad discretion here in
            awarding the bounty.It is important to note that the payment of the whistleblower bounty is
            dependent on the outcome of the decision. If the Facilitators rule in favor of the AD, the bounty
            should not be awarded. If the Facilitators rule against the AD, the bounty should be awarded if the
            whistleblower has responsibly submitted useful evidence.</td>
        </tr>
        <tr>
          <td>
            <dfn>Useful
              - Whistleblower Evidence Must Have Material Impact</dfn>
          </td>
          <td>Useful - Whistleblower Evidence Must Have Material Impact</td>
          <td>Action Tenet</td>
          <td>The element "useful" means that the evidence provided by the whistleblower must have had a material
            impact on the adjudication. The term "material impact" here does not imply that the adjudication
            process would have been impossible to resolve without the whistleblower's evidence. Instead, the
            evidence provided by the whistleblower can still be considered "useful" or of "material impact" if
            it serves a supportive role in the adjudication, even if it does not play a central or decisive
            part. The evidence simply needs to contribute meaningfully to the investigation, regardless of the
            extent of its influence. The Governance Facilitators ultimately have broad discretion here in
            awarding the bounty.It is important to note that the payment of the whistleblower bounty is
            dependent on the outcome of the decision. If the Facilitators rule in favor of the AD, the bounty
            should not be awarded. If the Facilitators rule against the AD, the bounty should be awarded if the
            whistleblower has responsibly submitted useful evidence.</td>
        </tr>
        <tr>
          <td>
            <dfn>Where
              Feasible - Governance Facilitators Have Discretion In Determining Whether Public Report Should
              Be Issued</dfn>
          </td>
          <td>Where Feasible - Governance Facilitators Have Discretion In Determining Whether Public Report Should
            Be Issued</td>
          <td>Action Tenet</td>
          <td>The element "where feasible" means that the Governance Facilitators have discretion to determine
            whether it is appropriate to issue a Public Report following an AC misalignment adjudication. Where
            an adjudication proceeding involves sensitive security matters or evidence, the Governance
            Facilitators have the option to defer from issuing a public report entirely; or to issue a report
            that excludes the sensitive security matters, while maintaining as much transparency as possible.
            The latter option should be preferred where possible.</td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="scenarios">
    <h1>Scenarios</h1>
    <table>
      <tr>
        <th>Doc No (or Temp Name)</th>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Finding</th>
        <th>Additional Guidance</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>Alternating
              between two roles in separate time intervals</dfn>
          </td>
          <td>Alternating between two roles in separate time intervals</td>
          <td>Scenario</td>
          <td>Entity occupied the role of a ranked Aligned Delegate. Entity then applied for, and secured, the
            role of a Facilitator. The entity actively occupied these two roles, but alternated between them in
            separate time intervals.</td>
          <td>Misaligned</td>
          <td>
            That Entity is alternating between two roles to perform their duties in separate time intervals does
            not negate the misalignment risk that the Target Document is intended to protect against. They are
            still formally occupying two roles at once. They still have access to sensitive information and
            experiences in two roles with different mandates and incentives.The Facilitator should derecognize
            Entity per <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Extended
              leave of absence</dfn>
          </td>
          <td>Extended leave of absence</td>
          <td>Scenario</td>
          <td>Entity occupied the role of a Facilitator. They took a leave of absence from the Facilitator role
            and stepped into the role of a Stability Scope Advisor. At the time their behavior was discovered by
            another Facilitator, the Entity had been performing solely in the role of a Stability Scope Advisor,
            while remaining on a leave of absence from their Facilitator role.</td>
          <td>Misaligned</td>
          <td>
            If an actor assumes more than one role in the Sky ecosystem, the risks of conflict of interest,
            collusion, conspiracy and other misaligned behavior necessarily arises. That the Entity was on a
            leave of absence from one role does not negate this risk. A contributor on an extended leave of
            absence has not formally cut ties with the role. Entity is still formally occupying two roles with
            different mandates, incentives and access/permissions. It is conceivable that Entity's Stability
            Scope Advisor work could be compromised or influenced, even in subtle ways, by the experiences,
            knowledge and biases to which Entity is exposed as a Facilitator. Therefore, the risk of
            misalignment, which the Target Document aims to guard against, remains present.The Facilitator
            should derecognize Entity from the Facilitator role per <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</dfn>.The
            Facilitator should likely consider derecognizing Entity from the Stability Scope Advisor role. No
            specific logic exists as yet for the adjudication of misalignment on the part of a Scope Advisor.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>On-call
              or stand-by role</dfn>
          </td>
          <td>On-call or stand-by role</td>
          <td>Scenario</td>
          <td>Entity was an Aligned Delegate. Entity then secured a second role with an Ecosystem Actor providing
            Executive spell crafting services, specifically as an "on call" dev. Entity claims it has never been
            on active duty in the second role; rather, they have only ever been on "standby" in that role. Thus,
            Entity argued it did not violate the Target Document despite holding two ecosystem roles.</td>
          <td>Misaligned</td>
          <td>
            If an actor assumes more than one role in the Sky ecosystem, the risks of conflict of interest,
            collusion, conspiracy and other misaligned behavior necessarily arises. That the Entity's second
            position is in an "on-call" or stand-by position does not negate this risk. Entity is still formally
            occupying two roles with different mandates, incentives and access/permissions. It is conceivable
            that Entity's decisionmaking in their first role could be compromised or influenced, even in subtle
            ways, by the experiences, knowledge and biases to which Entity is exposed in their second role.
            Therefore, the risk of misalignment, which the Target Document aims to guard against, remains
            present.The Facilitator should derecognize Entity as an AD per <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</dfn>.No
            specific logic exists as yet for the adjudication of misalignment on the part of an Ecosystem Actor
            team member.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Resignation
              notice not received</dfn>
          </td>
          <td>Resignation notice not received</td>
          <td>Scenario</td>
          <td>Entity was a full-time team member of a Governance Facilitator. Entity emailed the Facilitator a
            formal letter of resignation and then transitioned into the role of an AD. The Facilitator did not
            receive the resignation email and continued to list Entity as an active team member on the
            Facilitator team. During the Governance Facilitator's investigation, Entity provided proof of the
            resignation email. The email clearly stated an effective date of resignation, which date was prior
            to Entity's transition into the AD role. Entity also provided proof that all their permissions to
            the Facilitator team workspace were revoked; and they had no further communications or interactions
            with the Facilitator team after their intended resignation date.</td>
          <td>Aligned</td>
          <td>Though the Facilitator incorrectly continued to list Entity as a team member, in actual practice,
            Entity had cut all ties with the Facilitator team after the intended resignation date. This was
            proven via the dated resignation email; the revoked permissions; and the lack of communications.
            Given these facts, the Target Document is not triggered.</td>
        </tr>
        <tr>
          <td>
            <dfn>Volunteer
              Discord moderator</dfn>
          </td>
          <td>Volunteer Discord moderator</td>
          <td>Scenario</td>
          <td>Entity was a volunteer moderator for Sky's Discord. Without leaving their moderator role, Entity
            registered and became active as an Aligned Delegate.</td>
          <td>Aligned</td>
          <td>'Volunteer Discord moderator' is not a role that is formally defined in the Atlas. Therefore,
            Entity's first position as volunteer Discord moderator does not count as an ecosystem role. The
            Target Document is not triggered at all in this Scenario.</td>
        </tr>
        <tr>
          <td>
            <dfn>Delay In Payment To Prime Delegate Triggering Proposal</dfn>
          </td>
          <td>Delay In Payment To Prime Delegate Triggering Proposal</td>
          <td>Scenario</td>
          <td>Entity is a Prime Delegate with one (1) month’s worth of budget in their AD Buffer. Entity triggers 
            a Weekly Cycle Proposal. Immediately thereafter, Entity loses their Prime Delegate rank. Three days later, 
            before the Proposal has been voted on, the Governance Facilitators distribute compensation to other 
            Aligned Delegates but do not distribute compensation to Entity.</td>
          <td>Aligned</td>
          <td>Paying out the AD Buffer would have led to Entity’s AD Buffer dropping below the required threshold of 
            one (1) month’s worth of budget while the Proposal was still unresolved. In this Scenario, the triggering 
            AD cannot receive payout from the AD Buffer until the triggered Proposal is voted on and approved by Sky 
            Governance. Assuming that the Proposal is approved, the Governance Facilitators are authorized to disburse 
            the entire contents of the AD Buffer to the triggering AD in the next AD compensation cycle. However, if 
            the Proposal is rejected by the Governance Facilitators for misalignment or voted down by Sky Governance, 
            the triggering AD would lose their entire AD Buffer.</td>
        </tr>
             <tr>
          <td>
            <dfn>Prime Delegate Triggers Proposal And Loses Prime Delegate Rank Immediately Thereafter</dfn>
          </td>
          <td>Prime Delegate Triggers Proposal And Loses Prime Delegate Rank Immediately Thereafter</td>
          <td>Scenario</td>
          <td>Entity is a Prime Delegate with at least one (1) month’s worth of budget in their AD Buffer. Entity triggers 
            a Weekly Cycle Proposal. Immediately thereafter, Entity loses their Prime Delegate rank. The Governance Facilitators 
            continue to prepare a Governance Poll for the Proposal.</td>
          <td>Aligned as to Entity. Aligned as to the Governance Facilitators.</td>
          <td>The fact that Entity lost their Prime Delegate rank after triggering the Proposal is inconsequential. Entity satisfied 
            the requirement of being a Prime Delegate with at least one (1) month’s worth of budget in their AD Buffer at the time 
            of triggering the Proposal, and thus the Proposal was properly triggered. The Governance Facilitators acted correctly 
            to prepare a Governance Poll for the Proposal in accord with the process definition for the Atlas Edit Weekly Cycle.</td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="scenario-variations">
    <h1>Scenario Variations</h1>
    <table>
      <tr>
        <th>Doc No</th>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Finding</th>
        <th>Additional Guidance</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>Alternating
              between two roles in separate time intervals - var. 1</dfn>
          </td>
          <td>Alternating between two roles in separate time intervals - var. 1</td>
          <td>Scenario Variation</td>
          <td>Entity occupied the role of an unranked Aligned Delegate. Entity then applied for, and secured, the
            role of a Facilitator. Entity actively occupied these two roles, but alternated between them in
            separate time intervals.</td>
          <td>Misaligned</td>
          <td>
            An "ecosystem role" need not be compensated or full-time to be regulated by the Target Document. See
            <dfn>Other
              Ecosystem Roles - Ecosystem Role need not be compensated or full-time to be regulated under
              Target Document</dfn>.An unranked, uncompensated Aligned Delegate is nevertheless an 'ecosystem
            role' in the sense of the Target Document. Notwithstanding being unranked and uncompensated, the AD
            role still carries with it a mandate and array of incentives that are distinct from those of a
            Facilitator.The Facilitator should derecognize Entity from both AC roles per <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>On-call
              or standby role - var. 1</dfn>
          </td>
          <td>On-call or standby role - var. 1</td>
          <td>Scenario Variation</td>
          <td>Entity was an Aligned Delegate. Entity then secured a second role with an Ecosystem Actor providing
            Executive spell crafting services, specifically as an "on call" dev. Entity claims it has never been
            on active duty in the second role; rather, they have only ever been on "standby" in that role. Thus,
            Entity argued it did not violate the Target Document despite holding two ecosystem roles. During its
            investigation, the Facilitator discovered evidence that, despite the EA having a general policy that
            "on call" devs are paid only a nominal fee for the bounded time periods they are on call, Entity had
            been receiving an inordinately large compensation from the EA. When the Facilitator pressed both the
            EA and Entity for an explanation, none was given.</td>
          <td>Misaligned as to Entity.</td>
          <td>
            In contrast to the original Scenario, the Facilitator uncovered evidence that indicates Entity was
            not, as claimed, a mere "on call" dev, but rather was engaged in substantive work to justify the
            large compensation amount. That the Facilitator was stonewalled in its investigation also is a
            strong indication of malign intent on the part of Entity and the EA. Yet, there is no concrete proof
            of this. Under these circumstances, it is reasonable to extrapolate that derecognition from the AC
            role would suffice, per <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</dfn>.The
            concern remains that, potentially, a bad actor can continue to exploit the ecosystem, especially if
            other ecosystem participants are not aware of their questionable history. To mitigate this risk, the
            Facilitator can include details about the evidence it discovered in its formal derecognition notice,
            which can impact the reputation score of Entity.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Resignation
              notice not received - var. 1</dfn>
          </td>
          <td>Resignation notice not received - var. 1</td>
          <td>Scenario Variation</td>
          <td>Entity was a part-time team member of a Governance Facilitator. Entity then transitioned into the
            role of an AD. The Facilitator did not receive any resignation notice from Entity and continued to
            list Entity as an active team member on the Facilitator team. During the Governance Facilitor's
            investigation, Entity claimed it had sent the Facilitator a resignation email, but could not provide
            actual proof of this. The Governance Facilitator also discovered that Entity still had permissions
            to the Facilitator team workspace. The team's Discord contained casual, non-work related
            interactions between Entity and the Facilitator team members even after the date Entity became a
            formally recognized AD.</td>
          <td>Misaligned</td>
          <td>
            Entity was unable to provide any proof that it had formally resigned its first role with the
            Facilitator team. Merely claiming that a resignation email was sent is not sufficient. Further,
            unlike the original Scenario, Entity in this Variation continued to have access to the Facilitator
            team workspace even after the alleged date of resignation. Technically speaking, Entity is still
            formally occupying two roles with different mandates and incentives. The potential exists for
            conflict of interest, collusion, etc. The part-time role does not impact this analysis.The
            Governance Facilitator should derecognize Entity from its AD role per <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - AC Derecognition</dfn>.
          </td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="needed-research">
    <h1>Needed Research</h1>
    <table>
      <tr>
        <th>Doc No</th>
        <th>Name</th>
        <th>Type</th>
        <th>Research Prompt</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>AD
              Budget Management</dfn>
          </td>
          <td>AD Budget Management</td>
          <td>Needed Research</td>
          <td>Are there risks that should be considered regarding the potential mismanagement or misuse of the AD
            budget? The Target Document lists several examples of permissible ways to use the AD budget, which
            indicates implicitly constraints, or disallowed expenditures. How would compliance with these
            guidelines be monitored?</td>
        </tr>
        <tr>
          <td>
            <dfn>AD
              Whistleblower Bounty</dfn>
          </td>
          <td>Responsible Provision of Evidence</td>
          <td>Needed Research</td>
          <td>The element "responsibly provided" in the Target Documents means that whistleblower evidence must
            have been secured ethically, i.e., publicly available blockchain data. This generally means, no
            hacking or unauthorized access to systems, or breaches of data protection laws. Do challenging gray
            areas remain? What sort of standards or criteria should be met by whistleblower evidence to be
            considered responsibly gathered? For instance, is evidence gathered from private communication
            channels considered responsibly obtained if it was leaked to the whistleblower by an insider? How do
            we handle situations where the evidence is obtained through methods that might be legal but are
            still ethically questionable? And what sort of standards/criteria should be met by whistleblower
            evidence to be credible and useful in an investigation? How to assess the credibility or probative
            value of evidence, especially when dealing with blockchain data, which can be complex and difficult
            to interpret? What standards of proof should be required for evidence to be considered credible,
            particularly in cases where the evidence is circumstantial rather than direct? Perhaps this is
            already answered by current logic that demands that Facilitators apply the highest standards of
            Universal Alignment to AC adjudications, without affording benefit of the doubt.What are the
            expectations placed on Facilitators to verify whistleblower evidence?</td>
        </tr>
        <tr>
          <td>
            <dfn>AD
              Whistleblower Bounty</dfn>
          </td>
          <td>Responsible Provision of Evidence</td>
          <td>Needed Research</td>
          <td>The element "responsibly provided" in the Target Documents means that whistleblower evidence must
            have been secured ethically, i.e., publicly available blockchain data. This generally means, no
            hacking or unauthorized access to systems, or breaches of data protection laws. Do challenging gray
            areas remain? What sort of standards or criteria should be met by whistleblower evidence to be
            considered responsibly gathered? For instance, is evidence gathered from private communication
            channels considered responsibly obtained if it was leaked to the whistleblower by an insider? How do
            we handle situations where the evidence is obtained through methods that might be legal but are
            still ethically questionable? And what sort of standards/criteria should be met by whistleblower
            evidence to be credible and useful in an investigation? How to assess the credibility or probative
            value of evidence, especially when dealing with blockchain data, which can be complex and difficult
            to interpret? What standards of proof should be required for evidence to be considered credible,
            particularly in cases where the evidence is circumstantial rather than direct? Perhaps this is
            already answered by current logic that demands that Facilitators apply the highest standards of
            Universal Alignment to AC adjudications, without affording benefit of the doubt.What are the
            expectations placed on Facilitators to verify whistleblower evidence?</td>
        </tr>
        <tr>
          <td>
            <dfn>AD
              Whistleblower Bounty</dfn>
          </td>
          <td>Responsible Provision of Evidence</td>
          <td>Needed Research</td>
          <td>The element "responsibly provided" in the Target Documents means that whistleblower evidence must
            have been secured ethically, i.e., publicly available blockchain data. This generally means, no
            hacking or unauthorized access to systems, or breaches of data protection laws. Do challenging gray
            areas remain? What sort of standards or criteria should be met by whistleblower evidence to be
            considered responsibly gathered? For instance, is evidence gathered from private communication
            channels considered responsibly obtained if it was leaked to the whistleblower by an insider? How do
            we handle situations where the evidence is obtained through methods that might be legal but are
            still ethically questionable? And what sort of standards/criteria should be met by whistleblower
            evidence to be credible and useful in an investigation? How to assess the credibility or probative
            value of evidence, especially when dealing with blockchain data, which can be complex and difficult
            to interpret? What standards of proof should be required for evidence to be considered credible,
            particularly in cases where the evidence is circumstantial rather than direct? Perhaps this is
            already answered by current logic that demands that Facilitators apply the highest standards of
            Universal Alignment to AC adjudications, without affording benefit of the doubt.What are the
            expectations placed on Facilitators to verify whistleblower evidence?</td>
        </tr>
        <tr>
          <td>
            <dfn>Addressing
              Misalignment Of Ecosystem Actors Or Other Governance Participants</dfn>
          </td>
          <td>Addressing Misalignment Of Ecosystem Actors Or Other Governance Participants</td>
          <td>Needed Research</td>
          <td>Currently, the Atlas specifies an adjudication process for Alignment Conserver misalignment or
            breach of operational security. Research is needed to consider a process by which Facilitators
            investigate and adjudicate suspected misalignment on the part of Ecosystem Actors or other
            governance participants.</td>
        </tr>
        <tr>
          <td>
            <dfn>Conflicting
              Atlas Edit Proposals</dfn>
          </td>
          <td>Conflicting Atlas Edit Proposals</td>
          <td>Needed Research</td>
          <td>This is an extensive Research Track. Some critical questions to be explored:What criteria should be
            used to determine when two or more Atlas Edit Proposals are in conflict? Are conflicts strictly
            based on overlapping content, or do broader thematic or operational conflicts also count?For
            instance: if two AEPs amend different sections of the Atlas but have implications that could lead to
            contradictory outcomes, how should the Governance Facilitators identify and address this indirect
            conflict?What if one AEP effects a significant overhaul of an Atlas document, while another effects
            minor tweaks to the same component? How do the Facilitators determine which elements of which AEP
            should take precedence?If one AEP drew more support than the other, does this automatically mean the
            former is the best update? What if the former AEP was authored by an unknown author, while the
            second AEP was authored by a well-known community member with high reputation?If merging proposals
            in this fashion becomes a common practice, what issues could arise? There is a risk of governance
            paralysis, where no significant progress can be made because of a loop of constant revisions and
            counter-revisions. Community fatigue could set in, where stakeholders become disengaged from the
            governance process due to the perception that decisions are never final. The continuous cycle of
            evaluating, merging, and discarding parts of conflicting AEPs is not only time-consuming but also
            increases the complexity of governance operations.If the Governance Facilitators merge parts of two
            approved, but conflicting AEPs, and the final merged product significantly deviates from the
            original intents of both, the representation of SKY voters' will becomes a compelling question.</td>
        </tr>
        <tr>
          <td>
            <dfn>Criteria
              For AD Voting-Communication Requirement</dfn>
          </td>
          <td>Criteria For Voting-Communication Requirement</td>
          <td>Needed Research</td>
          <td>For the purpose of enforcing the Target Document, should there be explicit criteria for Aligned
            Delegates' voting-communications? What constitutes an adequate explanation for each vote? How would
            Governance Facilitators evaluate ADs' explanations for quality, completeness, etc.? How can
            Governance Facilitators objectively assess explanations that may vary widely in style and
            content?How might ADs' explanations vary across different types of votes, and should the criteria
            reflect these differences? Should more complex or high-stakes votes require more detailed
            explanations than routine or procedural votes?What feedback mechanisms should be in place to help
            ADs improve their explanations?What are the risks of not having explicit criteria for
            voting-communications? One is the potential failure of the Target Document's objective to ensure
            that ADs' voting activity is transparent to SKY holders who have delegated to that AD.</td>
        </tr>
        <tr>
          <td>
            <dfn>Defining
              "severe actions or violations" and "governance attack"</dfn>
          </td>
          <td>Defining "severe actions or violations" and "governance attack"</td>
          <td>Needed Research</td>
          <td>What specific criteria or actions qualify as "severe" enough to warrant derecognition? Develop clear
            guidelines that define what constitutes a "severe case" in the context of misaligned actions. This
            involves identifying key indicators of severity, such as the magnitude of the impact, the intent
            behind the actions, and the potential or actual harm caused.Also needed: What actions or behaviors
            specifically constitute a "Governance Attack"? Can you propose criteria or frameworks for assessing
            intent, the scope of actions, and their potential consequences? The research can perhaps explore how
            different governance models define and respond to attacks and consider psychological, legal, and
            operational perspectives to support a more fact-driven interpretive approach.</td>
        </tr>
        <tr>
          <td>
            <dfn>Defining
              threshold for "very mild slippery slope" breaches</dfn>
          </td>
          <td>Defining threshold for "very mild slippery slope" breaches</td>
          <td>Needed Research</td>
          <td>What specific actions or omissions qualify as "very mild slippery slope" breaches? Helpful research
            can include: developing a set of criteria or a checklist that defines what constitutes a "very mild
            slippery slope" breach. This could involve an analysis of past or hypothetical incidents,
            consultations with the Facilitators, etc. Such guidelines are likely needed to help Facilitators
            reliably determine whether an act should be classified as a 'minor' slippery slope infraction or a
            more severe act which would merit derecognition.</td>
        </tr>
        <tr>
          <td>
            <dfn>Derecognition
              Procedure</dfn>
          </td>
          <td>Derecognition Procedure</td>
          <td>Needed Research</td>
          <td>Research specific procedural steps for the derecognition of an AC. The procedure should account for
            ways in which this process can be streamlined or standardized to ensure swift action. Research
            should identify potential bottlenecks and suggest ways to eliminate them, such as pre-defined
            decision-making protocols, clear documentation requirements, and fast-track procedures for urgent
            cases.Another point to research involves the concepts of due process or fairness. Specific logic
            currently active in the Atlas clearly indicates that ACs are held to the highest standards of
            Universal Alignment. Such a standard would seem to indicate that "fairness" is not an objective in
            any proceeding involving AC derecognition. What are the arguments for and against this?</td>
        </tr>
        <tr>
          <td>
            <dfn>Derecognition
              Uncertainty Due To Anonymous Actors</dfn>
          </td>
          <td>Derecognition Uncertainty Due To Anonymous Actors</td>
          <td>Needed Research</td>
          <td>The Target Document defines the act of derecognition as "permanently removing" an entity from the
            Alignment Conserver role. In fact, it is not possible to effect such a permanent removal. Given the
            presence of anonymous/pseudonymous actors in the decentralized "workforce" of the Sky ecosystem, a
            known identity of an actor can be barred from an AC role; and yet that actor can easily re-enter the
            system under a different pseudonym or identity. Consider what measures can be implemented to
            counteract the scenario where derecognized entities reappear under a different guise. A robust
            reputation system is already planned; by tracking reputation that is earned over a long timescale, a
            derecognized entity would be barred from quickly regaining a foothold.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational
              Security Protocols - Research Track</dfn>
          </td>
          <td>Operational Security Protocols Research Track</td>
          <td>Needed Research</td>
          <td>
            Governance Facilitators may not have the needed experience and skills to adjudicate matters
            involving operational security best practices. See Endgame Edge Governance Facilitator team Forum
            post (<a
              href="https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532#proposal-for-community-discussion-2">https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532#proposal-for-community-discussion-2</a>)
            on AD derecognition: "The DAO could hire a security advisor firm/consultant as a Scope Advisor.
            (This could fall under the Governance Scope and its requirement for Governance Security processes.)
            Their task would be to thoroughly analyze the security needs and risks of the Alignment Conservers
            and develop ever-evolving Operational Security "Best Practices."With an explicit framework of
            agreed-upon Best Practices, all anon Alignment Conservers have a known target to meet. Further, the
            existence of an objective framework of Best Practices equips the Governance Facilitators to easily
            determine when a breach of opsec best practice has occurred. The explicit framework removes the risk
            of the Facilitators inappropriately inserting subjective bias into the decisionmaking process.The
            Security Scope Advisor could also assist in reviewing an informant's evidence to evaluate its
            validity/quality. The Security Scope Advisor could ensure that the methods used by the informant to
            secure the evidence were ethical. (All communications, evidence and data shared with the Security
            Scope Advisor would be under confidentiality protection). Finally, such an Advisor would have
            specialized expertise in opsec and associated matters that Governance Facilitators lack."This Needed
            Research is an extensive Research Track, given the wide-ranging implications and potential
            mechanisms around opsec best practices, and also how these should map onto the Atlas.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Operational
              Security Protocols - Research Track</dfn>
          </td>
          <td>Operational Security Protocols Research Track</td>
          <td>Needed Research</td>
          <td>
            Governance Facilitators may not have the needed experience and skills to adjudicate matters
            involving operational security best practices. See Endgame Edge Governance Facilitator team Forum
            post (<a
              href="https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532#proposal-for-community-discussion-2">https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532#proposal-for-community-discussion-2</a>)
            on AD derecognition: "The DAO could hire a security advisor firm/consultant as a Scope Advisor.
            (This could fall under the Governance Scope and its requirement for Governance Security processes.)
            Their task would be to thoroughly analyze the security needs and risks of the Alignment Conservers
            and develop ever-evolving Operational Security "Best Practices."With an explicit framework of
            agreed-upon Best Practices, all anon Alignment Conservers have a known target to meet. Further, the
            existence of an objective framework of Best Practices equips the Governance Facilitators to easily
            determine when a breach of opsec best practice has occurred. The explicit framework removes the risk
            of the Facilitators inappropriately inserting subjective bias into the decisionmaking process.The
            Security Scope Advisor could also assist in reviewing an informant's evidence to evaluate its
            validity/quality. The Security Scope Advisor could ensure that the methods used by the informant to
            secure the evidence were ethical. (All communications, evidence and data shared with the Security
            Scope Advisor would be under confidentiality protection). Finally, such an Advisor would have
            specialized expertise in opsec and associated matters that Governance Facilitators lack."This Needed
            Research is an extensive Research Track, given the wide-ranging implications and potential
            mechanisms around opsec best practices, and also how these should map onto the Atlas.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Operational
              Security Protocols - Research Track</dfn>
          </td>
          <td>Operational Security Protocols Research Track</td>
          <td>Needed Research</td>
          <td>
            Governance Facilitators may not have the needed experience and skills to adjudicate matters
            involving operational security best practices. See Endgame Edge Governance Facilitator team Forum
            post (<a
              href="https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532#proposal-for-community-discussion-2">https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532#proposal-for-community-discussion-2</a>)
            on AD derecognition: "The DAO could hire a security advisor firm/consultant as a Scope Advisor.
            (This could fall under the Governance Scope and its requirement for Governance Security processes.)
            Their task would be to thoroughly analyze the security needs and risks of the Alignment Conservers
            and develop ever-evolving Operational Security "Best Practices."With an explicit framework of
            agreed-upon Best Practices, all anon Alignment Conservers have a known target to meet. Further, the
            existence of an objective framework of Best Practices equips the Governance Facilitators to easily
            determine when a breach of opsec best practice has occurred. The explicit framework removes the risk
            of the Facilitators inappropriately inserting subjective bias into the decisionmaking process.The
            Security Scope Advisor could also assist in reviewing an informant's evidence to evaluate its
            validity/quality. The Security Scope Advisor could ensure that the methods used by the informant to
            secure the evidence were ethical. (All communications, evidence and data shared with the Security
            Scope Advisor would be under confidentiality protection). Finally, such an Advisor would have
            specialized expertise in opsec and associated matters that Governance Facilitators lack."This Needed
            Research is an extensive Research Track, given the wide-ranging implications and potential
            mechanisms around opsec best practices, and also how these should map onto the Atlas.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Should
              ban against occupying two ecosystem roles apply to all Sky stakeholder roles?</dfn>
          </td>
          <td>Should ban against occupying two ecosystem roles apply to all Sky stakeholder roles?</td>
          <td>Needed Research</td>
          <td>
            Given the rationale behind the Target Document <dfn>A.1.4
              - Alignment Conservers - Powers And Constraints - ACs Can Be Operationally Active In Only One
              Role At A Time</dfn>, the 'simultaneous occupying of two ecosystem roles' prohibition should
            likely not be limited to just the AC stakeholder category, but rather should apply universally to
            any Sky stakeholder who occupies a role formally defined in the Atlas. What would be the
            arguments for and against such a position?
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Should
              team contributors be subject to the ban against occupying two ecosystem roles?</dfn>
          </td>
          <td>Should team contributors be subject to the ban against occupying 2 ecosystem roles?</td>
          <td>Needed Research</td>
          <td>Should team contributors be subject to the Target Document's prohibition against occupying two
            roles? What would be the arguments for and against such a position? One argument against this would
            be that quality contributors are a scarce resource. Further, the decentralized work paradigm
            encourages having several part-time jobs. The sharing of contributors across several Sky teams -
            such that contributors gain experience in multiple operational aspects - might arguably enhance
            ecosystem intelligence. Would it make a meaningful difference to require contributors who do wish to
            work multiple roles to be doxxed?</td>
        </tr>
        <tr>
          <td>
            <dfn>Systematic
              basis of adjudication, fact-finding and evidence</dfn>
          </td>
          <td>Systematic basis of adjudication, fact-finding and evidence</td>
          <td>Needed Research</td>
          <td>
            This need is an extensive Research Track. The central research need that grows out of the
            Facilitator role has to do with developing systematic principles and protocols to serve as the
            foundation for adjudicating disputes and controversies, including processes for fact-finding,
            evidence validation and evaluation, mechanisms for ensuring impartiality and objectivity, an appeals
            process, etc. The Atlas has made a good start with establishing an adjudication framework. There is
            some logic concerning procedures for how disputes and controversies (including Alignment Conserver
            misalignment) are brought forward and how they are reviewed. But essential elements are missing,
            such as protocols and standards for fact-finding and evidence. Needed Research here includes methods
            for implementing a structured fact-finding process that gathers relevant information impartially and
            comprehensively. Who has the authority to investigate, to request evidence, to handle evidence? What
            types of evidence are permissible to consider? See <dfn>Responsibly
              Provided - Whistleblower Evidence Of Misalignment Must Be Secured Ethically</dfn>. What are the
            processes for collecting, preserving, and analyzing this evidence? When should evidence be shared
            with the larger community and when should it be kept confidential? Then there is the matter of
            assessing evidence in a way that is rigorous and impartial, without which, confidence in the Atlas
            and the governance process may be undermined. What criteria should be used to validate and evaluate
            evidence to ensure its reliability and relevance in decision-making? This involves determining the
            credibility of sources, the reliability of evidence, and the relevance of information to the
            specific case. The research should explore different approaches to evidence evaluation, such as the
            application of the burden of proof, standards of proof (e.g., preponderance of evidence, beyond a
            reasonable doubt), and the use of experts. How much discretion should Facilitators have in
            interpreting and applying the element "the highest standard of Universal Alignment"? How to
            safeguard against bias and ensure all Facilitator adjudications are made impartially? Investigate
            mechanisms to maintain objectivity and impartiality throughout the adjudication, fact-finding, and
            evidence evaluation processes. This could include the establishment of independent review panels
            (which could operate post facto to avoid excessively delaying the deplatforming of misaligned ACs),
            the use of conflict-of-interest policies, and training on cognitive biases for those involved in
            decision-making.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Systematic
              basis of adjudication, fact-finding and evidence</dfn>
          </td>
          <td>Systematic basis of adjudication, fact-finding and evidence</td>
          <td>Needed Research</td>
          <td>
            This need is an extensive Research Track. The central research need that grows out of the
            Facilitator role has to do with developing systematic principles and protocols to serve as the
            foundation for adjudicating disputes and controversies, including processes for fact-finding,
            evidence validation and evaluation, mechanisms for ensuring impartiality and objectivity, an appeals
            process, etc. The Atlas has made a good start with establishing an adjudication framework. There is
            some logic concerning procedures for how disputes and controversies (including Alignment Conserver
            misalignment) are brought forward and how they are reviewed. But essential elements are missing,
            such as protocols and standards for fact-finding and evidence. Needed Research here includes methods
            for implementing a structured fact-finding process that gathers relevant information impartially and
            comprehensively. Who has the authority to investigate, to request evidence, to handle evidence? What
            types of evidence are permissible to consider? See <dfn>Responsibly
              Provided - Whistleblower Evidence Of Misalignment Must Be Secured Ethically</dfn>. What are the
            processes for collecting, preserving, and analyzing this evidence? When should evidence be shared
            with the larger community and when should it be kept confidential? Then there is the matter of
            assessing evidence in a way that is rigorous and impartial, without which, confidence in the Atlas
            and the governance process may be undermined. What criteria should be used to validate and evaluate
            evidence to ensure its reliability and relevance in decision-making? This involves determining the
            credibility of sources, the reliability of evidence, and the relevance of information to the
            specific case. The research should explore different approaches to evidence evaluation, such as the
            application of the burden of proof, standards of proof (e.g., preponderance of evidence, beyond a
            reasonable doubt), and the use of experts. How much discretion should Facilitators have in
            interpreting and applying the element "the highest standard of Universal Alignment"? How to
            safeguard against bias and ensure all Facilitator adjudications are made impartially? Investigate
            mechanisms to maintain objectivity and impartiality throughout the adjudication, fact-finding, and
            evidence evaluation processes. This could include the establishment of independent review panels
            (which could operate post facto to avoid excessively delaying the deplatforming of misaligned ACs),
            the use of conflict-of-interest policies, and training on cognitive biases for those involved in
            decision-making.
          </td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="active-data">
    <h1>Active Data</h1>
    <table>
      <tr>
        <th>Doc No</th>
        <th>Name</th>
        <th>Type</th>
        <th>Content</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>A.1.1
              - Spirit Of The Atlas - List Of Interpretations - Atlas Interpretations</dfn>
          </td>
          <td>Spirit Of The Atlas - List Of Interpretations - Atlas Interpretations</td>
          <td>Active Data</td>
          <td>List of Atlas Interpretations:• Payments denominated in SKY in the Atlas will be made in MKR prior
            to the launch of SKY at the proscribed conversion rate listed in the Atlas.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - Derecognized Alignment
              Conservers</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - Derecognized Alignment Conservers
          </td>
          <td>Active Data</td>
          <td>
            | Date | Conserver Role | Identity | Known Aliases | Reasoning Post |
            |------------|----------------|------------|---------------|-----------------------------------------------------------------------------------------------------------------|
            | 2023-06-08 | AD | Bulwark | - | <a
              href="https://forum.makerdao.com/t/notice-aligned-delegate-derecognition-and-avc-member-warning/21099">https://forum.makerdao.com/t/notice-aligned-delegate-derecognition-and-avc-member-warning/21099</a>
            | | 2023-10-30 | AD | PALC | - | <a
              href="https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532">https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532</a>
            | | 2023-10-30 | AD | Navigator | - | <a
              href="https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532">https://forum.makerdao.com/t/ads-derecognition-due-to-operational-security-breach/22532</a>
            | | 2023-02-02 | AD | 0xDefensor | - | <a
              href="https://forum.makerdao.com/t/ad-derecognition-due-to-operational-security-breach-02-02-2024/23619">https://forum.makerdao.com/t/ad-derecognition-due-to-operational-security-breach-02-02-2024/23619</a>
            | | 2024-04-06 | AD | TRUE NAME | - | <a
              href="https://forum.makerdao.com/t/ad-derecognition-due-to-operational-security-breach-april-5-2024/24043">https://forum.makerdao.com/t/ad-derecognition-due-to-operational-security-breach-april-5-2024/24043</a>
            | | 2024-12-17 | AD | UPMaker | - | <a
              href="https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718">https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718</a>
            | | 2024-12-17 | AD | QGov | - | <a
              href="https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718">https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718</a>
            | | 2024-12-17 | AD | Skynet | - | <a
              href="https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718">https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718</a>
            | | 2024-12-17 | AD | Pf | - | <a
              href="https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718">https://forum.sky.money/t/derecognition-notice-for-multiple-aligned-delegates/25718</a>
            |
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.4
              - Alignment Conservers - Accountability And Misalignment Handling - List of Formally Warned
              Alignment Conservers</dfn>
          </td>
          <td>Alignment Conservers - Accountability And Misalignment Handling - List of Formally Warned Alignment
            Conservers</td>
          <td>Active Data</td>
          <td>
            | Date | Conserver Role | Identity | Known Aliases | Reasoning Post |
            |------------|----------------|-----------------------|---------------|-----------------------------------------------------------------------------------------------------------------|
            | 2023-06-08 | AVC Member | HKUST_EPI_BLOCKCHAIN | - | <a
              href="https://forum.makerdao.com/t/notice-aligned-delegate-derecognition-and-avc-member-warning/21099">https://forum.makerdao.com/t/notice-aligned-delegate-derecognition-and-avc-member-warning/21099</a>
            | | 2024-04-06 | AVC Member | ACRE DAOs | - | <a
              href="https://forum.makerdao.com/t/ad-derecognition-due-to-operational-security-breach-april-5-2024/24043">https://forum.makerdao.com/t/ad-derecognition-due-to-operational-security-breach-april-5-2024/24043</a>
            |
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.1.5
              - Aligned Delegates - Governance Facilitator Responsibilities - Current Aligned Delegates</dfn>
          </td>
          <td>Aligned Delegates - Governance Facilitator Responsibilities - Current Aligned Delegates</td>
          <td>Active Data</td>
          <td>
            | Delegate Name | EA Address | Delegation Contract | Forum Post || --------------- |
            ------------------------------------------------------------------------------------------------------------------------------------------------------------------
            |
            ------------------------------------------------------------------------------------------------------------------------------------------------------------------
            | --------------------------------------------------------------------------------- || Bonapublica | <a
              href="https://etherscan.io/address/0x167c1a762B08D7e78dbF8f24e5C3f1Ab415021D3">https://etherscan.io/address/0x167c1a762B08D7e78dbF8f24e5C3f1Ab415021D3</a>
            <a href="https://etherscan.io/verifySig/21271">https://etherscan.io/verifySig/21271</a> | <a
              href="https://etherscan.io/address/0xf1423F5A97940349E105B0D1C860D3dCE87E56dB">https://etherscan.io/address/0xf1423F5A97940349E105B0D1C860D3dCE87E56dB</a>
            <a href="https://etherscan.io/verifySig/259048">https://etherscan.io/verifySig/259048</a> | <a
              href="https://forum.makerdao.com/t/bonapublica-aligned-delegate-communication/20451/90">https://forum.makerdao.com/t/bonapublica-aligned-delegate-communication/20451/90</a>
            || PBG | <a
              href="https://etherscan.io/address/0x8D4df847dB7FfE0B46AF084fE031F7691C6478c2">https://etherscan.io/address/0x8D4df847dB7FfE0B46AF084fE031F7691C6478c2</a>
            <a href="https://etherscan.io/verifySig/16773">https://etherscan.io/verifySig/16773</a> | <a
              href="https://etherscan.io/address/0xCFE1c10B90dC49A063742b6eb29D1bDc7e722aa2">https://etherscan.io/address/0xCFE1c10B90dC49A063742b6eb29D1bDc7e722aa2</a>
            <a href="https://etherscan.io/verifySig/259576">https://etherscan.io/verifySig/259576</a> | <a
              href="https://forum.makerdao.com/t/pbg-aligned-delegate-communication-platform/20471/69">https://forum.makerdao.com/t/pbg-aligned-delegate-communication-platform/20471/69</a>
            || WBC | <a
              href="https://etherscan.io/address/0xeBcE83e491947aDB1396Ee7E55d3c81414fB0D47">https://etherscan.io/address/0xeBcE83e491947aDB1396Ee7E55d3c81414fB0D47</a>
            <a href="https://etherscan.io/verifySig/17927">https://etherscan.io/verifySig/17927</a> | <a
              href="https://etherscan.io/address/0xc139042755eae94bd10798251801b5bd26464b69">https://etherscan.io/address/0xc139042755eae94bd10798251801b5bd26464b69</a>
            <a href="https://etherscan.io/verifySig/253745">https://etherscan.io/verifySig/253745</a> | <a
              href="https://forum.makerdao.com/t/wbc-aligned-delegate-communications/20828">https://forum.makerdao.com/t/wbc-aligned-delegate-communications/20828</a>
            || BLUE | <a
              href="https://etherscan.io/address/0xb6c09680d822f162449cdfb8248a7d3fc26ec9bf">https://etherscan.io/address/0xb6c09680d822f162449cdfb8248a7d3fc26ec9bf</a>
            <a href="https://etherscan.io/verifySig/19057">https://etherscan.io/verifySig/19057</a> | <a
              href="https://etherscan.io/address/0xe1FF7ECf038900dd14A1E7E3a8CCF23f71f6A1c2">https://etherscan.io/address/0xe1FF7ECf038900dd14A1E7E3a8CCF23f71f6A1c2</a>
            <a href="https://etherscan.io/verifySig/258998">https://etherscan.io/verifySig/258998</a> | <a
              href="https://forum.makerdao.com/t/blue-ad-recognition-submission/20915">https://forum.makerdao.com/t/blue-ad-recognition-submission/20915</a>
            || JAG | <a
              href="https://etherscan.io/address/0x58d1ec57e4294e4fe650d1cb12b96ae34349556f">https://etherscan.io/address/0x58d1ec57e4294e4fe650d1cb12b96ae34349556f</a>
            <a
              href="https://etherscan.io/tx/0xcb017d31235abb7303c01169de358ffb1307c622994c802e1016dcdde8707164">https://etherscan.io/tx/0xcb017d31235abb7303c01169de358ffb1307c622994c802e1016dcdde8707164</a>
            | No active contract <a
              href="https://etherscan.io/tx/0xe195b455598d8ba6079af3654511474ce3b9c9cfeb5d7f942d3b80b3d5f83f20">https://etherscan.io/tx/0xe195b455598d8ba6079af3654511474ce3b9c9cfeb5d7f942d3b80b3d5f83f20</a>
            | <a
              href="https://forum.makerdao.com/t/jag-ad-delegate-submission/20972">https://forum.makerdao.com/t/jag-ad-delegate-submission/20972</a>
            || Cloaky | <a
              href="https://etherscan.io/address/0x9244F47D70587Fa2329B89B6f503022b63Ad54A5">https://etherscan.io/address/0x9244F47D70587Fa2329B89B6f503022b63Ad54A5</a>
            <a href="https://etherscan.io/verifySig/19712">https://etherscan.io/verifySig/19712</a> | <a
              href="https://etherscan.io/address/0xB02e05c257291aCD65A527227aCA6b7662E047f4">https://etherscan.io/address/0xB02e05c257291aCD65A527227aCA6b7662E047f4</a>
            <a href="https://etherscan.io/verifySig/258809">https://etherscan.io/verifySig/258809</a> | <a
              href="https://forum.makerdao.com/t/cloaky-ad-recognition-submission/21082">https://forum.makerdao.com/t/cloaky-ad-recognition-submission/21082</a>
            || Penguin Soldier | <a
              href="https://etherscan.io/address/0x41caF770eb0a9EeC0c9cC46F388ea5A76986E217">https://etherscan.io/address/0x41caF770eb0a9EeC0c9cC46F388ea5A76986E217</a>
            <a href="https://etherscan.io/verifySig/21884">https://etherscan.io/verifySig/21884</a> | <a
              href="https://etherscan.io/address/0x5b4870014313c808c374F8eD1AB5b78813EB9c7f">https://etherscan.io/address/0x5b4870014313c808c374F8eD1AB5b78813EB9c7f</a>
            <a href="https://etherscan.io/verifySig/25414">https://etherscan.io/verifySig/25414</a> | <a
              href="https://forum.makerdao.com/t/penguin-soldier-ad-recognition-submission/21395">https://forum.makerdao.com/t/penguin-soldier-ad-recognition-submission/21395</a>
            || Vision | <a
              href="https://etherscan.io/address/0xd21012e1fd245f6c25c0d527472fe42d2b78319f">https://etherscan.io/address/0xd21012e1fd245f6c25c0d527472fe42d2b78319f</a>
            <a href="https://etherscan.io/verifySig/23967">https://etherscan.io/verifySig/23967</a> | <a
              href="https://etherscan.io/address/0x3200c191Cc245b3E2de3FD3B3087104f3f313F57">https://etherscan.io/address/0x3200c191Cc245b3E2de3FD3B3087104f3f313F57</a>
            <a href="https://etherscan.io/verifySig/23965">https://etherscan.io/verifySig/23965</a> | <a
              href="https://forum.makerdao.com/t/vision-ad-recognition-submission/21777">https://forum.makerdao.com/t/vision-ad-recognition-submission/21777</a>
            || Nimsen | <a
              href="https://etherscan.io/address/0x1331bFCc9496f2F73500a4dA1eAbEA324517889D">https://etherscan.io/address/0x1331bFCc9496f2F73500a4dA1eAbEA324517889D</a>
            <a href="https://etherscan.io/verifySig/24053">https://etherscan.io/verifySig/24053</a> | <a
              href="https://etherscan.io/address/0xA2C669dc868be0A2a8D6C0ad715e17F45035BA76">https://etherscan.io/address/0xA2C669dc868be0A2a8D6C0ad715e17F45035BA76</a>
            <a href="https://etherscan.io/verifySig/24052">https://etherscan.io/verifySig/24052</a> | <a
              href="http://forum.makerdao.com/t/nimsen-ad-recognition-submission/21794">http://forum.makerdao.com/t/nimsen-ad-recognition-submission/21794</a>
            || Ikagai | <a
              href="https://etherscan.io/address/0x10078652eAB484c622030db7b4985BdccC626E99">https://etherscan.io/address/0x10078652eAB484c622030db7b4985BdccC626E99</a>
            <a href="https://etherscan.io/verifySig/24838">https://etherscan.io/verifySig/24838</a> | No active
            contract <a href="https://etherscan.io/verifySig/24836">https://etherscan.io/verifySig/24836</a> |
            <a
              href="https://forum.makerdao.com/t/ikagai-ad-recognition-submission/22124">https://forum.makerdao.com/t/ikagai-ad-recognition-submission/22124</a>
            || Byteron | <a
              href="https://etherscan.io/address/0xc2982e72D060cab2387Dba96b846acb8c96EfF66">https://etherscan.io/address/0xc2982e72D060cab2387Dba96b846acb8c96EfF66</a>
            <a href="https://etherscan.io/verifySig/27074">https://etherscan.io/verifySig/27074</a> | <a
              href="https://etherscan.io/address/0x6276e3d47cce873400d4ba3664bfb4b9c8ece79c">https://etherscan.io/address/0x6276e3d47cce873400d4ba3664bfb4b9c8ece79c</a>
            <a href="https://etherscan.io/verifySig/259643">https://etherscan.io/verifySig/259643</a> | <a
              href="https://forum.makerdao.com/t/byteron-ad-recognition-submission/22537">https://forum.makerdao.com/t/byteron-ad-recognition-submission/22537</a>
            || Shanah | <a
              href="https://etherscan.io/address/0xc9a0D0b89A74F7D9F229F9195c7fD7f7E09C127E">https://etherscan.io/address/0xc9a0D0b89A74F7D9F229F9195c7fD7f7E09C127E</a>
            <a href="https://etherscan.io/verifySig/25421">https://etherscan.io/verifySig/25421</a> | <a
              href="https://etherscan.io/address/0xdbb451BFd4e6E461caa2C8bf0dC83346A211c29C">https://etherscan.io/address/0xdbb451BFd4e6E461caa2C8bf0dC83346A211c29C</a>
            <a href="https://etherscan.io/verifySig/25421">https://etherscan.io/verifySig/25421</a> | <a
              href="https://forum.makerdao.com/t/shanah-aligned-delegate-communications/22264">https://forum.makerdao.com/t/shanah-aligned-delegate-communications/22264</a>
            || Pipkin | <a
              href="https://etherscan.io/address/0x0E661eFE390aE39f90a58b04CF891044e56DEDB7">https://etherscan.io/address/0x0E661eFE390aE39f90a58b04CF891044e56DEDB7</a>
            <a
              href="https://etherscan.io/tx/0x99a7580b90425e54958f56bd56c2018042b0cdbe9de407d4f693409b166c4d2a">https://etherscan.io/tx/0x99a7580b90425e54958f56bd56c2018042b0cdbe9de407d4f693409b166c4d2a</a>
            | <a
              href="https://etherscan.io/address/0x45C52826EFA13A6DE713528BF42B520C9fA50081">https://etherscan.io/address/0x45C52826EFA13A6DE713528BF42B520C9fA50081</a>
            <a
              href="https://etherscan.io/tx/0x63e9e44ad849c806f870800898e76ee47f96982946c1b44e447667e7cdab67eb">https://etherscan.io/tx/0x63e9e44ad849c806f870800898e76ee47f96982946c1b44e447667e7cdab67eb</a>
            | <a
              href="https://forum.makerdao.com/t/pipkin-ad-recognition/23448">https://forum.makerdao.com/t/pipkin-ad-recognition/23448</a>
            || JuliaChang | <a
              href="https://etherscan.io/address/0x252abAEe2F4f4b8D39E5F12b163eDFb7fac7AED7">https://etherscan.io/address/0x252abAEe2F4f4b8D39E5F12b163eDFb7fac7AED7</a>
            <a href="https://etherscan.io/verifySig/34622">https://etherscan.io/verifySig/34622</a> | <a
              href="https://etherscan.io/address/0x5D4a96aFadb5505a8fF21ddeCa2Baf3A63301396">https://etherscan.io/address/0x5D4a96aFadb5505a8fF21ddeCa2Baf3A63301396</a>
            <a href="hhttps://etherscan.io/verifySig/259101">https://etherscan.io/verifySig/259101</a> | <a
              href="https://forum.makerdao.com/t/juliachang-ad-recognition-submission/23507">https://forum.makerdao.com/t/juliachang-ad-recognition-submission/23507</a>
            || StoneWill | <a
              href="https://etherscan.io/address/0x72779c76bcC8DF6B7082f736f2C2BFba2db588f3">https://etherscan.io/address/0x72779c76bcC8DF6B7082f736f2C2BFba2db588f3</a>
            <a href="https://etherscan.io/verifySig/37256">https://etherscan.io/verifySig/37256</a> | <a
              href="https://etherscan.io/address/0x911682CB21d7e5bdc75544fB1FCf0Fb8E9635AcF">https://etherscan.io/address/0x911682CB21d7e5bdc75544fB1FCf0Fb8E9635AcF</a>
            <a href="https://etherscan.io/verifySig/37253">https://etherscan.io/verifySig/37253</a> | <a
              href="https://forum.makerdao.com/t/stonewill-ad-recognition-submission/23782">https://forum.makerdao.com/t/stonewill-ad-recognition-submission/23782</a>
            || Rocky | <a
              href="https://etherscan.io/address/0xc31637bda32a0811e39456a59022d2c386cb2c85">https://etherscan.io/address/0xc31637bda32a0811e39456a59022d2c386cb2c85</a>
            <a href="https://etherscan.io/verifySig/40946">https://etherscan.io/verifySig/40946</a> | <a
              href="https://etherscan.io/address/0x5FaC03E07447C1A3f4aD9A5f778f23C9e1fC4255">https://etherscan.io/address/0x5FaC03E07447C1A3f4aD9A5f778f23C9e1fC4255</a>
            <a href="https://etherscan.io/verifySig/40939">https://etherscan.io/verifySig/40939</a> | <a
              href="https://forum.makerdao.com/t/rocky-aligned-delegate-recognition-submission/24148">https://forum.makerdao.com/t/rocky-aligned-delegate-recognition-submission/24148</a>
            || Jiaozi | <a
              href="https://etherscan.io/address/0x774FB7955Ff69E5b8A5AFD0C0833B2719f7a2636">https://etherscan.io/address/0x774FB7955Ff69E5b8A5AFD0C0833B2719f7a2636</a>
            <a href="https://etherscan.io/verifySig/242924">https://etherscan.io/verifySig/242924</a> | <a
              href="https://etherscan.io/address/0xc1a1bdb7d60b7cb3920787a15a2b583786c52fb6">https://etherscan.io/address/0xc1a1bdb7d60b7cb3920787a15a2b583786c52fb6</a>
            <a href="https://etherscan.io/verifySig/243693">https://etherscan.io/verifySig/243693</a> | <a
              href="https://forum.makerdao.com/t/jiaozi-ad-recognition-submission/24374">https://forum.makerdao.com/t/jiaozi-ad-recognition-submission/24374</a>
            || AegisD | <a
              href="https://etherscan.io/address/0x78C180CF113Fe4845C325f44648b6567BC79d6E0">https://etherscan.io/address/0x78C180CF113Fe4845C325f44648b6567BC79d6E0</a>
            <a href="https://etherscan.io/verifySig/269032">https://etherscan.io/verifySig/269032</a> | <a
              href="https://etherscan.io/address/0xd5515682c4Fec4835E36d81fe28264d80602D637">https://etherscan.io/address/0xd5515682c4Fec4835E36d81fe28264d80602D637</a>
            <a href="https://etherscan.io/verifySig/269031">https://etherscan.io/verifySig/269031</a> | <a
              href="https://forum.sky.money/t/aegisd-ad-recognition-submission/26145">https://forum.sky.money/t/aegisd-ad-recognition-submission/26145</a>
            |
          </td>
        </tr>
        <tr>
          <td>
           <dfn>A.1.8
              - Emergency Response System - Emergency Response - Emergency Response Group Current Membership</dfn>
          </td>
          <td>Emergency Response System - Emergency Response - Emergency Response Group Current Membership</td>
          <td>Active Data</td>
          <td>The members of the Emergency Response Group are:<br> • Endgame Edge<br> • JanSky<br> • Ecosystem<br> • Phoenix Labs<br>
            • Jetstream<br> • Atlas Axis<br> • Steakhouse<br> • Blocktower<br> • BA Labs<br> • Maker Growth<br> • Dewiz<br> •Sidestream<br>
            • Cloaky<br> • Blue<br> • JuliaChang<br> • PullUp Labs<br> • Chronicle Labs<br> • TechOps
        </td>
        <tr>
          <td>
            <dfn>A.2.5
              - Star Incubation - Star Specific Support - Special Pre-launch Token Reward Programs Details</dfn>
          </td>
          <td>Star Incubation - Star Specific Support - Special Pre-launch Token Reward Programs Details</td>
          <td>Active Data</td>
          <td>
            No additional pre-launch token reward programs have been established pursuant to <dfn>A.2.5
              - Star Incubation - Spark Star-Specific Support - Special Pre-launch Token Reward Programs</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.6
              - Ecosystem Actor Incubation - Currently Incubating Ecosystem Actors - List</dfn>
          </td>
          <td>Ecosystem Actor Incubation - Currently Incubating Ecosystem Actors - List</td>
          <td>Active Data</td>
          <td>| Ecosystem Actor Name | Budget Allocation | Ecosystem Actor Goal | Team Members
            ||------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------||
            Phoenix Labs | 318,000 USDS paid out immediately in the beginning of May 2023. 127,833.33 USDS and
            1,972,500 SKY per month for all roles | Deliver the Spark Protocol and maintain it for 12 months,
            and support Star launch | 1 Business Development, 3 Smart Contract developers, 1 Developer Relations
            || Viridian Protector Advisory Company | 257,250 USDS provided immediately upon successful
            confirmation of the Incubating Ecosystem Actor in a Governance Poll. 85,750 USDS per month for full
            team. | Provide Protector Advisor work | Business Development, Risk Analyst, Lawyer || dewiz |
            150,000 USDS and 504,000 SKY per month. | General smart contract development and Collateral
            Onboarding Technical work (RWA focused). | 5 Smart Contract developers || Sidestream | 70,912.5 USDS
            per month. | Full stack smart contract and frontend development. | 3.5 FTE full stack developers ||
            PullUp | 3,300,000 USDS over one year implemented as DssVest. 96,000,000 SKY over two years
            implemented as DssVest. Full amount of SKY will not be drawn immediately, only as new contributors
            are onboarded | Innovation Engineering: Smart Burn Engine, Star launch, Sky Chain | Team member
            information will be kept private, instead detailed deliverable roadmap will be provided. ||
            Chronicle Labs | 310,150 USDS and 4,432,800 SKY for full team provided monthly as a linear dssvest
            stream for a 12 month period beginning July 1st 2023. | Launch a sustainable, secure, and
            decentralized oracle protocol and infrastructure service provider which supports the needs of Stars.
            Raise private capital and cease any further direct funding from Sky. | 1x General Manager, 3x Smart
            Contract Engineer, 3x Backend Engineer, 1x Fullstack Engineer, 1x DevOps Engineer, 1x Operations
            Manager, 1x Business Development Lead, 1x Marketing Strategist, 1x DevRel / Account Manager |</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Lawyer Registry Current Approved Legal
              Counsels</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Lawyer Registry Current Approved Legal Counsels</td>
          <td>Active Data</td>
          <td>There are no active legal counsels in the Lawyer Registry.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.2.9
              - Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee List Of
              Current Members</dfn>
          </td>
          <td>Legal Resilience - Legal Defense Resources - Resilience Fund Technical Committee List Of Current
            Members</td>
          <td>Active Data</td>
          <td>List of active Resilience Technical Committee Members:• Gallagher</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Andromeda Direct Exposure</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Andromeda Direct Exposure</td>
          <td>Active Data</td>
          <td>Current target sUSDe exposure is: 0</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Andromeda Legal Rails Exposure</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Andromeda Legal Rails Exposure</td>
          <td>Active Data</td>
          <td>Current target perpetual exposure for Andromeda is: 0</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Clydesdale Legal Rails Exposure</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Clydesdale Legal Rails Exposure</td>
          <td>Active Data</td>
          <td>Current target perpetual exposure for Clydesdale is: 0</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.3
              - Real World Assets - Perpetual Yield Strategies - Current Exposure Of Morpho SUSDe Or USDe DDM
              Vault</dfn>
          </td>
          <td>Real World Assets - Perpetual Yield Strategies - Current Exposure Of Morpho SUSDe Or USDe DDM Vault
          </td>
          <td>Active Data</td>
          <td>Current target exposure of Morpho sUSDe or USDe vault is: 550,000,000 USDS</td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Communication Channels And Media Assets
              Listing</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Communication Channels And Media Assets Listing</td>
          <td>Active Data</td>
          <td>
            The following channels should be used for initial and second public announcements of collateral
            offboarding. The order of announcement publication is as follows:1. The author of the collateral
            offboarding notice shall post to the Sky Forum detailing the recommended offboarding. This forum
            thread is used to inform downstream announcements on other channels.2. The Communication Coordinator
            publishes the associated notices to:• All public Sky Calendars• The Sky Official Discord's
            Announcement channel.• The official Sky subreddit.3. Partner Relationship Leads from relevant
            Ecosystem Actors reach out to:• Affected collateral partners (e.g., Aave)• Affected frontend service
            providers (e.g., Oasis, DeFi Saver)Additionally, outreach may be done to cover more channels not
            listed here. These may include other Ecosystem Actor or Facilitator owned Twitter accounts,
            communication channels, and platforms.Unless otherwise noted in <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process</dfn> and its subdocuments, the Accessibility
            Facilitators will take the lead in coordinating channels announcements.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>A.3.4
              - Collateral Portfolio - Offboarding Process - Current Communication Coordinator</dfn>
          </td>
          <td>Collateral Portfolio - Offboarding Process - Current Communication Coordinator</td>
          <td>Active Data</td>
          <td>The current Communication Coordinator is the Accessibility Facilitators.</td>
        </tr>
        <tr>
          <td>
            <dfn>A.5.9
              - Launch Project - Budget - Current Remaining Amount</dfn>
          </td>
          <td>Launch Project - Budget - Current Remaining Amount</td>
          <td>Active Data</td>
          <td>Remaining available one-time budget for the Launch Project:• 15,000,001 USDS• 62,400,000 SKY -
            The SKY can at most be spent at the rate of 48,000,000 SKY per month.</td>
        </tr>
      </tbody>
    </table>
  </div>
  <div id="agent-scope">
    <h1>Agent Scope Database</h1>
    <table>
      <tr>
        <th>Document Name</th>
        <th>Agent Name</th>
        <th>Doc Type</th>
        <th>Content</th>
      </tr>
      <tbody>
        <tr>
          <td>
            <dfn>Spark</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein specify all of the logic for Spark, including Spark's strategy and how it uses the Sky Primitives to operationalize this strategy.</td>
        </tr>
        <tr>
          <td>
            <dfn>Introduction</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Spark is an Agent focused on building on USDS in the Ethereum and adjacent DeFi ecosystem. This includes driving adoption of USDS and deploying collateral backing USDS at attractive risk-adjusted returns. Spark does this through the Spark Liquidity Layer, SparkLend, and Spark Savings.- The Spark Liquidity Layer directly provides USDS, sUSDS, and USDC liquidity across networks and DeFi markets.- SparkLend is a lending market focused on USDS borrowing, sourcing liquidity directly from Sky to provide the best borrow rates for USDS.- Spark Savings enables stablecoin holders to earn the best risk-adjusted rate in DeFi, at large scale, with minimal liquidity constraints.</td>
        </tr>
        <tr>
          <td>
            <dfn>Sky Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the Sky Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Genesis Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the Genesis Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Agent Creation Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instance of the Agent Creation Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Agent Creation Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Completed</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Agent Creation Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Agent Creation Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>Single Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Agent Creation Primitive is deployed solely for the one-time creation of the Agent, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The document herein contains the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Agent Creation Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Agent Creation Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Agent Creation Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Agent Creation Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Agent Creation Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the Single Agent Creation Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Single Instance of the Agent Creation Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Name</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The name of the Agent is Spark.</td>
        </tr>
        <tr>
          <td>
            <dfn>SubProxy Account</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The address of Spark's SubProxy Account on the Ethereum Mainnet is 0x3300f198988e4C9C63F75dF86De36421f06af8c4.</td>
        </tr>
        <tr>
          <td>
            <dfn>Genesis Account</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The address of Spark's Genesis Account will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Custom Instance Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the custom parameters of the Single Instance of the Agent Creation Primitive, if any.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Agent Creation Primitive is deployed solely for the one-time creation of the Agent, no further operational process is needed post-deployment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Single Instance of the Agent Creation Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Agent Creation Primitive is deployed solely for the one-time creation of the Agent, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Star Transformation Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instance of the Star Transformation Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Star Transformation Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Completed</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Star Transformation Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Star Transformation Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>Single Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Star Transformation Primitive is deployed solely for the one-time transformation of the Agent, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Star Transformation Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Star Transformation Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Star Transformation Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Star Transformation Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Star Transformation Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the Single Star Transformation Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Single Instance of the Star Transformation Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Agent Type</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Spark is a Star Agent.</td>
        </tr>
        <tr>
          <td>
            <dfn>Custom Instance Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the custom parameters of the Single Instance of the Star Transformation Primitive, if any.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Star Transformation Primitive is deployed solely for the one-time transformation of the Agent, no further operational process is needed post-deployment.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Single Instance of the Star Transformation Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Star Transformation Primitive is deployed solely for the one-time transformation of the Agent, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Executor Transformation Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instance of the Executor Transformation Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Executor Transformation Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Inactive</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Executor Transformation Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Executor Transformation Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Executor Transformation Primitive is deployed solely for the one-time transformation of the Agent, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Executor Transformation Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Executor Transformation Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Executor Transformation Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Executor Transformation Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Executor Transformation Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Executor Transformation Primitive is deployed solely for the one-time transformation of the Agent, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Agent Token Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instance of the Agent Token Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Agent Token Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Agent Token Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>Single Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Agent Token Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Agent Token Primitive is Invoked solely for the one-time deployment of the Agent's token, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Agent Token Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Agent Token Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Agent Token Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Agent Token Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the Single Agent Token Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Single Instance of the Agent Token Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Token Name</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The name of Spark's token is Spark.</td>
        </tr>
        <tr>
          <td>
            <dfn>Token Symbol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The symbol of Spark's token is SPK.</td>
        </tr>
        <tr>
          <td>
            <dfn>Genesis Supply</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Genesis Supply of SPK is 10 billion.</td>
        </tr>
        <tr>
          <td>
            <dfn>Token Address</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The address of SPK on the Ethereum Mainnet is 0xc20059e0317de91738d13af027dfc4a50781b066. The address of SPK on Base is 0x24327d9138f9f3fc77becb10d9bdc2abb324ee50.</td>
        </tr>
        <tr>
          <td>
            <dfn>Token Admin</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The token Admin is Spark's SubProxy Account on the Ethereum Mainnet at 0x3300f198988e4C9C63F75dF86De36421f06af8c4.</td>
        </tr>
        <tr>
          <td>
            <dfn>Token Emissions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            Token emissions beyond the Genesis Supply are permanently disabled; this cannot be reverted by Spark Governance. Sky Governance retains the ability to revert where Spark is in violation of First Loss Capital requirements and emissions are required by the Risk Framework. See <dfn>A.3.3</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Custom Instance Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the custom parameters of the Single Instance of the Agent Token Primitive, if any.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the operational processes for minting and initial distribution of the tokens from the Genesis Supply.</td>
        </tr>
        <tr>
          <td>
            <dfn>Minting Of Tokens To SPK Company Ltd</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Genesis Supply will be minted to an account owned by SPK Company Ltd and operationally controlled by Operational GovOps on behalf of SPK Company Ltd.</td>
        </tr>
        <tr>
          <td>
            <dfn>Transfer Of Tokens To Sky</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Operational GovOps, on behalf of SPK Company Ltd, will transfer 6.5 billion SPK tokens from SPK Company Ltd account to an account specified by Sky.</td>
        </tr>
        <tr>
          <td>
            <dfn>Transfer Of Tokens To Spark Foundation</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Operational GovOps, on behalf of SPK Company Ltd, will transfer 3.5 billion SPK tokens from the SPK Company Ltd account to the Spark Foundation. The address of the Spark Foundation on the Ethereum Mainnet will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Single Instance of the Agent Token Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Agent Token Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Agent Token Primitive is Invoked solely for the one-time deployment of the Agent's token, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the Operational Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Executor Accord Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Executor Accord Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Executor Accord Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Executor Accord Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>DAOCraft Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>DAOCraft Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Executor Accord Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Executor Accord Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Executor Accord Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Executor Accord Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Executor Accord Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Executor Accord Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>DAOCraft Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the DAOCraft Executor Accord Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the DAOCraft Instance of the Executor Accord Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Executor Agent</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>In the near term DAOCraft will take on the functions of an Operational Executor Agent, including both Operational GovOps and Operational Facilitator roles.</td>
        </tr>
        <tr>
          <td>
            <dfn>Custom Instance Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the custom parameters of the DAOCraft Instance of the Executor Accord Primitive, if any.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of the DAOCraft Instance of the Executor Accord Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the DAOCraft Instance of the Executor Accord Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Executor Accord Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Executor Accord Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instance of the Root Edit Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Root Edit Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Root Edit Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>Single Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Root Edit Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Root Edit Primitive is deployed only once, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Root Edit Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Root Edit Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Root Edit Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Root Edit Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the Single Root Edit Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The parameters of the Root Edit Primitive are fully specified by the Operational Process Definition in <dfn>Operational Process Definition</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The documents herein define the process for using the Root Edit Primitive to update the Spark Agent Artifact. Information on Spark governance that is unrelated to the use of the Root Edit Primitive is located at <dfn>Governance Information Unrelated To Root Edit Primitive</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for using the Root Edit Primitive to update the Spark Agent Artifact in routine or normal conditions (i.e., non-emergency situations).</td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Proposal Submission</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Root Edit process begins with a SPK token holder submitting a proposal through the Powerhouse system containing a draft Artifact Edit Proposal. A SPK token holder must hold at least 1% of the circulating token supply to submit a proposal. The proposal must also be posted on the Sky Forum under the "Spark" tag.</td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Proposal Submission Requirements Exception</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>For proposals that solely entail a buyback or a grant of SPK tokens, the requirement that SPK token holders must hold at least 1% of the circulating token supply to submit a proposal is waived. However, all other procedural requirements within the Root Edit process continue to apply.</td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Expert Advisor Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>A future iteration of the Spark Artifact will specify guidelines for obtaining specialized review of proposals requiring advanced technical or financial analysis.</td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Proposal Review By Operational Facilitator</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Within seven (7) days of the proposal being submitted, the Operational Facilitator must review the Root Edit Proposal for alignment.If the proposal is aligned, the Operational Facilitator must respond to the Forum post to announce their finding. In this Forum post, the Operational Facilitator must also confirm that the proposal is feasible for Operational GovOps to operationalize.If the proposal is misaligned, the Operational Facilitator must respond to the Forum post to announce their finding and provide the reasoning for it.</td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Token Holder Vote</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Where their review of the proposal results in a finding of alignment with the Sky Core Atlas and Spark Artifact, the Operational Facilitator next triggers a Snapshot poll to allow token holders to vote on the proposal. The poll is open for three (3) days. A poll must have at least 10% of the circulating token supply participating and must have 50% of votes in favor to be approved.</td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Artifact Update</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>At the conclusion of the poll, if the proposal is approved, the Operational Facilitator submits the edit to Powerhouse to formally update the Agent Artifact. Regardless of the outcome, the Operational Facilitator updates the Powerhouse System to include the result of the vote, including any pertinent documents.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Restrictions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Spark Artifact cannot be edited in any way that violates the Sky Core Atlas or its specifications of the Sky Primitives, or in any way that is otherwise misaligned. The Operational Facilitator must enforce this rule through their review of Artifact Edit Proposals.</td>
        </tr>
        <tr>
          <td>
            <dfn>Time-Limited Root Edit Restrictions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>For a period of three years after the Genesis Supply emissions of SPK tokens take place, no Artifact Edit is permitted that:- Would have the effect of removing Phoenix Labs or the Spark Foundation from their roles as core service providers to Spark; or- Is designed to remove or elect a Board Member of the Spark Foundation; or otherwise alter the composition of the Board of the Spark Foundation.</td>
        </tr>
        <tr>
          <td>
            <dfn>Non-Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for using the Root Edit Primitive to update the Spark Agent Artifact in non-routine conditions.</td>
        </tr>
        <tr>
          <td>
            <dfn>Emergency Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for using the Root Edit Primitive to update the Spark Agent Artifact in urgent or emergency situations.</td>
        </tr>
        <tr>
          <td>
            <dfn>Root Edit Voting Process in Urgent and Emergency Situations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            In an Urgent or Emergency Situation, as defined by the Sky Core Atlas in <dfn>A.1.8 - Emergency Voting System - Definition Of Emergency Situations</dfn>, the Operational Facilitator may allow a Root Edit to occur more quickly than the timeline specified above. Where feasible, the Operational Facilitator should announce the decision to deploy the emergency Root Edit protocol and provide their reasoning via a public Sky Forum post (under the "Spark" tag), unless doing so would endanger Spark or its users.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Single Instance of the Root Edit Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Root Edit Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Root Edit Primitive is deployed only once, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Light Agent Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Light Agent Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Light Agent Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Inactive</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Light Agent Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Light Agent Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Light Agent Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Light Agent Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Light Agent Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Light Agent Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Light Agent Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Light Agent Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Light Agent Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Ecosystem Upkeep Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the Ecosystem Upkeep Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Distribution Requirement Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instance of the Distribution Requirement Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Distribution Requirement Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Distribution Requirement Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>Single Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Distribution Requirement Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Distribution Requirement Primitive is deployed only once, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Distribution Requirement Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Distribution Requirement Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Distribution Requirement Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Distribution Requirement Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the Single Distribution Requirement Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Single Instance of the Distribution Requirement Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Terms</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Spark will buy back and distribute 0.25% of its total token supply per year.</td>
        </tr>
        <tr>
          <td>
            <dfn>Custom Instance Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the custom parameters of the Single Instance of the Distribution Requirement Primitive, if any.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of the Single Instance of the Distribution Requirement Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the protocol for routine ongoing management of the Single Instance of this Distribution Requirement Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Process Definition For Buy Back And Distribution Obligation</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The process to buy back and distribute 0.25% of Spark's tokens per year will be specified in future iterations of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Non-Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for non-routine ongoing management of the Single Instance of this Distribution Requirement Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Emergency Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for handling emergency situations in the ongoing management of the Single Instance of this Distribution Requirement Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Single Instance of the Distribution Requirement Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Distribution Requirement Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Distribution Requirement Primitive is deployed only once, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Market Cap Fee Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Market Cap Fee Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Market Cap Fee Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Inactive</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Market Cap Fee Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Market Cap Fee Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Market Cap Fee Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Market Cap Fee Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Market Cap Fee Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Market Cap Fee Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Market Cap Fee Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Market Cap Fee Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Market Cap Fee Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Upkeep Rebate Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instance of the Upkeep Rebate Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Upkeep Rebate Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Upkeep Rebate Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>Single Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Upkeep Rebate Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Upkeep Rebate Primitive is deployed only once, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Upkeep Rebate Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Upkeep Rebate Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Upkeep Rebate Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Upkeep Rebate Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Single Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the Single Upkeep Rebate Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Every Star Agent is entitled to the Upkeep Rebate Primitive for tokens of other Star Agents that they hold. Because this right automatically applies, there are no parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of the Single Instance of the Upkeep Rebate Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the protocol for routine ongoing management of the Single Instance of this Upkeep Rebate Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Holds Tokens Of Other Agents In Its SubProxy Account</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Spark keeps all tokens of other Agents it holds in its SubProxy account.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Deducts Rebate From Ecosystem Upkeep Fees</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>When paying Ecosystem Upkeep fees, Spark deducts the rebate from the fees it pays.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Reviews Rebate</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Operational GovOps reviews Spark's calculation of the rebate before executing a return of surplus to token holders. In the event of any issues, Operational GovOps cannot execute the distribution. If Operational GovOps does not execute the distribution, Operational GovOps must post an explanation on the Sky Forum under the "Spark" tag and work with Spark to resolve the disagreement. If Operational GovOps and Spark cannot resolve the disagreement, it must be escalated to Core GovOps.</td>
        </tr>
        <tr>
          <td>
            <dfn>Non-Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for non-routine ongoing management of the Single Instance of this Upkeep Rebate Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Emergency Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for handling emergency situations in the ongoing management of the Single Instance of this Upkeep Rebate Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Single Instance of the Upkeep Rebate Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Upkeep Rebate Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Because the Upkeep Rebate Primitive is deployed only once, no further Instances of the Primitive can be Invoked.</td>
        </tr>
        <tr>
          <td>
            <dfn>SkyLink Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the SkyLink Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Token SkyLink Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's instances of the Token SkyLink Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Token SkyLink Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Token SkyLink Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Token SkyLink Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Token SkyLink Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Token SkyLink Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Token SkyLink Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Token SkyLink Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Token SkyLink Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Token SkyLink Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Token SkyLink Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Demand Side Stablecoin Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the Demand Side Stablecoin Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Accessibility Reward Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's instances of the Accessibility Reward Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Accessibility Reward Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Accessibility Reward Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>SparkLend Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Accessibility Reward Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Accessibility Reward Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Accessibility Reward Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Accessibility Reward Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Accessibility Reward Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Accessibility Reward Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the SparkLend Accessibility Reward Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the SparkLend Instance of the Accessibility Reward Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Reward Code</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>128.</td>
        </tr>
        <tr>
          <td>
            <dfn>Tracking Methodology</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This Instance uses the Tracking Methodology specified in .</td>
        </tr>
        <tr>
          <td>
            <dfn>Custom Instance Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the custom parameters of the SparkLend Instance of the Accessibility Reward Primitive, if any.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of the SparkLend Instance of the Accessibility Reward Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the protocol for routine ongoing management of the SparkLend Instance. This Instance inherits the base class of operational logic defined in , subject to the qualifications specified in .Modifications to the base operational logic automatically propagate to this Instance. In future iterations of the Spark Artifact, a version of the full process definition customized to Spark will be included herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Agent Customizations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Star Agent may define instance-specific customization of the routine protocol to extend the baseline functionality defined in the Sky Core Atlas. This can include custom routines or processes layered on top of the inherited Sky Core logic. Any extensions must remain fully aligned with the requirements specified in the Sky Core Atlas. This document defines those customizations, if any.[No customization presently.]</td>
        </tr>
        <tr>
          <td>
            <dfn>Non-Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for non-routine ongoing management of the SparkLend Instance of this Accessibility Reward Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Emergency Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for handling emergency situations in the ongoing management of the SparkLend Instance of this Accessibility Reward Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the SparkLend Instance of the Accessibility Reward Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Accessibility Reward Payments</dfn>
          </td>
          <td>Spark</td>
          <td>Active Data Controller</td>
          <td>The Accessibility Reward payments for the SparkLend Instance of the Accessibility Reward Primitive are defined as Active Data. The Active Data is updated as follows:- The Responsible Party is Operational GovOps. - The Update Process must follow the protocol for 'Direct Edit'.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Accessibility Reward Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Accessibility Reward Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Boost Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Integration Boost Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Integration Boost Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Integration Boost Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Aave Instance Configuration Document Location</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This Instance's associated Instance Configuration Document is located at <dfn>Aave Instance Configuration Document</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Integration Boost Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Integration Boost Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>,; whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Integration Boost Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Integration Boost Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Integration Boost Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Integration Boost Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Aave Instance Configuration Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Instance Configuration Document for the Aave Integration Boost Primitive Instance.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Aave Instance of the Integration Boost Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Partner Name</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The partner for the Aave Integration Boost is Aave.</td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Partner Reward Address</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The reward address for the Aave Integration Boost is 0xac140648435d03f784879cd789130F22Ef588Fcd on the Ethereum Mainnet.</td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Partner Chain</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Aave Integration Boost is on the Ethereum Mainnet.</td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Boost Cadence</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The payment cadence for the Aave Integration Boost is weekly.</td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Boost Data Submission Format</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The Data Submission Responsible Actor calculates the net deposits based on on-chain events and makes the data available through an API endpoint located at <a href="https://info-sky.blockanalitica.com/api/v1/incentivized-pools/">https://info-sky.blockanalitica.com/api/v1/incentivized-pools/</a>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Boost Data Submission Responsible Actor</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Data Submission Responsible Actor is BA Labs.</td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Boost Savings Rate Adjustment Strategy</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Integration Boost is calculated based on per block values for USDS in Aave and the Sky Savings Rate.</td>
        </tr>
        <tr>
          <td>
            <dfn>Custom Instance Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the custom parameters of the Aave Instance of the Integration Boost Primitive, if any.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of the Aave Instance of the Integration Boost Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the protocol for routine ongoing management of the Aave Instance. This Instance inherits the base class of operational logic defined in , subject to the qualifications specified in . Modifications to the base operational logic automatically propagate to this Instance. In future iterations of the Spark Artifact, a version of the full process definition customized to Spark will be included herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Agent Customizations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Star Agent may define Instance-specific customization of the routine protocol to extend the baseline functionality defined in the Sky Core Atlas. This can include custom routines or processes layered on top of the inherited Sky Core logic. Any extensions must remain fully aligned with the requirements specified in the Sky Core Atlas. This document defines those customizations, if any.[No customization presently.]</td>
        </tr>
        <tr>
          <td>
            <dfn>Non-Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for non-routine ongoing management of the Aave Instance of this Integration Boost Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Emergency Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for handling emergency situations in the ongoing management of the Aave Instance of this Integration Boost Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Aave Instance of the Integration Boost Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Initial Planning</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with initial planning of the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational GovOps Review</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with Operational GovOps Review during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Artifact Edit Proposal</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The materials associated with preparing the Artifact Edit Proposal during the Invocation of this Instance are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Integration Boost Payments</dfn>
          </td>
          <td>Spark</td>
          <td>Active Data Controller</td>
          <td>The Integration Boost payments for the Aave Instance of the Integration Boost Primitive are defined as Active Data. The Active Data is updated as follows:- The Responsible Party is Operational GovOps. - The Update Process must follow the protocol for 'Direct Edit'.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Integration Boost Primitive with Completed Status are contained herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Integration Boost Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Pioneer Chain Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Pioneer Chain Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Pioneer Chain Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Inactive</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Pioneer Chain Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Pioneer Chain Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Pioneer Chain Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Pioneer Chain Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Pioneer Chain Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Pioneer Chain Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Pioneer Chain Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Pioneer Chain Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Pioneer Chain Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Supply Side Stablecoin Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the Supply Side Stablecoin Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Allocation System Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Allocation System Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Allocation System Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Active</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Allocation System Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Allocation System Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Allocation System Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Allocation System Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Allocation System Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Allocation System Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Multi-Instance Coordinator Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein specify the logic for coordinating multiple Instances of the Allocation System Primitive. In the future, additional logic will be added herein regarding how capital is allocated between different Instances of the Allocation System Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Allocation System Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Allocation System Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Allocation System Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>First Loss Capital Rental Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the First Loss Capital Rental Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the First Loss Capital Rental Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Inactive</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the First Loss Capital Rental Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the First Loss Capital Rental Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the First Loss Capital Rental Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the First Loss Capital Rental Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the First Loss Capital Rental Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the First Loss Capital Rental Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the First Loss Capital Rental Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the First Loss Capital Rental Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the First Loss Capital Rental Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Actively Stabilizing Collateral Rental Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Actively Stabilizing Collateral Rental Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Actively Stabilizing Collateral Rental Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Inactive</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Actively Stabilizing Collateral Rental Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Actively Stabilizing Collateral Rental Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Actively Stabilizing Collateral Rental Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Actively Stabilizing Collateral Rental Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Actively Stabilizing Collateral Rental Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Actively Stabilizing Collateral Rental Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Actively Stabilizing Collateral Rental Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Actively Stabilizing Collateral Rental Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Actively Stabilizing Collateral Rental Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Core Governance Primitives</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein implement the Core Governance Primitives for Spark. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Core Governance Reward Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain all data and specifications for Spark's Instances of the Core Governance Reward Primitive. See .</td>
        </tr>
        <tr>
          <td>
            <dfn>Primitive Hub Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein organize all base information relevant to Spark's usage of the Core Governance Reward Primitive.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Activation Status</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Inactive</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Core Governance Reward Primitive with Instance status of Active.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains a Directory of all Instances of the Core Governance Reward Primitive with Instance status of Completed.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations Directory</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document contains a Directory of all prospective Instances of the Core Governance Reward Primitive whose Invocation is currently in progress. Invocations that are completed successfully are moved to <dfn>Active Instances Directory</dfn>, whereas failed Invocations are Archived in <dfn>Hub Data Repository</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Hub Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the Data Repository for the Primitive Hub Document.</td>
        </tr>
        <tr>
          <td>
            <dfn>Archived Invocations/Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for archived Invocations and Instances of the Core Governance Reward Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Failed Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for failed Invocations of the Core Governance Reward Primitive are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Suspended Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subtrees for Instances of the Core Governance Reward Primitive with Suspended Status are stored here.</td>
        </tr>
        <tr>
          <td>
            <dfn>Active Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Core Governance Reward Primitive with Active Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Completed Instances</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Instances of the Core Governance Reward Primitive with Completed Status are stored herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>In Progress Invocations</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The in progress Invocations of the Core Governance Reward Primitive are contained herein. Once an Invocation is successfully completed, its subtree will be moved to <dfn>Active Instances</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Omni Documents</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define Spark's strategic intent and operational processes relating to infrastructure inherited from Sky Core, activities unrelated to Sky Primitives, or activities spanning multiple Sky Primitives.</td>
        </tr>
        <tr>
          <td>
            <dfn>Governance Information Unrelated To Root Edit Primitive</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The documents herein specify Spark governance information that is unrelated to the use of the Root Edit Primitive. The governance process for updating the Spark Artifact is specified in the Root Edit Primitive above at <dfn>Root Edit Primitive</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Sky Forum</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Spark uses the Sky Forum for governance-related discussion. Posts should use the "Spark" tag.</td>
        </tr>
        <tr>
          <td>
            <dfn>Discord</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            Spark also uses Discord for more immediate communication. The Spark Discord is located at <a href="https://t.co/v6zG0MZtak">https://t.co/v6zG0MZtak</a>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Sky Ecosystem Emergency Response</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein specify Spark's emergency response protocol in situations that impact the entire Sky Ecosystem. This protocol will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Agent-Specific Emergency Response</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein specify Spark's emergency response protocol in situations solely impacting Spark versus the broader Sky Ecosystem. This protocol will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Management Of Infrastructure Inherited From Sky Core</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein specify Spark's strategy and operational processes for managing infrastructure inherited from Sky Core.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Liquidity Layer</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters and operational processes related to the Spark Liquidity Layer. Control of the Spark Liquidity Layer is being transitioned to Spark.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Global Addresses</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein list the core addresses for the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Allocator Contracts</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains key addresses that apply globally across the Spark Liquidity Layer on all chains.◦ ALLOCATOR_BUFFER 0xc395D150e71378B47A1b8E9de0c1a83b75a08324◦ ALLOCATOR_ORACLE 0xc7B91C401C02B73CBdF424dFaaa60950d5040dB7◦ ALLOCATOR_REGISTRY 0xCdCFA95343DA7821fdD01dc4d0AeDA958051bB3B◦ ALLOCATOR_ROLES 0x9A865A710399cea85dbD9144b7a09C889e94E803◦ ALLOCATOR_VAULT (ALLOCATOR-SPARK-A) 0x691a6c29e9e96dd897718305427Ad5D534db16BA</td>
        </tr>
        <tr>
          <td>
            <dfn>ALM Contracts</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein list the ALM Contract Addresses for the Spark Liquidity Layer on each blockchain.</td>
        </tr>
        <tr>
          <td>
            <dfn>Ethereum Mainnet</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains the ALM Contract Addresses for the Spark Liquidity Layer on the Ethereum Mainnet.◦ ALM_CONTROLLER (MainnetController): 0x5cf73FDb7057E436A6eEaDFAd27E45E7ab6E431e◦ ALM_FREEZER 0x90D8c80C028B4C09C0d8dcAab9bbB057F0513431 ◦ Currently active Freezer Role IDs: •0x0ac42a08299cbc4428ec38ad4a8e7d7440779fbbb20ea90bd10c094a406cfa6f◦ ALM_RELAYER 0x8a25A24EDE9482C4Fc0738F99611BE58F1c839AB ◦ Currently active Relayer Role IDs •0xab4f864e5201b0fde9b5ee3e4cf96384802b0ffdfcf7f9de4699ce21a30afc4f◦ ALM_PROXY 0x1601843c5E9bC251A3272907010AFa41Fa18347E◦ ALM_RATE_LIMITS 0x7A5FD5cf045e010e62147F065cEAe59e5344b188</td>
        </tr>
        <tr>
          <td>
            <dfn>Base</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains the ALM Contract Addresses for the Spark Liquidity Layer on Base.◦ ALM_CONTROLLER (ForeignController) 0x5F032555353f3A1D16aA6A4ADE0B35b369da0440 ◦ ALM_FREEZER 0x90D8c80C028B4C09C0d8dcAab9bbB057F0513431 ◦ Currently active Freezer Role IDs: • 0x0ac42a08299cbc4428ec38ad4a8e7d7440779fbbb20ea90bd10c094a406cfa6f◦ ALM_RELAYER 0x8a25A24EDE9482C4Fc0738F99611BE58F1c839AB ◦ Currently active Relayer Role IDs • 0xab4f864e5201b0fde9b5ee3e4cf96384802b0ffdfcf7f9de4699ce21a30afc4f◦ ALM_PROXY 0x2917956eFF0B5eaF030abDB4EF4296DF775009cA◦ ALM_RATE_LIMITS 0x983eC82E45C61a42FDDA7B3c43B8C767004c8A74</td>
        </tr>
        <tr>
          <td>
            <dfn>Arbitrum</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document contains the ALM Contract Addresses for the Spark Liquidity Layer on Arbitrum.◦ ALM_CONTROLLER (ForeignController) 0x77e11453a99a7770b04f7921FfccD3eE9761ba6c◦ ALM_FREEZER 0x90D8c80C028B4C09C0d8dcAab9bbB057F0513431 ◦ Currently active Freezer Role IDs: • 0x0ac42a08299cbc4428ec38ad4a8e7d7440779fbbb20ea90bd10c094a406cfa6f◦ ALM_RELAYER 0x8a25A24EDE9482C4Fc0738F99611BE58F1c839AB ◦ Currently active Relayer Role IDs • 0xab4f864e5201b0fde9b5ee3e4cf96384802b0ffdfcf7f9de4699ce21a30afc4f◦ ALM_PROXY 0x92afd6F2385a90e44da3a8B60fe36f6cBe1D8709◦ ALM_RATE_LIMITS 0x19D08879851FB54C2dCc4bb32b5a1EA5E9Ad6838</td>
        </tr>
        <tr>
          <td>
            <dfn>Core Vault Security Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein list the Rate Limiters for the Spark Liquidity Layer on each blockchain.</td>
        </tr>
        <tr>
          <td>
            <dfn>Ethereum Mainnet</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document lists the current RateLimits for the Spark Liquidity Layer on Ethereum Mainnet.◦ Maximum amount of USDS that can be minted within the Spark Liquidity Layer (LIMIT_USDS_MINT). ◦ maxAmount (USDS): 50,000,000 ◦ slope (USDS/ day): 50,000,000◦ Maximum amount of USDS that can be burned within the Spark Liquidity Layer (LIMIT_USDS_BURN). ◦ maxAmount (USDS): 0 ◦ slope (USDS/ day): 0◦ Maximum amount of USDS that can be swapped for USDC by the Spark Liquidity Layer in the Mainnet PSM (LIMIT_USDS_TO_USDC). ◦ maxAmount (USDC): 50,000,000 ◦ slope (USDC/ day): 50,000,000◦ Maximum amount of USDC that can be sent to the Base ALM Proxy (LIMIT_USDC_TO_DOMAIN, hashed with Base domain). ◦ maxAmount (USDC): 4,000,000 ◦ slope (USDC/ day): 2,000,000 ◦ Maximum amount of USDC that can be bridged to Base ALM Proxy using the Circle Cross-Chain Transfer Protocol (LIMIT_USDC_TO_CCTP_BASE). • maxAmount (USDC): max • slope (USDC/ day): 0◦ Maximum amount of USDC that can be sent to the Ethereum Mainnet ALM Proxy (LIMIT_USDC_TO_DOMAIN, hashed with Ethereum domain). ◦ maxAmount (USDC): 4,000,000 ◦ slope (USDC/ day): 2,000,000 ◦ Maximum amount of USDC that can be bridged to Ethereum Mainnet ALM Proxy using the Circle Cross-Chain Transfer Protocol (LIMIT_USDC_TO_CCTP_ETH). • maxAmount (USDC): max • slope (USDC/ day): 0◦ Maximum amount of USDC that can be sent to the Ethereum Mainnet ALM Proxy (LIMIT_USDC_TO_DOMAIN, hashed with Ethereum domain). ◦ maxAmount (USDC): 4,000,000 ◦ slope (USDC/ day): 2,000,000 ◦ Maximum amount of USDC that can be bridged to Ethereum Mainnet ALM Proxy using the Circle Cross-Chain Transfer Protocol (LIMIT_USDC_TO_CCTP_ETH). • maxAmount (USDC): max • slope (USDC/ day): 0</td>
        </tr>
        <tr>
          <td>
            <dfn>Base</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document lists the current RateLimits for the Spark Liquidity Layer on Base.◦ Maximum amount of USDC that can be deposited into the PSM (LIMIT_PSM_DEPOSIT_USDC). ◦ maxAmount (USDC): 50,000,000 ◦ slope (USDC/ day): 50,000,000◦ Maximum amount of USDC that can be withdrawn from the PSM (LIMIT_PSM_WITHDRAW_USDC). ◦ maxAmount (USDC): 50,000,000 ◦ slope (USDC/ day): 50,000,000◦ Maximum amount of USDS that can be deposited into the PSM (LIMIT_PSM_DEPOSIT_USDS). ◦ maxAmount (USDS): Unlimited ◦ slope (USDS/ day): Unlimited◦ Maximum amount of USDS that can be withdrawn from the PSM (LIMIT_PSM_WITHDRAW_USDS). ◦ maxAmount (USDS): max ◦ slope (USDs/ day): 0◦ Maximum amount of sUSDS that can be deposited into the PSM (LIMIT_PSM_DEPOSIT_SUSDS). ◦ maxAmount (sUSDS): Unlimited ◦ slope (sUSDS/ day): Unlimited◦ Maximum amount of sUSDS that can be withdrawn from the PSM (LIMIT_PSM_WITHDRAW_SUSDS). ◦ maxAmount (sUSDS): max ◦ slope (sUSDs/ day): 0</td>
        </tr>
        <tr>
          <td>
            <dfn>Arbitrum</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document lists the current RateLimits for the Spark Liquidity Layer on Arbitrum.◦ Maximum amount of USDC that can be deposited into the PSM (LIMIT_PSM_DEPOSIT_USDC). ◦ maxAmount (USDC): This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope (USDC/ day): This parameter will be specified in a future iteration of the Spark Artifact.◦ Maximum amount of USDC that can be withdrawn from the PSM (LIMIT_PSM_WITHDRAW_USDC). ◦ maxAmount (USDC): This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope (USDC/ day): This parameter will be specified in a future iteration of the Spark Artifact.◦ Maximum amount of USDS that can be deposited into the PSM (LIMIT_PSM_DEPOSIT_USDS). ◦ maxAmount (USDS): This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope (USDS/ day): This parameter will be specified in a future iteration of the Spark Artifact. ◦ Maximum amount of USDS that can be withdrawn from the PSM (LIMIT_PSM_WITHDRAW_USDS). ◦ maxAmount (USDS): This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope (USDs/ day): This parameter will be specified in a future iteration of the Spark Artifact. ◦ Maximum amount of sUSDS that can be deposited into the PSM (LIMIT_PSM_DEPOSIT_SUSDS). ◦ maxAmount (sUSDS): This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope (sUSDS/ day): This parameter will be specified in a future iteration of the Spark Artifact. ◦ Maximum amount of sUSDS that can be withdrawn from the PSM (LIMIT_PSM_WITHDRAW_SUSDS). ◦ maxAmount (sUSDS): This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope (sUSDs/ day): This parameter will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Offchain Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein list the offchain parameters for the Spark Liquidity Layer on each blockchain.</td>
        </tr>
        <tr>
          <td>
            <dfn>Ethereum Mainnet</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document lists the current offchain parameters for the Spark Liquidity Layer on Ethereum Mainnet.◦ Minimum transaction size for operations (MAINNET_MIN_OPERATION_SIZE) 400,000◦ A buffer amount below the maximum debt ceiling (DEBT_CEILING_BUFFER) 10,000</td>
        </tr>
        <tr>
          <td>
            <dfn>Base</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document lists the current offchain parameters for the Spark Liquidity Layer on Base.◦ Minimum transaction size for operations (BASE_MIN_OPERATION_SIZE) 400,000◦ Minimum balance of USDC that must be maintained in a Base account within the SLL (USDC_MIN_BALANCE_BASE) 800,000◦ Ideal balance of USDC that should be maintained in a Base account within the SLL (USDC_OPTIMAL_BALANCE_BASE) 800,000◦ Maximum balance of USDC that can be maintained in a Base account within the SLL (USDC_MAX_BALANCE_BASE) 800,000</td>
        </tr>
        <tr>
          <td>
            <dfn>Arbitrum Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document lists the current offchain parameters for the Spark Liquidity Layer on Arbitrum.◦ Minimum transaction size for operations (ARBITRUM_MIN_OPERATION_SIZE) This parameter will be specified in a future iteration of the Spark Artifact. ◦ Minimum balance of USDC that must be maintained in Arbitrum account within the SLL (USDC_MIN_BALANCE_ARBITRUM) This parameter will be specified in a future iteration of the Spark Artifact. ◦ Ideal balance of USDC that should be maintained in a Arbitrum account within the SLL (USDC_OPTIMAL_BALANCE_ARBITRUM) This parameter will be specified in a future iteration of the Spark Artifact. ◦ Maximum balance of USDC that can be maintained in a Arbitrum account within the SLL (USDC_MAX_BALANCE_ARBITRUM) This parameter will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Multi-Deployment Coordinator Document</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein specify the logic for coordinating multiple deployments of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Role Hierarchy</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the key roles responsible for managing the Spark Liquidity Layer, including how those roles are activated and controlled.</td>
        </tr>
        <tr>
          <td>
            <dfn>Default Admin Role</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The DEFAULT_ADMIN_ROLE is the constructor role, providing the address with this role authority to grant and revoke any role<strong>,</strong> including itself and all other roles defined in the contract. This role is fully controlled by Sky Governance via the Spark Proxy.constructor(address admin) {_grantRole(DEFAULT_ADMIN_ROLE, admin);</td>
        </tr>
        <tr>
          <td>
            <dfn>Relayer Role</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The RELAYER_ROLE is the address for the Spark Liquidity Layer ALM Planner offchain system that calls functions on Controller contracts to perform actions on behalf of the ALMProxy contract.The Relayer Role can only be added or revoked by an address with DEFAULT_ADMIN_ROLE through adding/ removing RelayerRoleID to/ from the RELAYER Account within MainnetController contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>ALM Controller Role</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The ALM_CONTROLLER_ROLE is the address of the role that can call the call functions on the ALMProxy contract and update RateLimits contract. It includes MainnetController and ForeignController contracts. ALM Controller contracts are accessed and modified via the Relayer Role.</td>
        </tr>
        <tr>
          <td>
            <dfn>Freezer Role</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The FREEZER_ROLE is the address of the emergency role that allows freezing all actions on the Controller contracts.Freeze function is invoked in the Controller contract by the Relayer Role.</td>
        </tr>
        <tr>
          <td>
            <dfn>Coordination Strategy</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>In the future, additional logic will be added herein regarding how capital is allocated between different deployments of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Processes</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the processes for ongoing management of the Spark Liquidity Layer and its active deployments.</td>
        </tr>
        <tr>
          <td>
            <dfn>Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the protocol for routine ongoing management of the Spark Liquidity Layer and its active deployments.</td>
        </tr>
        <tr>
          <td>
            <dfn>RateLimits Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the operations performed to ensure RateLimits are maintained in line with Spark's strategy, market conditions, and security considerations.◦ Query current RateLimits for a specific keyFunction getRateLimitData(bytes32 key) external override view returns (RateLimitData memory) { return _data[key]; } function getCurrentRateLimit(bytes32 key) public override view returns (uint256) { RateLimitData memory d = _data[key]; // Unlimited rate limit case if (d.maxAmount == type(uint256).max) { return type(uint256).max; } return _min( d.slope * (block.timestamp - d.lastUpdated) + d.lastAmount, d.maxAmount ); }◦ Set the RateLimits for a specific keyfunction setRateLimitData( bytes32 key, uint256 maxAmount, uint256 slope, uint256 lastAmount, uint256 lastUpdated ) public override onlyRole(DEFAULT_ADMIN_ROLE) { require(lastAmount &lt;= maxAmount, "RateLimits/invalid-lastAmount"); require(lastUpdated &lt;= block.timestamp, "RateLimits/invalid-lastUpdated"); _data[key] = RateLimitData({ maxAmount: maxAmount, slope: slope, lastAmount: lastAmount, lastUpdated: lastUpdated }); emit RateLimitDataSet(key, maxAmount, slope, lastAmount, lastUpdated); } function setRateLimitData(bytes32 key, uint256 maxAmount, uint256 slope) external override { setRateLimitData(key, maxAmount, slope, maxAmount, block.timestamp); }◦ Set an unlimited RateLimitfor a specific keyfunction setUnlimitedRateLimitData(bytes32 key) external override { setRateLimitData(key, type(uint256).max, 0, type(uint256).max, block.timestamp);◦ Trigger a decrease of a RateLimit for a specific keyfunction triggerRateLimitDecrease(bytes32 key, uint256 amountToDecrease) external override onlyRole(CONTROLLER) returns (uint256 newLimit) { RateLimitData storage d = _data[key]; uint256 maxAmount = d.maxAmount; require(maxAmount &gt; 0, "RateLimits/zero-maxAmount"); if (maxAmount == type(uint256).max) return type(uint256).max; // Special case unlimited uint256 currentRateLimit = getCurrentRateLimit(key); require(amountToDecrease &lt;= currentRateLimit, "RateLimits/rate-limit-exceeded"); d.lastAmount = newLimit = currentRateLimit - amountToDecrease; d.lastUpdated = block.timestamp; emit RateLimitDecreaseTriggered(key, amountToDecrease, currentRateLimit, newLimit); }◦ Trigger an increase of a RateLimit for a specific keyfunction triggerRateLimitIncrease(bytes32 key, uint256 amountToIncrease) external override onlyRole(CONTROLLER) returns (uint256 newLimit) { RateLimitData storage d = _data[key]; uint256 maxAmount = d.maxAmount; require(maxAmount &gt; 0, "RateLimits/zero-maxAmount"); if (maxAmount == type(uint256).max) return type(uint256).max; // Special case unlimited uint256 currentRateLimit = getCurrentRateLimit(key); d.lastAmount = newLimit = _min(currentRateLimit + amountToIncrease, maxAmount); d.lastUpdated = block.timestamp; emit RateLimitIncreaseTriggered(key, amountToIncrease, currentRateLimit, newLimit);</td>
        </tr>
        <tr>
          <td>
            <dfn>MainnetController Contract Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the functions controlled by the Controller contract for Spark Liquidity Layer operations on Ethereum Mainnet.</td>
        </tr>
        <tr>
          <td>
            <dfn>Admin Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed by the DEFAULT_ADMIN_ROLE within the MainnetController contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>Set The MintRecipient For A Specific DestinationDomain</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to set the mintRecipient for a specific destinationDomain. This is used in cross-chain transfers to specify the address that will receive minted tokens on the target chain. ◦ Ensure you're working as an Admin. Only the DEFAULT_ADMIN_ROLE is allowed to setMintRecipient. function setMintRecipient(uint32 destinationDomain, bytes32 mintRecipient) external onlyRole(DEFAULT_ADMIN_ROLE) ◦ Associate the mintRecipient with the destinationDomain , meaning that whenever tokens are minted on this domain, they will go to this recipient. { mintRecipients[destinationDomain] = mintRecipient; ◦ Emit the event to the blockchain logs. emit MintRecipientSet(destinationDomain, mintRecipient); }</td>
        </tr>
        <tr>
          <td>
            <dfn>Relayer Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed by the RELAYER_ROLE within the MainnetController contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>Core Vault Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations that are performed to maintain the desired level of liquidity and debt balance of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Mint USDS</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the steps to mint USDS from the Sky Allocation Vault to the Spark ALM Proxy. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to mintUSDS. Also, ensure the contract isActive i.e. can process the request. function mintUSDS(uint256 usdsAmount) external onlyRole(RELAYER) isActive ◦ Ensure the <a href="https://etherscan.io/address/0x7A5FD5cf045e010e62147F065cEAe59e5344b188#readContract#F3">RateLimits</a> allow to mint the required amount. rateLimited(LIMIT_USDS_MINT, usdsAmount) ◦ Call the MainnetController contract to mint USDS into the Buffer. 1. Encode the mint function call, using abi.encodeCall with the address vault from which USDS will be drawn, and the amount of USDS to mint. 2. Send the encoded call using proxy.doCall() to the draw function of the vault contract. { // Mint USDS into the buffer proxy.doCall( address(vault), abi.encodeCall(vault.draw, (usdsAmount)) ); ◦ Call the MainnetController contract to transfer USDS from the Buffer to the ALM Proxy. 1. Encode the transfer function call, using abi.encodeCall with the buffer address USDS will be transferred from, the proxy address that will receive USDS (i.e. ALM Proxy), and the amount of USDS to transfer. 2. Send the encoded call using proxy.doCall() to the transferFrom function of the USDS contract. // Transfer USDS from the buffer to the proxy proxy.doCall( address(usds), abi.encodeCall(usds.transferFrom, (buffer, address(proxy), usdsAmount)) ); }• <strong>Burn</strong>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Burn USDS</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the steps to return and then burn Spark's USDS debt in the Sky Allocation Vault. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to burnUSDS. Also, ensure the contract isActive i.e. can process the request.function burnUSDS(uint256 usdsAmount) external onlyRole(RELAYER) isActive ◦ Ensure the <a href="https://etherscan.io/address/0x7A5FD5cf045e010e62147F065cEAe59e5344b188#readContract#F3">RateLimits</a> allow the required amount to mint.cancelRateLimit(LIMIT_USDS_MINT, usdsAmount) ◦ Call the MainnetController to transfer USDS from the AML Proxy to the Buffer. 1. Encode the transfer function call, using abi.encodeCall with the buffer address USDS will be transferred to, and the amount of USDS to transfer. 2. Send the encoded call using proxy.doCall() to the transfer function of the USDS contract. { // Transfer USDS from the proxy to the buffer proxy.doCall( address(usds), abi.encodeCall(usds.transfer, (buffer, usdsAmount)) ); ◦ Call the MainnetController contract to burn USDS. 1. Encode the wipe function call, using abi.encodeCall with the address vault from which USDS will be burned, and the amount of USDS to burn. 2. Send the encoded call using proxy.doCall() to the wipe function of the vault contract. // Burn USDS from the buffer proxy.doCall( address(vault), abi.encodeCall(vault.wipe, (usdsAmount)) ); }• <strong>ER</strong>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>ERC4626 Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed to deposit and withdraw liquidity from yield-bearing Integrator vaults.</td>
        </tr>
        <tr>
          <td>
            <dfn>Deposit ERC4626 Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the steps to deposit assets from the ALM Proxy to the ERC4626 vault to receive yield-bearing shares.◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to depositERC4626 tokens. Also, ensure the contract isActivei.e. can process the request. function depositERC4626(address token, uint256 amount) external onlyRole(RELAYER) isActive ◦ Ensure ALM Proxy holds enough of the underlying asset to cover the instructed deposit amount. ◦ Ensure the deposit amount is allowed within the RateLimits. rateLimited( RateLimitHelpers.makeAssetKey(LIMIT_4626_DEPOSIT, token), amount ) returns (uint256 shares) { // Note that whitelist is done by rate limits IERC20 asset = IERC20(IERC4626(token).asset()); ◦ Call the approve ERC4626 function to update the allowance of the asset contract. 1. Encode the function call to the ERC-4626 approve method, using abi.encodeCall to allow the token address spend up to amount of a token from ALM Proxy's balance. 2. Send the encoded call using proxy.doCall() specifying the address of the asset contract you want to deposit into. // Approve asset to token from the proxy (assumes the proxy has enough of the asset). proxy.doCall( address(asset), abi.encodeCall(asset.approve, (token, amount)) ); ◦ Call the deposit ERC4626 function to transfer the underlying asset to ERC-4626 token and receive vault shares. 1. Encode the function call to ERC-4626 deposit method, using abi.encodeCall with the address of the ERC-4626 token vault, the amount of the underlying asset to deposit and theaddress(proxy) that will receive the resulting shares (i.e. ALM Proxy). 2. Send the encoded call using proxy.doCall() to the deposit function on the ERC-4626 vault contract (token). 3. Decode the raw bytes data returned from the doCall() function intouint256 value, representing the number of vault shares minted from the deposit. // Deposit asset into the token, proxy receives token shares, decode the resulting shares shares = abi.decode( proxy.doCall( token, abi.encodeCall(IERC4626(token).deposit, (amount, address(proxy))) ), (uint256) ); }</td>
        </tr>
        <tr>
          <td>
            <dfn>Withdraw ERC4626 Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the steps to withdraw a yield-earning balance from the ERC4626 vault to the ALM Proxy. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to withdrawERC4626 tokens. Also, ensure the contract isActivei.e. can process the request. function withdrawERC4626(address token, uint256 amount) external onlyRole(RELAYER) isActive ◦ Ensure ALM Proxy holds sufficient shares of the ERC-4626 vault token to cover the instructed withdraw amount. ◦ Ensure the withdraw amount is allowed within the RateLimits. // Check withdrawal limits. rateLimited( RateLimitHelpers.makeAssetKey(LIMIT_4626_WITHDRAW, token), amount ) returns (uint256 shares) ◦ Call the withdraw ERC4626 function to withdraw a required amount of underlying assets from an ERC-4626 vault and receive the corresponding vault shares. 1. Encode the function call to the ERC-4626 withdraw method, using abi.encodeCall with the address of the ERC-4626 token vault, the amount of the underlying asset to withdraw and theaddress(proxy) of the recipient of the withdrawn assets and the sender of the shares (i.e. ALM Proxy). 2. Send the encoded call using proxy.doCall() to the withdraw function on the ERC-4626 vault contract (token). 3. Decode the raw bytes data returned from the doCall() function intouint256 value, representing the number of token shares burned in the withdrawal. { // Withdraw asset from a token, decode resulting shares. // Assumes proxy has adequate token shares. shares = abi.decode( proxy.doCall( token, abi.encodeCall(IERC4626(token).withdraw, (amount, address(proxy), address(proxy))) ), (uint256) ); } ◦ Call the redeemERC4626 function to redeem a specific number of vault shares for the underlying asset. 1. Encode the function call to the ERC-4626 redeem method, using abi.encodeCall with the address of the ERC-4626 token vault, the shares to redeem and theaddress(proxy) of the receiver of redeemed assets and the owner of shares being received (i.e. ALM Proxy). 2. Send the encoded call using proxy.doCall()to the redeem function on the ERC-4626 vault contract (token). 3. Decode the raw bytes data returned from the doCall() function into uint256 value, representing the number of underlying assets received for the redeemed shares. function redeemERC4626(address token, uint256 shares) external onlyRole(RELAYER) isActive returns (uint256 assets) { // Redeem shares for assets from the token, decode the resulting assets. // Assumes proxy has adequate token shares. assets = abi.decode( proxy.doCall( token, abi.encodeCall(IERC4626(token).redeem, (shares, address(proxy), address(proxy))) ), (uint256) ); ◦ Decrease the RateLimit based on the assets redeemed. rateLimits.triggerRateLimitDecrease( RateLimitHelpers.makeAssetKey(LIMIT_4626_WITHDRAW, token), assets ); }</td>
        </tr>
        <tr>
          <td>
            <dfn>Aave Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed to deposit and withdraw liquidity from yield-bearing Aave deployments.</td>
        </tr>
        <tr>
          <td>
            <dfn>Deposit to Aave ATokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the steps to deposit assets from the ALM Proxy to the Aave pool to receive yield-bearing ATokens. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to depositAave. Also, ensure the contract isActivei.e. can process the request. function depositAave(address aToken, uint256 amount) external onlyRole(RELAYER) isActive ◦ Ensure ALM Proxy holds enough of the underlying asset to cover the instructed deposit amount. ◦ Ensure the deposit amount is allowed within the RateLimits. rateLimited( RateLimitHelpers.makeAssetKey(LIMIT_AAVE_DEPOSIT, aToken), amount ) ◦ Initialize the underlying variable as an ERC-20 token interface.Initialize the interface for the address of the underlying asset retrieved from the aToken contract (the contract that represents the deposited assets in Aave). The IERC20 interface allows interacting with ERC-20 tokens, including performing actions like transferring, approving, and checking balances. { IERC20 underlying = IERC20(IATokenWithPool(aToken).UNDERLYING_ASSET_ADDRESS()); ◦ Initialize the pool variable as an interface for the Aave pool.Retrieve the Aave pool contract address associated with the given aToken. This address represents the Aave lending pool where the assets are deposited. IAavePool interface allows interacting with the Aave pool's functions (like supply). IAavePool pool = IAavePool(IATokenWithPool(aToken).POOL()); ◦ Call the approve function to update the allowance of the underlying asset contract. 1. Encode the approve function call, using abi.encodeCall allowing the Aave pool address to spend up to amount of the underlying token from the ALM Proxy's balance. 2. Send the encoded call using proxy.doCall() specifying the address of the asset contract you want to deposit into. // Approve underlying to Aave pool from the proxy (assumes the proxy has enough underlying). proxy.doCall( address(underlying), abi.encodeCall(underlying.approve, (address(pool), amount)) ); ◦ Call the deposit function to transfer the underlying asset to the Aave lending pool and receive the aTokens. 1. Encode the deposit function call, using abi.encodeCall with the address of the underlying token, the amount of the underlying asset to deposit and theaddress(proxy) that will receive the resulting aTokens (i.e. ALM Proxy). 2. Send the encoded call using proxy.doCall() to the supply function on Aave (pool). // Deposit underlying into Aave pool, proxy receives aTokens proxy.doCall( address(pool), abi.encodeCall(pool.supply, (address(underlying), amount, address(proxy), 0)) ); }</td>
        </tr>
        <tr>
          <td>
            <dfn>Withdraw Aave ATokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the steps to withdraw a yield-earning balance from the Aave AToken vaults to the ALM Proxy. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to withdrawAave tokens. Also, ensure the contract isActivei.e. can process the request. function withdrawAave(address aToken, uint256 amount) external onlyRole(RELAYER) isActive ◦ Ensure ALM Proxy holds sufficient aTokensto cover the instructed withdraw amount. ◦ Ensure the withdraw amount is allowed within the RateLimits. // Check withdrawal limits. rateLimited( RateLimitHelpers.makeAssetKey(LIMIT_AAVE_WITHDRAW, aToken), amount ) ◦ Initialize the pool variable as an interface for the Aave pool.Retrieve the Aave pool contract address associated with the given aToken. This address represents the Aave lending pool fron which the assets are withdrawn. IAavePool pool = IAavePool(IATokenWithPool(aToken).POOL()); ◦ Call the withdraw function to withdraw a required amount of underlying asset from Aave pool address and receive the corresponding aTokens. 1. Encode the withdraw function using abi.encodeCall with the underlying asset address from the aToken contract, specifying which token is being withdrawn, the amount of the underlying asset to withdraw, and theaddress(proxy) of the recipient of the withdrawn assets (i.e. ALM Proxy). 2. Send the encoded call using proxy.doCall() to the withdraw function of the Aave pool contract. 3. Decode the raw bytes data returned from the doCall() function intouint256 value, representing the amount of underlying assets that were successfully withdrawn from the Aave pool (amountWithdrawn). // Withdraw underlying from Aave pool, decode resulting amount withdrawn. // Assumes proxy has adequate aTokens. amountWithdrawn = abi.decode( proxy.doCall( address(pool), abi.encodeCall( pool.withdraw, (IATokenWithPool(aToken).UNDERLYING_ASSET_ADDRESS(), amount, address(proxy)) ) ), (uint256) ); ◦ Decrease the RateLimit based on the assets redeemed. rateLimits.triggerRateLimitDecrease( RateLimitHelpers.makeAssetKey(LIMIT_AAVE_WITHDRAW, aToken), amountWithdrawn ); }</td>
        </tr>
        <tr>
          <td>
            <dfn>Ethena Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed to manage the Ethena deployment, including rate limiting, role-based access control, and cooldown functionality.</td>
        </tr>
        <tr>
          <td>
            <dfn>Set A Delegated Signer In The EthenaMinter Contract</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to set a delegated signer to the Ethena Minter contract. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to setDelegatedSigner. Also, ensure the contract isActivei.e. can process the request. function setDelegatedSigner(address delegatedSigner) external onlyRole(RELAYER) isActive◦ Use proxy.doCall() to forward the call to the ethenaMinter contract and call setDelegatedSigner function to set the address that will be authorized as adelegatedSigner. To call on ethenaMinter contract, the function must be encoded using abi.encodeCall. { proxy.doCall( address(ethenaMinter), abi.encodeCall(ethenaMinter.setDelegatedSigner, (address(delegatedSigner))) );}• <strong>Remove</strong></td>
        </tr>
        <tr>
          <td>
            <dfn>Remove A Delegated Signer In The EthenaMinter Contract</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to remove a delegated signer from the Ethena Minter contract. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to removeDelegatedSigner. Also, ensure the contract isActivei.e. can process the request. function removeDelegatedSigner(address delegatedSigner) external onlyRole(RELAYER) isActive ◦ Use proxy.doCall() to forward the call to the ethenaMinter contract and call removeDelegatedSigner function to remove the authorization for the address to act as adelegatedSigner. To call on ethenaMinter contract, the function must be encoded using abi.encodeCall. { proxy.doCall( address(ethenaMinter), abi.encodeCall(ethenaMinter.removeDelegatedSigner, (address(delegatedSigner))) );}</td>
        </tr>
        <tr>
          <td>
            <dfn>Approve Minting Of USDe By EthenaMinter Contract</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to approve the minting of USDe by the Ethena Minter contract. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to prepareUSDeMint. Also, ensure the contract isActivei.e. can process the request. function prepareUSDeMint(uint256 usdcAmount) external onlyRole(RELAYER) isActive ◦ Enforce a rate limit on how much USDC can be approved for minting USDe. rateLimited(LIMIT_USDE_MINT, usdcAmount) ◦ Use proxy.doCall() to send an approval call to the usdc contract, allowing the ethenaMinter contract to spend up to the specified amount of USDC. Encode the function using abi.encodeCall. { proxy.doCall( address(usdc), abi.encodeCall(usdc.approve, (address(ethenaMinter), usdcAmount)) );}</td>
        </tr>
        <tr>
          <td>
            <dfn>Approve Burning Of USDe By EthenaMinter Contract</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to approve the burning of USDe by the Ethena Minter contract. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to prepareUSDeBurn. Also, ensure the contract isActivei.e. can process the request. function prepareUSDeBurn(uint256 usdeAmount) external onlyRole(RELAYER) isActive ◦ Enforce a rate limit on how much USDe can be approved for burning.rateLimited(LIMIT_USDE_BURN, usdeAmount) ◦ Use proxy.doCall() to send an approval call to the usde contract, allowing the ethenaMinter contract to spend up to the specified amount of USDe. Encode the function using abi.encodeCall.{ proxy.doCall( address(usde), abi.encodeCall(usde.approve, (address(ethenaMinter), usdeAmount)) );}</td>
        </tr>
        <tr>
          <td>
            <dfn>Initiate A sUSDe Cooldown Period</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to initiate a sUSDe Cooldown period. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to cooldownAssetsSUSDe. Also, ensure the contract isActivei.e. can process the request. function cooldownAssetsSUSDe(uint256 usdeAmount) external onlyRole(RELAYER) isActive ◦ Enforce a rate limit on how much sUSDe can be cooled down. rateLimited(LIMIT_SUSDE_COOLDOWN, usdeAmount) ◦ Use proxy.doCall() to make a call to the susde contract, invoking the cooldownAssets function with the specified amount of sUSDe**.** Encode the function using abi.encodeCall. { proxy.doCall( address(susde), abi.encodeCall(susde.cooldownAssets, (usdeAmount)) );}</td>
        </tr>
        <tr>
          <td>
            <dfn>Cool Down sUSDe Shares</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to cool down sUSDe shares. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to cooldownSharesSUSDe. Also, ensure the contract isActivei.e. can process the request. function cooldownSharesSUSDe(uint256 susdeAmount) external onlyRole(RELAYER) isActive ◦ Use proxy.doCall() to make a call to the susde contract, initiating the cooldown on the specified amount of sUSDe shares**.** Encode the function using abi.encodeCall.Decode the result returned by the cooldownShares function into a uint256 value, representing the amount of shares that were actually cooled down (cooldownAmount). { cooldownAmount = abi.decode( proxy.doCall( address(susde), abi.encodeCall(susde.cooldownShares, (susdeAmount)) ), (uint256) ); ◦ Decrease the RateLimit, effectively reducing the available cooldown limit, based on the cooldownAmount. rateLimits.triggerRateLimitDecrease(LIMIT_SUSDE_COOLDOWN, cooldownAmount);}</td>
        </tr>
        <tr>
          <td>
            <dfn>Unstake sUSDe And Return It To ALM Proxy</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to unstake sUSDe and return it to the ALM Proxy. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to unstakeSUSDe. Also, ensure the contract isActivei.e. can process the request. function unstakeSUSDe() external onlyRole(RELAYER) isActive ◦ Use proxy.doCall() to make a call to the susde contract to invoke the unstake function, which unstakes sUSDe and sends the resulting tokens back to the proxy address (i.e. ALM Proxy). Encode the function using abi.encodeCall.</td>
        </tr>
        <tr>
          <td>
            <dfn>PSM Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the swap operations performed by Spark Liquidity Layer in the PSM.</td>
        </tr>
        <tr>
          <td>
            <dfn>Swap USDS to USDC</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines a series of operations to swap USDS to USDC through the PSM. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to swapUSDSToUSDC. Also, ensure the contract isActivei.e. can process the request. function swapUSDSToUSDC(uint256 usdcAmount) external onlyRole(RELAYER) isActive ◦ Ensure the <a href="https://etherscan.io/address/0x7A5FD5cf045e010e62147F065cEAe59e5344b188#readContract#F3">RateLimits</a> allow to swap the required USDS amount to USDC.rateLimited(LIMIT_USDS_TO_USDC, usdcAmount) ◦ Convert USDC amounts to an 18 token decimal format using psmTo18ConversionFactor.{ uint256 usdsAmount = usdcAmount * psmTo18ConversionFactor; ◦ Ensure ALM Proxy has enough USDS balance to swap for the required USDC amount. ◦ Approve the daiUsds contract to spend the usdsAmount on behalf of the proxy.daiUsdsis a contract that facilitates a 1:1 swap between USDS and DAI.proxy.doCall( address(usds), abi.encodeCall(usds.approve, (address(daiUsds), usdsAmount)) ); ◦ Swap USDS to DAI.USDS is swapped to DAI in a 1:1 ratio through the daiUsds contract and sent back to the proxy. proxy.doCall( address(daiUsds), abi.encodeCall(daiUsds.usdsToDai, (address(proxy), usdsAmount))); ◦ Approve the PSM to spend the newly acquired DAI.The approval is needed for the PSM to be able to swap DAI for USDC. proxy.doCall( address(dai), abi.encodeCall(dai.approve, (address(psm), usdsAmount))); ◦ Swap DAI to USDC.Swap DAI to USDC in the PSM at a 1:1 ratio with no fee, using the buyGemNoFee function and return USDC to the proxy. proxy.doCall( address(psm), abi.encodeCall(psm.buyGemNoFee, (address(proxy), usdcAmount)) ); }
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Swap USDC to USDS</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines a series of operations to swap USDC to USDS through the PSM. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to swapUSDCToUSDS. Also, ensure the contract isActivei.e. can process the request. function swapUSDCToUSDS(uint256 usdcAmount) external onlyRole(RELAYER) isActive ◦ Ensure the <a href="https://etherscan.io/address/0x7A5FD5cf045e010e62147F065cEAe59e5344b188#readContract#F3">RateLimits</a> allow to swap the required USDC amount to USDS.cancelRateLimit(LIMIT_USDS_TO_USDC, usdcAmount) ◦ Ensure ALM Proxy has enough USDC balance to swap for the required USDS amount. ◦ Approve the PSM to spend USDC.The approval is needed for the PSM to be able to execute a swap of USDC.proxy.doCall( address(usdc), abi.encodeCall(usdc.approve, (address(psm), usdcAmount))); ◦ Calculate the swap limit per transaction.The maximum amount of USDC that can be swapped to DAI in one transaction is calculated, based on the DAI balance held by the PSM.psmTo18ConversionFactor converts DAI's 18 token decimals to USDC's 6 token decimals.uint256 limit = dai.balanceOf(address(psm)) / psmTo18ConversionFactor; ◦ Perform a direct swap feasibility check and swap USDC to DAI, if possible.If the usdcAmount is less than or equal to the limit, a direct swap is performed. _swapUSDCToDAI is called to execute the swap from USDC to DAI.if (usdcAmount &lt;= limit) { _swapUSDCToDAI(usdcAmount);} ◦ If direct swap is not possible, perform iterative swap of USDC to DAI with DAI refilling.If the usdcAmount exceeds the limit, the contract splits the swap into multiple smaller swaps as follows: 1. Refill the PSM with DAI by calling psm.fill(). 2. Recalculate the limit to see how much USDC can be swapped after the refill. 3. Swap the maximum possible USDC amount that doesn't exceed the limit. 4. Update remainingUsdcToSwap by subtracting the amount just swapped. 5. Repeat the process until the full usdcAmount is swapped.If the PSM can't be filled, the transaction reverts with DssLitePsm/nothing-to-fill.else { uint256 remainingUsdcToSwap = usdcAmount; while (remainingUsdcToSwap &gt; 0) { psm.fill(); limit = dai.balanceOf(address(psm)) / psmTo18ConversionFactor; uint256 swapAmount = remainingUsdcToSwap &lt; limit ? remainingUsdcToSwap : limit; _swapUSDCToDAI(swapAmount); remainingUsdcToSwap -= swapAmount; }} ◦ Convert USDC amount to DAI amount accounting for the token decimal difference. { uint256 daiAmount = usdcAmount * psmTo18ConversionFactor; ◦ Approve the daiUsds contract to spend the daiAmount on behalf of the proxy. proxy.doCall( address(dai), abi.encodeCall(dai.approve, (address(daiUsds), daiAmount))); ◦ Swap DAI to USDS.DAI is swapped to USDS in a 1:1 ratio through the daiUsds contract and sent back to the proxy.proxy.doCall( address(daiUsds), abi.encodeCall(daiUsds.daiToUsds, (address(proxy), daiAmount)) ); }
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Bridging Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed to bridge liquidity between Ethereum Mainnet and the destination blockchains for the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Bridge USDC Using Circle Cross-Chain Transfer Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to bridge USDC using the Circle Cross-Chain Transfer Protocol. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to transferUSDCToCCTP. Also, ensure the contract isActivei.e. can process the request.function transferUSDCToCCTP(uint256 usdcAmount, uint32 destinationDomain) external onlyRole(RELAYER) isActive ◦ Ensure the bridging transaction complies with RateLimits.LIMIT_USDC_TO_CCTP: Enforces a rate limit on total USDC transferred via CCTP.LIMIT_USDC_TO_DOMAIN: Enforces a rate limit on USDC transferred to a specific destinationDomain.rateLimited(LIMIT_USDC_TO_CCTP, usdcAmount) rateLimited( RateLimitHelpers.makeDomainKey(LIMIT_USDC_TO_DOMAIN, destinationDomain), usdcAmount ) ◦ Verify mint recipient.Check that a mint recipient (mapping from domain IDs to recipient addresses) is configured for the destinationDomain.If no recipient is configured, the transaction reverts with an error message.bytes32 mintRecipient = mintRecipients[destinationDomain];require(mintRecipient != 0, "MainnetController/domain-not-configured"); ◦ Ensure ALM Proxy has enough USDC to cover the amount instructed in the transfer. ◦ Approve CCTP to spend USDC on behalf of the proxy.This action is necessary for the CCTP contract to initiate the cross-chain transfer.proxy.doCall( address(usdc), abi.encodeCall(usdc.approve, (address(cctp), usdcAmount))); ◦ Initiate the USDC transfer through CCTP. ◦ Check the transfer limit. Retrieve the maximum amount of USDC that can be transferred in a single CCTP message. This limit is fetched from the localMinter contract associated with CCTP. uint256 burnLimit = cctp.localMinter().burnLimitsPerMessage(address(usdc)); ◦ If single transaction is possible within per-message limit, initiate the CCTP transfer for the entire USDC amount. { _initiateCCTPTransfer(usdcAmount, destinationDomain, mintRecipient);} ◦ If usdcAmount exceeds the per-message limit, the transfer is split into multiple smaller batches executing the following loop until the remaining amount is less than or equal to the limit. 1. Transfer the maximum allowed (burnLimit) using _initiateCCTPTransfer. 2. Reduce the remaining usdcAmount by the burnLimit. while (usdcAmount &gt; burnLimit) { _initiateCCTPTransfer(burnLimit, destinationDomain, mintRecipient); usdcAmount -= burnLimit;} ◦ Send remaining USDC amount (if applicable) If there is any usdcAmount left after the loop, send the remaining amount in a single transfer, ensuring the entire amount is transferred, even if it didn't divide evenly by the burnLimit. if (usdcAmount &gt; 0) { _initiateCCTPTransfer(usdcAmount, destinationDomain, mintRecipient);}</td>
        </tr>
        <tr>
          <td>
            <dfn>Bridge USDS / sUSDS Using OP Token Bridge</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to bridge USDS or sUSDS using the OP Token Bridge. This process will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>ForeignController Contract Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the functions controlled by the Controller contract for Spark Liquidity Layer cross-chain operations on a destination blockchain.</td>
        </tr>
        <tr>
          <td>
            <dfn>Admin Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed by the DEFAULT_ADMIN_ROLE within the ForeignController contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>Set The MintRecipient For A Specific DestinationDomain</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to set a mintRecipient for a specific destinationDomain. This is used in cross-chain transfers to specify the address that will receive minted tokens on the target chain. ◦ Ensure you're working as an Admin. Only the DEFAULT_ADMIN_ROLE is allowed to setMintRecipient. function setMintRecipient(uint32 destinationDomain, bytes32 mintRecipient) external onlyRole(DEFAULT_ADMIN_ROLE) ◦ Associate the mintRecipient with the destinationDomain , meaning that whenever tokens are minted on this domain, they will go to this recipient. { mintRecipients[destinationDomain] = mintRecipient; ◦ Emit the event to the blockchain logs. emit MintRecipientSet(destinationDomain, mintRecipient); }</td>
        </tr>
        <tr>
          <td>
            <dfn>Relayer Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations performed by the RELAYER_ROLE within the ForeignController contract.</td>
        </tr>
        <tr>
          <td>
            <dfn>ERC4626 Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the operations that are performed to deposit and withdraw liquidity from yield-bearing Integrator vaults.</td>
        </tr>
        <tr>
          <td>
            <dfn>Deposit to ERC4626 Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the steps to deposit assets from the ALM Proxy to the ERC4626 vault to receive yield-bearing shares.The process for depositing to ERC4626 Tokens on destination blockchain through the ForeignController contract is the same as the one for depositing to ERC4626 Tokens on Ethereum Mainnet though the MainnetController contract, and can be found at <dfn>Deposit ERC4626 Tokens</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Withdraw ERC4626 Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the steps to withdraw a yield-earning balance from the ERC4626 vault to the ALM Proxy.The process for withdrawing ERC4626 Tokens on destination blockchain through the ForeignController contract is the same as the one for withdrawing ERC4626 Tokens on Ethereum Mainnet though the MainnetController contract, and can be found at <dfn>Withdraw ERC4626 Tokens</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Aave Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations that are performed to deposit and withdraw liquidity from yield-bearing Aave deployments.</td>
        </tr>
        <tr>
          <td>
            <dfn>Deposit to Aave ATokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the steps to deposit assets from the ALM Proxy to the Aave pool to receive yield-bearing ATokens.The process for depositing to Aave ATokens on destination blockchain through the ForeignController contract is the same as the one for depositing to Aave ATokens on Ethereum Mainnet though the MainnetController contract, and can be found at <dfn>Deposit to Aave ATokens</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Withdraw Aave ATokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the steps to withdraw a yield-earning balance from the Aave AToken vaults to the ALM Proxy.The process for withdrawing Aave ATokens on destination blockchain through the ForeignController contract is the same as the one for withdrawing Aave ATokens on Ethereum Mainnet though the MainnetController contract, and can be found at <dfn>Withdraw Aave ATokens</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>PSM Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the swap operations that are performed by the Spark Liquidity Layer in the Spark Base PSM.</td>
        </tr>
        <tr>
          <td>
            <dfn>Deposit Asset Into The PSM</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines a series of operations to deposit an asset into the PSM. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to depositPSM. Also, ensure the contract isActivei.e. can process the request. function depositPSM(address asset, uint256 amount) external onlyRole(RELAYER) isActive ◦ Ensure the <a href="https://etherscan.io/address/0x7A5FD5cf045e010e62147F065cEAe59e5344b188#readContract#F3">RateLimits</a> allow to deposit the required amount of the asset to the PSM.If limit is not breached, the function will return the number of PSM shares that will be received in return for depositing the asset.rateLimitedAsset(LIMIT_PSM_DEPOSIT, asset, amount) returns (uint256 shares) ◦ Via proxy.doCall approve the transfer of amount of the specified asset to the PSM contract through the IERC20.approve.The approve function of the ERC-20 token allows the PSM contract to spend the amount of the asset that is being deposited.proxy.doCall( asset, abi.encodeCall(IERC20.approve, (address(psm), amount))); ◦ Deposit the asset into the PSM via the deposit function of the PSM contract. ◦ Encode the function using abi.encodeCall, creating the necessary data for the call: • asset: The address of the ERC-20 token being deposited. • address(proxy): The address of the proxy contract that is making the deposit on behalf of the user. • amount: The amount of the asset to deposit into the PSM. ◦ Use the proxy contract to call the deposit function of the PSM contract. ◦ Decode the result of the deposit function call using abi.decode. The expected return value is a uint256, which represents the number of PSM shares received by the proxy after the deposit. shares = abi.decode( proxy.doCall( address(psm), abi.encodeCall( psm.deposit, (asset, address(proxy), amount) ) ), (uint256));
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Withdraw The MaxAmount Of Asset From The PSM</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines a series of operations to withdraw an asset from the PSM. ◦ Ensure you're working as a Relayer. Only the RELAYER role is allowed to withdrawPSM. Also, ensure the contract isActivei.e. can process the request.function withdrawPSM(address asset, uint256 maxAmount) external onlyRole(RELAYER) isActive ◦ Withdraw the asset from the PSM via the proxy. ◦ Encode the function call with abi.encodeCall()providing the required parameters: • asset: The address of the ERC-20 asset to withdraw (for example, USDC). • address(proxy): The address of the proxy contract calling the PSM to execute the withdrawal. • maxAmount: The maximum amount to withdraw. ◦ Use the proxy contract to call the psm.withdraw function of the PSM contract. ◦ Decode the result of the psm.withdraw function call using abi.decode. The expected return value is a uint256, which represents actual amount of assets withdrawn from the PSM. assetsWithdrawn = abi.decode( proxy.doCall( address(psm), abi.encodeCall( psm.withdraw, (asset, address(proxy), maxAmount) ) ), (uint256) );</td>
        </tr>
        <tr>
          <td>
            <dfn>Bridging Functions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the operations that are performed to bridge liquidity between the destination blockchain and Ethereum Mainnet for the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Bridge USDC Using Circle Cross-Chain Transfer Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the process to bridge USDC using the Circle Cross-Chain Transfer Protocol.The process for bridging USDC using CCTP through the ForeignController contract is the same as the one for bridging USDC using CCTP throuhg the MainnetController contract, and can be found at <dfn>Bridge USDC Using Circle Cross-Chain Transfer Protocol</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Bridge USDS / sUSDS using OP Token Bridge</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the process to bridge USDS / sUSDS using the OP Token Bridge. This process will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Non-Routine Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for non-routine ongoing management of the Spark Liquidity Layer and its active deployments.</td>
        </tr>
        <tr>
          <td>
            <dfn>Emergency Protocol</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define all the possible actions that can be taken in case of an emergency within Spark Liquidity Layer operations.</td>
        </tr>
        <tr>
          <td>
            <dfn>Freeze Contract Functionalities</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document defines the emergency procedure to temporarily disable functions within the Controller contract. ◦ Temporarily disable contract functionalities. The freeze function is an emergency procedure to be used to protect against risks such as security vulnerabilities, market volatility, or governance decisions. ◦ Ensure you're working as a Freezer. Only the FREEZER_ROLE is allowed to freeze the contract. function freeze() external onlyRole(FREEZER) ◦ Pause the contract functions by setting the state variable active to false. active = false; This variable is typically checked in the isActive modifier: modifier isActive { require(active, "MainnetController/not-active"); _;} This effectively pauses any functions using the isActive modifier. ◦ Emit the event for off-chain tracking. emit Frozen();◦ Reactivate disabled contract functionalities. ◦ Ensure you're working as an Admin. Only the DEFAULT_ADMIN_ROLE is allowed to reactivate the contract. function reactivate() external onlyRole(DEFAULT_ADMIN_ROLE) ◦ Resume normal contract operations by setting the state variable active back to true. active = true; This allows functions using the isActive modifier to be called again. ◦ Emit the event for off-chain tracking. emit Reactivated();</td>
        </tr>
        <tr>
          <td>
            <dfn>Remove Compromised Relayer As Freezer</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This function is used to remove a Relayer from the Controller contract.This action should be used if the RelayerID has been compromised, for example by: ◦ Falling under control of an unauthorized actor. ◦ Misalignment of an authorized actor holding RelayerID ownership.mainnetController.removeRelayer(compromisedRelayer)</td>
        </tr>
        <tr>
          <td>
            <dfn>Redeem All L2 Positions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document lists the actions that should be performed if there is a need to recover the liquidity from L2 Integrators and centralize it in the L2 Spark ALM Proxy. ◦ Withdraw all ERC4626 balances. foreignController.redeemERC4626(address(token), token.balanceOf(address(proxy)))More detailed instructions on the code to execute this can be found in the <dfn>Withdraw ERC4626 Tokens</dfn>. ◦ Withdraw all AToken balances. foreignController.withdrawAave(aToken, aToken.balanceOf(address(proxy))More detailed instructions on the code to execute this can be found in the <dfn>Withdraw Aave ATokens</dfn>. ◦ Withdraw all Assets from the PSM. foreignController.withdrawPSM(address(usdc), type(uint256).max)More detailed instructions on the code to execute this can be found in the <dfn>Withdraw The MaxAmount Of Asset From The PSM</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Bridge Liquidity From L2 ALM Proxy To Mainnet</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the actions that should be performed if there is a need to bring all liquidity from the Spark ALM Proxy on the destination domain to the Spark ALM Proxy on Mainnet. ◦ Bridge USDC. foreignController.transferUSDCToCCTP(usdc.balanceOf(address(proxy)), 0);More detailed instructions on the code to execute this can be found in the <dfn>Bridge USDC Using Circle Cross-Chain Transfer Protocol</dfn>. ◦ Bridge USDS and sUSDS
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Redeem All Mainnet Positions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the actions that should be performed if there is a need to recover the liquidity from Mainnet Integrators and centralize it in the Mainnet Spark ALM Proxy. ◦ Withdraw all ERC4626 balances.fmainnetController.redeemERC4626(address(token), token.balanceOf(address(proxy)))More detailed instructions on the code to execute this can be found in the <dfn>Withdraw ERC4626 Tokens</dfn>. ◦ Withdraw all AToken balances.mainnetController.withdrawAave(aToken, aToken.balanceOf(address(proxy))More detailed instructions on the code to execute this can be found in the <dfn>Withdraw Aave ATokens</dfn>. ◦ Withdraw all Ethena balances. ◦ Start cooldown for sUSDe. mainnetController.cooldownSharesSUSDe(susde.balanceOf(address(proxy)) More detailed instructions on the code to execute this can be found in the <dfn>Cool Down sUSDe Shares</dfn>. ◦ Unstake sUSDe. mainnetController.unstakeSUSDe() More detailed instructions on the code to execute this can be found in the <dfn>Unstake sUSDe And Return It To ALM Proxy</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Swap USDC to USDS</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the actions that should be performed if there is a need to centralize all recovered liquidity in USDS.mainnetController.swapUSDCToUSDS(usdc.balanceOf(address(proxy))More detailed instructions on the code to execute this can be found in the <dfn>Swap USDC to USDS</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Burn USDS</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            This document defines the actions that should be performed if there is a need to repay and then burn Spark's USDS debt.mainnetController.burnUSDS(usds.balanceOf(address(proxy))More detailed instructions on the code to execute this can be found in the <dfn>Burn USDS</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Active Deployments</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain specifications for the active deployments of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Ethereum Mainnet Deployment Specifications</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for all Ethereum Mainnet deployments of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the SparkLend deployment of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the SparkLend deployment on Ethereum Mainnet. ◦ USDS ◦ Address This parameter will be specified in a future iteration of the Spark Artifact. ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: 150,000,000 ◦ slope: 75,000,000 ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: Unlimited ◦ slope: Unlimited◦ USDC ◦ Address This parameter will be specified in a future iteration of the Spark Artifact. ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: 20,000,000 ◦ slope: 10,000,000 ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: Unlimited ◦ slope: Unlimited</td>
        </tr>
        <tr>
          <td>
            <dfn>Aave Core Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Aave Core deployment of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the Aave Core deployment on Ethereum Mainnet.◦ USDS AToken ◦ Address 0x32a6268f9Ba3642Dda7892aDd74f1D34469A4259 ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact. ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact.◦ USDC AToken ◦ Address 0x98C23E9d8f34FEFb1B7BD6a91B7FF122F4e16F5c ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact. ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Aave Prime Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Aave Prime deployment of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the Aave Prime deployment on Ethereum Mainnet.◦ USDS ◦ Address This parameter will be specified in a future iteration of the Spark Artifact. ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: 50,000,000 ◦ slope: 50,000,000 ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: Unlimited ◦ slope: Unlimited</td>
        </tr>
        <tr>
          <td>
            <dfn>Fluid Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Fluid deployment of the Spark Liquidity Layer on Ethereum Mainnet.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the Fluid deployment on Ethereum Mainnet.◦ Fluid sUSDS ◦ Address 0x2BBE31d63E6813E3AC858C04dae43FB2a72B0D11 ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: 10,000,000 ◦ slope: 5,000,000 ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: 10,000,000 ◦ slope: 5,000,000</td>
        </tr>
        <tr>
          <td>
            <dfn>Ethena Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Ethena deployment of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the Ethena deployment on Ethereum Mainnet.◦ USDe ◦ Address 0x4c9edd5852cd905f086c759e8383e09bff1e68b3 ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact. ◦ Outflow Parameters • Outflow RateLimit IDThis parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact.◦ sUSDe ◦ Address 0x9d39a5de30e57443bff2a8307a4256c8797a3497 ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact. ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: This parameter will be specified in a future iteration of the Spark Artifact. ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Delegated Signers</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>This document herein contain the addresses authorized as delegatedSigners in the ethenaMinter contract.delegatedSigners are set up and removed in the MainnetController contract by the Relayer role.</td>
        </tr>
        <tr>
          <td>
            <dfn>Addresses Of Delegated Signers</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>delegatedSigner addressesxxx</td>
        </tr>
        <tr>
          <td>
            <dfn>Base Deployment Specifications</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for all Base deployments of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Fluid Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Fluid deployment of the Spark Liquidity Layer on Base.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the Fluid deployment on Base.◦ Fluid sUSDS ◦ Address 0xf62e339f21d8018940f188F6987Bcdf02A849619 ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: 10,000,000 ◦ slope: 5,000,000 ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: 10,000,000 ◦ slope: 5,000,000</td>
        </tr>
        <tr>
          <td>
            <dfn>Morpho Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Morpho deployment of the Spark Liquidity Layer on Base.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the Morpho deployment on Base.◦ Morpho USDC ◦ Address 0x305E03Ed9ADaAB22F4A58c24515D79f2B1E2FD5D ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: 50,000,000 ◦ slope: 25,000,000 ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: Unlimited ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Aave Deployment Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters of the Aave deployment of the Spark Liquidity Layer on Base.</td>
        </tr>
        <tr>
          <td>
            <dfn>List of Tokens</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for the Tokens of the Aave deployment on Base. ◦ USDC AToken ◦ Address 0x4e65fE4DbA92790696d040ac24Aa414708F5c0AB ◦ Inflow Parameters • Inflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Inflow RateLimits ◦ maxAmount: 50,000,000 ◦ slope: 25,000,000 ◦ Outflow Parameters • Outflow RateLimitID This parameter will be specified in a future iteration of the Spark Artifact. • Outflow RateLimits ◦ maxAmount: Unlimited ◦ slope: This parameter will be specified in a future iteration of the Spark Artifact.</td>
        </tr>
        <tr>
          <td>
            <dfn>Arbitrum Deployment Specifications</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain the specifications for all Arbitrum deployments of the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Spark Liquidity Layer.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters and operational processes related to SparkLend. Control of SparkLend is being transitioned to Spark.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The parameters of SparkLend are specified in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Definitions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subdocuments herein provide definitions of the SparkLend risk parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>Borrow Rate Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The borrow rate is the annualized percentage yield for borrowing the asset, which is determined based on the market's Interest Rate Model and actual utilization in the market.</td>
        </tr>
        <tr>
          <td>
            <dfn>Supply Rate Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The supply rate is the annualized percentage yield for supplying the asset, which is determined based on borrow rate as:supply rate = market utilization * borrow rate * (1-reserve factor)</td>
        </tr>
        <tr>
          <td>
            <dfn>Interest Rate Model Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The Interest Rate Model ("IRM") is defined by four main parameters:1. Base Rate - the starting rate at 0% utilization2. Variable Slope 1 - the rate at optimal utilization3. Variable Slope 2 - the rate at 100% utilization4. Utilization - the utilization itselfThe Base Rate, Slope 1, and Slope 2 parameters are further defined in: <dfn>Base Rate Definition</dfn>; <dfn>Slope 1 Definition</dfn>; and <dfn>Slope 2 Definition</dfn>.All markets except Dai use this IRM. The IRM for Dai is independent of utilization and is defined as a spread over the Core Stability Parameters Base Rate set forth in <dfn>A.3.2 - Core Stability Parameters - Parameters - Base Rate</dfn>. The spread is determined by the Stability Facilitators, in consultation with the Stability Scope Advisors.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>LTV Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The LTV is the maximum percentage of the value of collateral that borrowers can borrow against their collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>Liquidation Threshold Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The liquidation threshold is the maximum debt a borrower can owe as a percentage of their collateral before their position is considered under-collateralized and thus at risk of being liquidated.</td>
        </tr>
        <tr>
          <td>
            <dfn>High Efficiency Mode Category Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The High Efficiency Mode Category groups assets that are highly correlated with each other into buckets, for example Stablecoins or various forms of ETH. Borrowing against an asset to acquire another asset in the same category can support higher LTVs and liquidation thresholds as determined by the protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>Liquidation Bonus Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The liquidation bonus is the bonus for liquidating an unhealthy loan, or equivalently the penalty for having an unhealthy loan liquidated. The party paying off the unhealthy loan is entitled to collateral with an equivalent value as the debt paid off plus the liquidation bonus.</td>
        </tr>
        <tr>
          <td>
            <dfn>Reserve Factor Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The reserve factor is the percentage of interest payments paid to the protocol.</td>
        </tr>
        <tr>
          <td>
            <dfn>Supply Cap Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The supply cap is the maximum amount of the asset that can be supplied.</td>
        </tr>
        <tr>
          <td>
            <dfn>Borrow Cap Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The borrow cap is the maximum amount of the asset that can be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Optimal Utilization Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The optimal utilization represents the desired target utilization of the borrowing capacity for the asset. It is an input used to determine the interest rate of borrowing. When the actual utilization is above the optimal utilization, borrowing rates will be higher; and when the actual utilization is below the optimal utilization, borrowing rates will be lower.</td>
        </tr>
        <tr>
          <td>
            <dfn>Isolated Debt Ceiling Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The isolated debt ceiling represents the maximum amount that can be borrowed against designated isolated assets, as determined by the Stability Facilitators in consultation with the Stability Scope Advisors. Only Stablecoins may be borrowed against isolated assets.</td>
        </tr>
        <tr>
          <td>
            <dfn>Base Rate Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The base rate is an input used to determine the interest rate of borrowing. The base rate is adjusted based on actual borrowing utilization relative to optimal borrowing utilization to arrive at the actual borrowing rate.</td>
        </tr>
        <tr>
          <td>
            <dfn>Reserve State Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The reserve state represents the state of the market for a particular collateral type. The reserve state may be:• Active - all activities may occur• Frozen - all activities may occur except for supplying and borrowing• Paused - no activities may occur</td>
        </tr>
        <tr>
          <td>
            <dfn>Slope 1 Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Slope 1 is the interest rate at optimal utilization in the Interest Rate Model.</td>
        </tr>
        <tr>
          <td>
            <dfn>Slope 1 Spread Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Slope 1 Spread is the difference between the WETH interest rate at optimal utilization in the Interest Rate Model and the staking yield on stETH. The Slope 1 Spread Parameter is only defined for WETH.</td>
        </tr>
        <tr>
          <td>
            <dfn>Slope 2 Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Slope 2 is the interest rate at 100% utilization in the Interest Rate Model.</td>
        </tr>
        <tr>
          <td>
            <dfn>Collateral-Enabled Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>If Collateral is Enabled, then the asset may be used as collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>Borrowing-Enabled Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>If Borrowing is Enabled, then the asset may be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Isolated Collateral-Enabled Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>If Isolated Collateral is Enabled, only Stablecoins can be borrowed when using the asset as collateral.</td>
        </tr>
        <tr>
          <td>
            <dfn>Isolation Mode Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>When a user is in Isolation Mode, only assets with Isolated Borrow enabled can be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Siloed Borrowing-Enabled Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>If Siloed Borrowing is Enabled, then when borrowing the asset, no other asset may be borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Flash Loan Enabled Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>If the Flash Loan Enabled parameter is activated, then the asset may be borrowed using a flash loan.</td>
        </tr>
        <tr>
          <td>
            <dfn>Total Flash Loan Fee Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Total Flash Loan Fee incorporates a fee paid to the protocol and a fee paid to liquidity providers. This total fee is calculated as a percentage of the flash loan amount. Of the Total Flash Loan Fee, the Protocol Flash Loan Fee is paid to the protocol, with the remainder paid to liquidity providers.The Total Flash Loan Fee is set on a protocol level, regardless of what assets are being borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>Protocol Flash Loan Fee Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Protocol Flash Loan Fee is the fee for a flash loan paid to the protocol as a percentage of the flash loan amount.The Protocol Flash Loan Fee is set on a protocol level, regardless of what assets are being borrowed.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Current Configuration</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subdocuments herein define the current configuration of the SparkLend risk parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>GNO Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current GNO risk parameters are:• LTV: 0%• Liquidation Threshold: 25%• E-mode Category: N/A• Liquidation Bonus: 10%• Reserve Factor: 0%• Supply Cap: N/A• Borrow Cap: N/A• Optimal Utilization: 100%• Isolated Debt Ceiling: $5,000,000• Base Rate: 1%• Slope 1: 0%• Slope 2: 0%• Reserve State: Frozen• Collateral: Yes• Borrowing: No• Isolated Collateral: Yes• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>Dai Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current Dai risk parameters are:• LTV: 0%• Liquidation Threshold: 0.01%• E-mode Category: N/A• Liquidation Bonus: 4.5%• Reserve Factor: 0%• Supply Cap: N/A• Borrow Cap: N/A• Optimal Utilization: N/A• Isolated Debt Ceiling: N/A• Base Rate: N/A• Slope 1: N/A• Slope 2: N/A• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: Yes• Siloed Borrowing: No• Flash Loan Enabled: YesThe Dai Borrow Rate is set directly by the Stability Facilitators in consultation with the Stability Scope Advisors, and is currently equal to ~9.5%, which is the Dai Savings Rate plus 1%.</td>
        </tr>
        <tr>
          <td>
            <dfn>WETH Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current WETH risk parameters are:• LTV: 82%• Liquidation Threshold: 83%• E-mode Category: ETH• Liquidation Bonus: 5%• Reserve Factor: 5%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap automater• Optimal Utilization: 90%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: N/A• Slope 1 Spread: -0.50%• Slope 2: 120%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: YesThe Slope 1 parameter for WETH is calculated based on the following formula:slope 1 = stETH yield + slope 1 spread - base rate</td>
        </tr>
        <tr>
          <td>
            <dfn>USDT Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current USDT risk parameters are:• LTV: 0%• Liquidation Threshold: 0%• E-mode Category: USD• Liquidation Bonus: 0%• Reserve Factor: 5%• Supply Cap: 30,000,000 USDT• Borrow Cap: Set by cap automater• Optimal Utilization: 95%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 6.83%• Slope 2: 15%• Reserve State: Active• Collateral: No• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>WBTC Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current WBTC risk parameters are:• LTV: 0%• Liquidation Threshold: 55%• E-mode Category: N/A• Liquidation Bonus: 7%• Reserve Factor: 20%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap automater• Optimal Utilization: 60%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 2%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>sDai Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current sDai risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: USD• Liquidation Bonus: 5%• Reserve Factor: 10%• Supply Cap: Set by cap automater• Borrow Cap: N/A• Optimal Utilization: 100%• Isolated Debt Ceiling: N/A• Base Rate: 1%• Slope 1: 0%• Slope 2: 0%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>wstETH Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current wstETH risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: ETH• Liquidation Bonus: 7%• Reserve Factor: 30%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap automater• Optimal Utilization: 70%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 2%• Slope 2: 200%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>USDC Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current USDC risk parameters are:• LTV: 0%• Liquidation Threshold: 0%• E-mode Category: USD• Liquidation Bonus: 0%• Reserve Factor: 5%• Supply Cap: 60,000,000 USDC• Borrow Cap: Set by cap automater• Optimal Utilization: 95%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 6.83%• Slope 2: 15%• Reserve State: Active• Collateral: No• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>weETH Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current weETH risk parameters are:• LTV: 72%• Liquidation Threshold: 73%• E-mode Category: N/A• Liquidation Bonus: 10%• Reserve Factor: 15%• Supply Cap: Set by cap automator• Borrow Cap: N/A• Optimal Utilization: 45%• Isolated Debt Ceiling: $200,000,000• Base Rate: 5%• Slope 1: 15%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: Yes• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>rETH Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current rETH risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: ETH• Liquidation Bonus: 7%• Reserve Factor: 15%• Supply Cap: Set by cap automater• Borrow Cap: Set by cap automater• Optimal Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 0.25%• Slope 1: 7%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>Total Flash Loan Fee Current Value</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Total Flash Loan Fee is 0.00%.</td>
        </tr>
        <tr>
          <td>
            <dfn>Protocol Flash Loan Fee Current Value</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Protocol Flash Loan Fee is 0.00%.</td>
        </tr>
        <tr>
          <td>
            <dfn>cbBTC Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current cbBTC risk parameters are:• LTV: 74%• Liquidation Threshold: 75%• E-mode Category: N/A• Liquidation Bonus: 8%• Reserve Factor: 20%• Supply Cap: 500 cbBTC• Borrow Cap: 50 cbBTC• Optimal Utilization: 60%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 4%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No</td>
        </tr>
        <tr>
          <td>
            <dfn>sUSDS Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current sUSDS risk parameters are:• LTV: 79%• Liquidation Threshold: 80%• E-mode Category: N/A• Liquidation Bonus: 5%• Reserve Factor: 10%• Supply Cap: 50,000,000 sUSDS• Borrow Cap: 0 sUSDS• Optimal Utilization: 80%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 2%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No</td>
        </tr>
        <tr>
          <td>
            <dfn>LBTC Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current LBTC risk parameters are:• LTV: 65%• Liquidation Threshold: 70%• E-mode Category: 3• Liquidation Bonus: 8%• Reserve Factor: 15%• Supply Cap: 250 LBTC• Borrow Cap: 0• Optimal Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 5%• Slope 1: 15%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>tBTC Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current tBTC risk parameters are:• LTV: 65%• Liquidation Threshold: 70%• E-mode Category: 0• Liquidation Bonus: 8%• Reserve Factor: 20%• Supply Cap: 125 tBTC• Borrow Cap: 25 tBTC• Optimal Utilization: 60%• Isolated Debt Ceiling: N/A• Base Rate: 0%• Slope 1: 4%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: Yes• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: Yes</td>
        </tr>
        <tr>
          <td>
            <dfn>ezETH Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current ezETH risk parameters are:• LTV: 72%• Liquidation Threshold: 73%• E-mode Category: 0• Liquidation Bonus: 10%• Reserve Factor: 15%• Supply Cap: 2,000 ezETH• Borrow Cap: 0• Optimal Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 5%• Slope 1: 15%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>rsETH Risk Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current rsETH risk parameters are:• LTV: 72%• Liquidation Threshold: 73%• E-mode Category: 0• Liquidation Bonus: 10%• Reserve Factor: 15%• Supply Cap: 2,000 rsETH• Borrow Cap: 0• Optimal Utilization: 45%• Isolated Debt Ceiling: N/A• Base Rate: 5%• Slope 1: 15%• Slope 2: 300%• Reserve State: Active• Collateral: Yes• Borrowing: No• Isolated Collateral: No• Isolated Borrowing: No• Siloed Borrowing: No• Flash Loan Enabled: No</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Cap Automators</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            Cap Automaters allow the Supply Cap defined in <dfn>Supply Cap Definition</dfn> and the Borrow Cap defined in <dfn>Borrow Cap Definition</dfn> to be dynamically adjusted.The Cap Automater is defined in terms of three parameters:1. gap - the target available exposure2. ttl - the cooldown period for cap increases3. max - the absolute maximum exposureAny user can permissionlessly update a covered Supply Cap or Borrow Cap so the available exposure is equal to the target, as long as the resulting exposure does not exceed the specified maximum limit and the cooldown period has elapsed in the case of increases to the Supply Cap or Borrow Cap.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Cap Automator Parameter Definitions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subdocuments herein define the parameters of the Cap Automators.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Cap Automator Target Available Exposure Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The gap parameter is the target gap between the supply usage and the Supply Cap, in the case of the Supply Cap, or between the borrow usage and the Borrow Cap, in the case of the Borrow Cap.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Cap Automator Cooldown Period Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The ttl parameters is the minimum time requirement before it is possible to increase the Supply Cap or Borrow Cap, expressed in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Cap Automator Absolute Maximum Exposure Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The max parameter is the maximum the Supply Cap or Borrow Cap can be increased to.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator Current Configuration</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subdocuments herein define the current configuration of the cap automators for each covered market.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator WETH Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current WETH cap automator parameters are:• Supply cap ◦ gap: 150,000 WETH ◦ ttl: 12 hours ◦ max: 2 million WETH• Borrow cap ◦ gap: 10,000 WETH ◦ ttl: 12 hours ◦ max: 1 million WETH</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator wstETH Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current wstETH cap automator parameters are:• Supply cap ◦ gap: 50,000 wstETH ◦ ttl: 12 hours ◦ max: 1.2 million wstETH• Borrow cap ◦ gap: 10,000 wstETH ◦ ttl: 12 hours ◦ max: 1,000,000 wstETH</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator rETH Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current rETH cap automator parameters are:• Supply cap ◦ gap: 10,000 rETH ◦ ttl: 12 hours ◦ max: 80,000 rETH• Borrow cap ◦ gap: 100 rETH ◦ ttl: 12 hours ◦ max: 2,400 rETH</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator WBTC Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current WBTC cap automator parameters are:• Supply cap ◦ gap: 200 WBTC ◦ ttl: 12 hours ◦ max: 5,000 WBTC• Borrow cap ◦ gap: 1 WBTC ◦ ttl: 12 hours ◦ max: 1 WBTC</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator sDai Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current sDai cap automator parameters are:• Supply cap ◦ gap: 50 million sDai ◦ ttl: 12 hours ◦ max: 1 billion sDai• Borrow cap: n/a - not a borrowable asset ◦ gap: n/a ◦ ttl: n/a ◦ max: 0 sDAI</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator USDC Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current USDC cap automator parameters are:• Supply cap ◦ gap: n/a ◦ ttl: n/a ◦ max: 60 million USDC• Borrow cap ◦ gap: 6 million USDC ◦ ttl: 12 hours ◦ max: 57 million USDC</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator USDT Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current USDT cap automator parameters are:• Supply cap ◦ gap: n/a ◦ ttl: n/a ◦ max: 30 million USDT• Borrow cap ◦ gap: 3 million USDT ◦ ttl: 12 hours ◦ max: 28.5 million USDT</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator cbBTC Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current cbBTC cap automator parameters are:• Supply cap ◦ gap: 500 cbBTC ◦ ttl: 12 hours ◦ max: 3,000 cbBTC• Borrow cap ◦ gap: 50 cbBTC ◦ ttl: 12 hours ◦ max: 500 cbBTC</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator sUSDS Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current sUSDS cap automator parameters are:• Supply cap ◦ gap: 50 millions sUSDS ◦ ttl: 12 hours ◦ max: 500 million sUSDS• Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator weETH Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current weETH cap automator parameters are:• Supply cap ◦ gap: 10,000 weETH ◦ ttl: 12 hours ◦ max: 500,000 weETH• Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator LBTC Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current LBTC cap automator parameters are:• Supply cap ◦ gap: 250 LBTC ◦ ttl: 12 hours ◦ max: 2,500 LBTC• Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator tBTC Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current tBTC cap automator parameters are:• Supply cap ◦ gap: 125 tBTC ◦ ttl: 12 hours ◦ max: 500 tBTC• Borrow cap ◦ gap: 25 tBTC ◦ ttl: 12 hours ◦ max: 250 tBTC</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator ezETH Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current ezETH cap automator parameters are:• Supply cap ◦ gap: 2,000 ezETH ◦ ttl: 12 hours ◦ max: 20,000 ezETH• Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Cap Automator rsETH Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current rsETH cap automator parameters are:• Supply cap ◦ gap: 2,000 rsETH ◦ ttl: 12 hours ◦ max: 20,000 rsETH• Borrow cap ◦ gap: N/A ◦ ttl: N/A ◦ max: N/A</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Kill Switch</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The kill switch disables all borrowing across SparkLend markets in the event of a depeg on key collateral assets.The kill switch is defined in terms of a threshold for specified pegged assets. If the ratio of the price of a specified asset to its peg is equal to or less than the threshold, then any user can trigger the kill switch to disable borrowing across all SparkLend markets.After the kill switch is triggered, markets can be reactivated by Sky Governance after resetting the kill switch. Resetting the kill switch is subject to the Governance Security Delay specified in <dfn>A.1.9 - A2 - Sky Core Governance Security - Governance Security Delay Requirements</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Kill Switch Current Configuration</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The kill switch currently covers the following assets with the specified thresholds:• STETH/ETH - 0.95</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of SparkLend. Future iterations of the Artifact will specify operational processes owned by Spark.</td>
        </tr>
        <tr>
          <td>
            <dfn>SparkLend Risk Parameters Modification</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            The modification of SparkLend parameters is temporarily controlled by Sky Core, but will be transitioned to Spark in the future. Currently, the Stability Facilitators, in consultation with the Stability Scope Advisors and Phoenix Labs, may recommend changes to any of the parameters specified in the subdocuments of <dfn>SparkLend Risk Parameters Definitions</dfn> or <dfn>SparkLend Risk Parameters Cap Automator Parameter Definitions</dfn>.As a general rule, the modification of said parameters is pursuant to the Operational Weekly Cycle and can be effected directly via an Executive Vote, without requiring a Governance Poll.Changes to the parameters defined in the following documents are exceptions to the general rule and require a Governance Poll followed by an Executive Vote: • <dfn>Liquidation Threshold Definition</dfn> • <dfn>Liquidation Bonus Definition</dfn>
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Collateral Onboarding/Offboarding</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The onboarding/offboarding of SparkLend collateral is temporarily controlled by Sky Core, but will be transitioned to Spark in the future. Currently, it is implemented by the Stability Facilitators, in consultation with the Stability Scope Advisors and Phoenix Labs, through the Operational Weekly Cycle.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Protocol-Aave Revenue Share</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Spark Protocol must pay out 10% of the income it generates from operating the borrowing and lending functionality of the protocol that is based on the Aave codebase. The documents herein define the Spark Protocol-Aave Revenue Share and its associated operational processes.</td>
        </tr>
        <tr>
          <td>
            <dfn>Sky Core Governance Responsibility For Virtual Revenue Share Prior to Launch of SPK</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            Before the launch of Agent tokens, Sky Governance is temporarily responsible for paying out a "virtual revenue share" on behalf of Spark Protocol. It is calculated by taking the total amount of Dai borrowed from Spark Protocol, and then assuming a "virtual income" equivalent to 1% of this supply, and calculating a revenue share of 10% on that basis. The calculations and payments must be done manually by the Support Facilitators at the end of each quarter.As an example: if, before the launch of Agent tokens, 200 million Dai is borrowed on Spark Protocol, then the virtual income is 1% of 200 million Dai, which gives 2 million Dai; and of that 2 million Dai the virtual revenue share is 200,000 Dai.This 200,000 Dai must be paid out in incremental payments each quarter directly by Sky Governance from the Sky Surplus Buffer to a smart contract under the control of Aave Governance. If, before the launch of Agent tokens, less than 100 million Dai is borrowed from Spark Protocol by the Sky Protocol, accrual towards the virtual revenue share payments are paused (unpaid virtual revenue share that already accrued is still paid out at the end of the quarter), and the counting down of the revenue share duration is paused. The virtual revenue share payments and the counting down of the remaining revenue share duration is resumed when at least 100 million Dai is again borrowed from Spark Protocol by the Sky Protocol.Once SPK tokens launch, the virtual revenue share system will be discontinued, and the standard rules of the Spark Protocol Aave Revenue Share Ecosystem Agreement shall take effect. See <dfn>Standard Agreement Post SPK Launch</dfn>.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Standard Agreement Post SPK Launch</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Post SPK launch, the following revenue-share operational process takes effect. The revenue share payment must be calculated manually at the end of each quarter by the Spark and manually paid as Dai to a smart contract under the control of Aave Governance from Spark. The payments must occur for the revenue share duration of two (2) years, starting from September 25th, 2023.If at any point in time after the launch of Agent tokens, Spark Protocol is generating less than 1 million Dai per year in income for Spark Agent, accrual towards the revenue share payments are paused (unpaid revenue share that already accrued is still paid out at the end of the quarter), and the counting down of the revenue share duration is paused. The revenue share payments and the counting down of the remaining revenue share duration is resumed when Spark Protocol is generating more than 1 million Dai per year in income again.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to SparkLend.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Dai Direct Deposit Module</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the parameters and operational processes related to the Spark Dai Direct Deposit Module. Spark is able to temporarily borrow Dai from Sky Core through the Spark Dai Direct Deposit Module (D3M). This will be replaced by borrowing at the Agents Credit Line Borrow Rate specified in after the launch of Agent Vaults and the development of a new Rate System.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The parameters of the Spark Dai Direct Deposit Module are specified in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameter Definitions</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subdocuments herein define the Spark Dai Direct Deposit Module parameters.</td>
        </tr>
        <tr>
          <td>
            <dfn>Target Available Debt Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The gap parameter is the target gap between the debt usage and the debt ceiling.</td>
        </tr>
        <tr>
          <td>
            <dfn>Debt Ceiling Increase Cooldown Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The ttl parameter is the minimum time requirement before it is possible to increase the debt ceiling, expressed in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>Maximum Debt Ceiling Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The line is the maximum amount of debt that can be borrowed under the Spark Dai Direct Deposit Module.</td>
        </tr>
        <tr>
          <td>
            <dfn>Buffer Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>buffer is a fixed-sized amount of pre-minted Dai which the Spark Dai Direct Deposit Module is designed to maintain in most situations.</td>
        </tr>
        <tr>
          <td>
            <dfn>Debt Write Off Timelock Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>tau is the timelock required before bad debt can be written off after the Spark Dai Direct Deposit Module has been shut down, expressed in seconds.</td>
        </tr>
        <tr>
          <td>
            <dfn>Current Configuration</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The current parameters of the Spark Dai Direct Deposit Module are:- gap: 40 million Dai- ttl: 24 hours- line: 2.5 billion Dai- buffer: 100 million Dai- tau: 7 days</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of the Spark Dai Direct Deposit Module. Future iterations of the Artifact will specify operational processes owned by Spark.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Dai Direct Deposit Module Ongoing Management</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Spark Dai Direct Deposit Module is managed by the Stability Facilitators, in consultation with the Stability Scope Advisors and Phoenix Labs.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Deployment Of New Direct Deposit Modules</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The Stability Facilitators can directly include the deployment of new Direct Deposit Modules in Executive Votes, with risk parameters defined by the Stability Facilitators. These parameters should be based on input from the Stability Scope Advisors and Phoenix Labs and should best serve the needs of the Sky Ecosystem and its collaboration with other protocols.</td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Spark Dai Direct Deposit Module.</td>
        </tr>
        <tr>
          <td>
            <dfn>Spark Pre-launch Token Rewards</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The subdocuments herein define the parameters and operational processes related to Spark's pre-launch token rewards program. These rewards will be paid exclusively out of the SPK tokens held by the Spark Foundation.</td>
        </tr>
        <tr>
          <td>
            <dfn>Parameters</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The parameters of the Spark Pre-launch Token Rewards are specified in the subdocuments herein.</td>
        </tr>
        <tr>
          <td>
            <dfn>Conditions For The Pre-launch Token Rewards</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>Spark has a pre-launch token rewards program based on the usage of its lending platform. Users of the platform will receive an airdrop of SPK tokens, depending on how much and how long they have used the platform during the pre-launch token reward period. These rewards are only for users on Ethereum Mainnet.There are two seasons of the Spark pre-launch token rewards: Season 1 and Season 2.Season 1 of pre-launch token rewards was active from August 20 2023 and lasted for nine months, ending on May 20 2024. 60m SPK tokens were allocated in this period.In Season 2 6.66M SPK will be rewarded per month to SparkLend users who qualify for the airdrop.Season 2 is an additional pre-farming period, which runs until the Spark Agent launches as part of Sky Endgame launch season.The monthly SPK rewards are allocated as follows:◦ 80 % is allocated to users borrowing DAI and/or USDS◦ 20 % is allocated to users supplying ETHThe proposed full anti-cheat SPK Airdrop for SparkLend is calculated using the following formula:Airdrop = 80% * (DAI Borrows + USDS Borrows - sDAI Supplies * sDAI Liquidation Threshold - sUSDS Supplies * sUSDS Liquidation Threshold) + 20% * (ETH Supplies - ETH Borrows / ETH Liquidation Threshold)All supplies and borrows are denominated in USD based on the on-chain oracle price at that block to determine the conversion.</td>
        </tr>
        <tr>
          <td>
            <dfn>Operational Process Definition</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein define the process for the ongoing management of the Spark Pre-launch Token Rewards.</td>
        </tr>
        <tr>
          <td>
            <dfn>Pre-launch Token Rewards Ongoing Management</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            Spark can activate a new SPK token pre-launch token reward airdrop program to capture other growth opportunities.The program can last until the moment SPK launches, or a shorter duration. When activated, the exact details of the special pre-launch token reward airdrop program must be specified in <dfn>Conditions For The Pre-launch Token Rewards</dfn>.The SPK tokens for the future Spark Airdrop are allocated between all borrowers based on a formula announced by Spark and specified in the above cited document. The rate of SPK tokens being earned is 3.33 million SPK per month, distributed on a per block basis proportional to the formula specified in the above cited document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Special Pre-launch Token Reward Programs</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>
            Spark can activate a new SPK token pre-launch token reward airdrop program to capture other growth opportunities.The program can last until the moment SPK launches, or a shorter duration. When activated, the exact details of the special pre-launch token reward airdrop program must be specified in <dfn>Special Pre-launch Token Reward Program Details</dfn>.The SPK tokens for the future Spark Airdrop are allocated between all borrowers based on a formula announced by Spark and specified in the above cited document. The rate of SPK tokens being earned is 3.33 million SPK per month, distributed on a per block basis proportional to the formula specified in the above cited document.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Special Pre-launch Token Reward Program Details</dfn>
          </td>
          <td>Spark</td>
          <td>Active Data Controller</td>
          <td>
            The special pre-launch token reward airdrop program is defined as Active Data in <dfn>Special Pre-launch Token Reward Program Details</dfn>.The Active Data is updated as follows:- The Responsible Party is Operational GovOps.- The Update Process must follow the protocol for 'Direct Edit'.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>Data Repository</dfn>
          </td>
          <td>Spark</td>
          <td>Core</td>
          <td>The documents herein contain data relevant to the Spark Pre-launch Token Rewards.</td>
        </tr>
      </tbody>
    </table>
  </div>
</body>

</html>
